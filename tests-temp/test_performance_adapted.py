#!/usr/bin/env python3
"""
æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡åŠŸèƒ½æµ‹è¯•è„šæœ¬ï¼ˆé€‚é…ç‰ˆï¼‰
éªŒè¯é¡¹ç›®ä¸­å®é™…å¯ç”¨çš„æ€§èƒ½ç›‘æ§ã€æ—¶é—´è·Ÿè¸ªã€ç»Ÿè®¡è®°å½•ç­‰åŠŸèƒ½
"""

import sys
import os
import time
import json
import tempfile
from pathlib import Path
from unittest.mock import Mock, patch
from datetime import datetime, timedelta
from typing import Dict, List, Any

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_progress_tracker_performance():
    """æµ‹è¯•è¿›åº¦è·Ÿè¸ªå™¨æ€§èƒ½ç›‘æ§"""
    print("ğŸ” æµ‹è¯•è¿›åº¦è·Ÿè¸ªå™¨æ€§èƒ½ç›‘æ§...")

    try:
        from src.utils.progress import ProgressTracker

        # åˆ›å»ºè¿›åº¦è·Ÿè¸ªå™¨
        progress = ProgressTracker(verbose=True)

        print("   æµ‹è¯•åŸºæœ¬æ—¶é—´è·Ÿè¸ª:")
        progress.start(total_steps=10)

        # æ¨¡æ‹Ÿæ–‡ä»¶åˆ†æè¿‡ç¨‹
        start_time = time.time()
        for i in range(10):
            time.sleep(0.01)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            progress.step(f"å¤„ç†æ–‡ä»¶ {i+1}")
            if i % 3 == 0:  # æ¯3ä¸ªæ–‡ä»¶æ›´æ–°é—®é¢˜è®¡æ•°
                progress.update_issue_count(i // 3 + 1)

        elapsed_time = time.time() - start_time
        progress.finish()

        print(f"   - æ¨¡æ‹Ÿåˆ†æå®Œæˆæ—¶é—´: {elapsed_time:.3f}s")

        # è·å–æ‘˜è¦ä¿¡æ¯
        summary = progress.get_summary()
        print("   è¿›åº¦è·Ÿè¸ªæ‘˜è¦:")
        print(f"     - å®Œæˆæ­¥éª¤æ•°: {summary.get('steps_completed', 0)}")
        print(f"     - æ€»æ­¥éª¤æ•°: {summary.get('total_steps', 0)}")
        print(f"     - å‘ç°é—®é¢˜æ•°: {summary.get('total_issues', 0)}")
        print(f"     - æ€»è€—æ—¶: {summary.get('total_time', 0):.3f}s")

        # éªŒè¯æ€§èƒ½æŒ‡æ ‡åˆç†æ€§
        total_time = summary.get('total_time', 0)
        steps_completed = summary.get('steps_completed', 0)
        performance_reasonable = total_time > 0 and steps_completed == 10

        print(f"     - æ€§èƒ½æŒ‡æ ‡åˆç†æ€§: {'âœ…' if performance_reasonable else 'âŒ'}")

        # æµ‹è¯•ç®€åŒ–æ¨¡å¼è¿›åº¦è·Ÿè¸ªå™¨
        print("\n   æµ‹è¯•ç®€åŒ–æ¨¡å¼è¿›åº¦è·Ÿè¸ª:")
        progress2 = ProgressTracker(verbose=False)
        progress2.start(total_steps=5)

        start_time = time.time()
        for i in range(5):
            progress2.step(f"ç®€åŒ–æ¨¡å¼æ­¥éª¤ {i+1}")
            time.sleep(0.005)

        progress2.finish()
        elapsed_time2 = time.time() - start_time

        summary2 = progress2.get_summary()
        print(f"     - ç®€åŒ–æ¨¡å¼å®Œæˆæ—¶é—´: {elapsed_time2:.3f}s")
        print(f"     - ç®€åŒ–æ¨¡å¼æ­¥éª¤æ•°: {summary2.get('steps_completed', 0)}")

        speed_comparison = elapsed_time2 < elapsed_time
        print(f"     - ç®€åŒ–æ¨¡å¼æ€§èƒ½æå‡: {'âœ…' if speed_comparison else 'âŒ'}")

        return performance_reasonable and len(summary) > 0

    except Exception as e:
        print(f"âŒ è¿›åº¦è·Ÿè¸ªå™¨æ€§èƒ½ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_logger_performance_monitoring():
    """æµ‹è¯•æ—¥å¿—ç³»ç»Ÿæ€§èƒ½ç›‘æ§"""
    print("\nğŸ” æµ‹è¯•æ—¥å¿—ç³»ç»Ÿæ€§èƒ½ç›‘æ§...")

    try:
        from src.utils.logger import get_logger

        logger = get_logger()

        print("   æµ‹è¯•APIè¯·æ±‚æ—¥å¿—è®°å½•:")
        # æ¨¡æ‹ŸAPIè¯·æ±‚æ—¥å¿—è®°å½•
        start_time = time.time()

        logger.log_api_request(
            api_type="LLM",
            endpoint="/analyze",
            status="success",
            response_time=0.234,
            model="glm-4.5",
            tokens=150
        )

        logger.log_api_request(
            api_type="Static Analysis",
            endpoint="/pylint",
            status="success",
            response_time=0.089,
            file_count=5
        )

        api_log_time = time.time() - start_time
        print(f"     - APIæ—¥å¿—è®°å½•æ—¶é—´: {api_log_time:.3f}s")

        print("\n   æµ‹è¯•æ‰¹é‡æ—¥å¿—æ€§èƒ½:")
        # æµ‹è¯•æ‰¹é‡æ—¥å¿—è®°å½•æ€§èƒ½
        log_count = 100
        start_time = time.time()

        for i in range(log_count):
            logger.info(f"Performance test log {i}")
            if i % 10 == 0:
                logger.warning(f"Warning message {i}")

        batch_log_time = time.time() - start_time
        logs_per_second = log_count / batch_log_time
        print(f"     - æ‰¹é‡æ—¥å¿—æ€§èƒ½: {logs_per_second:.0f} æ¡/ç§’")
        print(f"     - æ€»æ—¥å¿—æ•°: {log_count}")
        print(f"     - æ€»è€—æ—¶: {batch_log_time:.3f}s")

        print("\n   æµ‹è¯•æ—¥å¿—æ€§èƒ½æŒ‡æ ‡æ”¶é›†:")
        # æ¨¡æ‹Ÿæ€§èƒ½æŒ‡æ ‡æ—¥å¿—
        performance_logs = []
        for i in range(10):
            log_time = time.time()
            logger.info(f"Processing item {i}", extra={
                'performance': {
                    'item_id': i,
                    'start_time': log_time,
                    'processing_time': 0.01 + (i * 0.001)
                }
            })
            performance_logs.append(log_time)

        print(f"     - æ€§èƒ½æ—¥å¿—è®°å½•æ•°: {len(performance_logs)}")

        # æ€§èƒ½åŸºå‡†æµ‹è¯•
        performance_good = (
            api_log_time < 0.01 and
            logs_per_second > 1000
        )

        print(f"     - æ—¥å¿—æ€§èƒ½è¯„ä¼°: {'âœ… ä¼˜ç§€' if performance_good else 'âŒ éœ€ä¼˜åŒ–'}")
        return performance_good

    except Exception as e:
        print(f"âŒ æ—¥å¿—ç³»ç»Ÿæ€§èƒ½ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cache_performance_monitoring():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½ç›‘æ§"""
    print("\nğŸ” æµ‹è¯•ç¼“å­˜æ€§èƒ½ç›‘æ§...")

    try:
        from src.utils.cache import CacheManager

        cache = CacheManager()

        print("   æµ‹è¯•ç¼“å­˜ç»Ÿè®¡åŠŸèƒ½:")
        # åˆå§‹ç»Ÿè®¡
        initial_stats = cache.get_stats()
        print(f"     - åˆå§‹ç¼“å­˜å¤§å°: {initial_stats.get('size', 0)}")
        print(f"     - åˆå§‹æ€»å­—èŠ‚æ•°: {initial_stats.get('total_size_bytes', 0)}")

        # æ·»åŠ æµ‹è¯•æ•°æ®
        test_data = []
        for i in range(100):
            data = {
                'id': i,
                'content': f'test_content_{i}',
                'metadata': {
                    'created_at': datetime.now().isoformat(),
                    'size': len(f'test_content_{i}') * 10,
                    'tags': [f'tag_{j}' for j in range(3)]
                }
            }
            test_data.append(data)
            cache.set(f"cache_key_{i}", data, ttl=300)

        # è·å–ç¼“å­˜ç»Ÿè®¡
        stats_after_write = cache.get_stats()
        print(f"     - å†™å…¥åç¼“å­˜å¤§å°: {stats_after_write.get('size', 0)}")
        print(f"     - å†™å…¥åæ€»å­—èŠ‚æ•°: {stats_after_write.get('total_size_bytes', 0)}")
        print(f"     - åç«¯ç±»å‹: {stats_after_write.get('backend_type', 'unknown')}")

        # æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡
        print("\n   æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡:")
        cache_hits = 0
        cache_misses = 0

        # ç¬¬ä¸€æ¬¡è®¿é—®ï¼ˆåº”è¯¥å…¨éƒ¨å‘½ä¸­ï¼‰
        start_time = time.time()
        for i in range(100):
            result = cache.get(f"cache_key_{i}")
            if result is not None:
                cache_hits += 1
            else:
                cache_misses += 1
        read_time = time.time() - start_time

        hit_rate = cache_hits / (cache_hits + cache_misses) if (cache_hits + cache_misses) > 0 else 0
        print(f"     - ç¼“å­˜å‘½ä¸­æ•°: {cache_hits}")
        print(f"     - ç¼“å­˜æœªå‘½ä¸­æ•°: {cache_misses}")
        print(f"     - å‘½ä¸­ç‡: {hit_rate:.1%}")
        print(f"     - è¯»å–æ€§èƒ½: {100/read_time:.0f} æ¬¡/ç§’")

        # æµ‹è¯•ä¸“ç”¨ç¼“å­˜æ–¹æ³•æ€§èƒ½
        print("\n   æµ‹è¯•ä¸“ç”¨ç¼“å­˜æ–¹æ³•æ€§èƒ½:")
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_file = Path("perf_test_file.py")
        test_file.write_text("def test_func(): return 'test'")

        # é™æ€åˆ†æç¼“å­˜
        static_result = {'tool': 'pylint', 'issues': [], 'score': 9.0}
        cache_start = time.time()
        cache.cache_static_analysis(str(test_file), 'comprehensive', static_result)
        cache_time = time.time() - cache_start

        get_start = time.time()
        cached_result = cache.get_static_analysis(str(test_file), 'comprehensive')
        get_time = time.time() - get_start

        print(f"     - é™æ€åˆ†æç¼“å­˜æ—¶é—´: {cache_time:.6f}s")
        print(f"     - é™æ€åˆ†æè·å–æ—¶é—´: {get_time:.6f}s")
        print(f"     - ç¼“å­˜ç»“æœæ­£ç¡®: {'âœ…' if cached_result else 'âŒ'}")

        # LLMå“åº”ç¼“å­˜
        llm_start = time.time()
        cache.cache_llm_response("test prompt", "glm-4.5", "test response")
        llm_cache_time = time.time() - llm_start

        get_llm_start = time.time()
        llm_response = cache.get_llm_response("test prompt", "glm-4.5")
        get_llm_time = time.time() - get_llm_start

        print(f"     - LLMç¼“å­˜æ—¶é—´: {llm_cache_time:.6f}s")
        print(f"     - LLMè·å–æ—¶é—´: {get_llm_time:.6f}s")
        print(f"     - LLMç¼“å­˜æ­£ç¡®: {'âœ…' if llm_response else 'âŒ'}")

        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        test_file.unlink(missing_ok=True)

        # æ€§èƒ½éªŒè¯
        performance_valid = (
            stats_after_write.get('size', 0) == 100 and
            hit_rate >= 0.9 and
            cache_time < 0.01 and get_time < 0.01
        )

        print(f"     - ç¼“å­˜æ€§èƒ½éªŒè¯: {'âœ…' if performance_valid else 'âŒ'}")
        return performance_valid

    except Exception as e:
        print(f"âŒ ç¼“å­˜æ€§èƒ½ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_file_operation_performance():
    """æµ‹è¯•æ–‡ä»¶æ“ä½œæ€§èƒ½"""
    print("\nğŸ” æµ‹è¯•æ–‡ä»¶æ“ä½œæ€§èƒ½...")

    try:
        print("   æµ‹è¯•æ–‡ä»¶è¯»å†™æ€§èƒ½:")
        temp_dir = tempfile.mkdtemp()
        test_files = []

        # æµ‹è¯•æ–‡ä»¶å†™å…¥æ€§èƒ½
        write_start = time.time()
        for i in range(20):
            file_path = Path(temp_dir) / f"test_file_{i}.txt"
            content = f"Test file {i}\n" + "x" * 1000  # 1KBå†…å®¹
            file_path.write_text(content)
            test_files.append(file_path)
        write_time = time.time() - write_start

        write_speed = len(test_files) / write_time
        print(f"     - æ–‡ä»¶å†™å…¥é€Ÿåº¦: {write_speed:.0f} æ–‡ä»¶/ç§’")
        print(f"     - å†™å…¥æ–‡ä»¶æ•°: {len(test_files)}")

        # æµ‹è¯•æ–‡ä»¶è¯»å–æ€§èƒ½
        read_start = time.time()
        read_count = 0
        for file_path in test_files:
            content = file_path.read_text()
            read_count += len(content)
        read_time = time.time() - read_start

        read_speed = read_count / 1024 / read_time  # KB/s
        print(f"     - æ–‡ä»¶è¯»å–é€Ÿåº¦: {read_speed:.0f} KB/ç§’")
        print(f"     - è¯»å–æ€»å­—èŠ‚æ•°: {read_count}")

        # æµ‹è¯•æ–‡ä»¶éå†æ€§èƒ½
        traverse_start = time.time()
        for file_path in Path(temp_dir).iterdir():
            if file_path.is_file():
                stat = file_path.stat()
        traverse_time = time.time() - traverse_start

        print(f"     - ç›®å½•éå†æ—¶é—´: {traverse_time:.3f}s")
        print(f"     - éå†æ–‡ä»¶æ•°: {len(test_files)}")

        # æµ‹è¯•å¤§æ–‡ä»¶æ“ä½œ
        print("\n   æµ‹è¯•å¤§æ–‡ä»¶æ“ä½œæ€§èƒ½:")
        large_file = Path(temp_dir) / "large_file.txt"
        large_content = "x" * (1024 * 100)  # 100KB

        large_write_start = time.time()
        large_file.write_text(large_content)
        large_write_time = time.time() - large_write_start

        large_read_start = time.time()
        large_read_content = large_file.read_text()
        large_read_time = time.time() - large_read_start

        print(f"     - å¤§æ–‡ä»¶å†™å…¥æ—¶é—´: {large_write_time:.3f}s")
        print(f"     - å¤§æ–‡ä»¶è¯»å–æ—¶é—´: {large_read_time:.3f}s")
        print(f"     - å¤§æ–‡ä»¶å¤§å°: {len(large_read_content)} å­—èŠ‚")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        shutil.rmtree(temp_dir)

        # æ€§èƒ½éªŒè¯
        performance_valid = (
            write_speed > 100 and
            read_speed > 1000 and
            traverse_time < 0.1 and
            large_write_time < 0.1 and
            large_read_time < 0.1
        )

        print(f"     - æ–‡ä»¶æ“ä½œæ€§èƒ½éªŒè¯: {'âœ…' if performance_valid else 'âŒ'}")
        return performance_valid

    except Exception as e:
        print(f"âŒ æ–‡ä»¶æ“ä½œæ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_memory_usage_monitoring():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨ç›‘æ§"""
    print("\nğŸ” æµ‹è¯•å†…å­˜ä½¿ç”¨ç›‘æ§...")

    try:
        print("   æµ‹è¯•å†…å­˜ä½¿ç”¨è·Ÿè¸ª:")

        # åŸºç¡€å†…å­˜ç›‘æ§
        import gc
        import sys

        # è·å–åˆå§‹å†…å­˜çŠ¶æ€
        gc.collect()
        initial_objects = len(gc.get_objects())
        print(f"     - åˆå§‹å¯¹è±¡æ•°é‡: {initial_objects}")

        # åˆ›å»ºå¤§é‡å¯¹è±¡è¿›è¡Œæµ‹è¯•
        data_objects = []
        for i in range(1000):
            data = {
                'id': i,
                'data': 'x' * 100,
                'metadata': {
                    'created_at': time.time(),
                    'type': f'type_{i % 10}',
                    'tags': [f'tag_{j}' for j in range(5)]
                }
            }
            data_objects.append(data)

        peak_objects = len(gc.get_objects())
        print(f"     - å³°å€¼å¯¹è±¡æ•°é‡: {peak_objects}")
        print(f"     - æ–°å¢å¯¹è±¡æ•°é‡: {peak_objects - initial_objects}")

        # æµ‹è¯•å†…å­˜æ¸…ç†
        del data_objects
        gc.collect()

        after_cleanup_objects = len(gc.get_objects())
        print(f"     - æ¸…ç†åå¯¹è±¡æ•°é‡: {after_cleanup_objects}")
        print(f"     - æ¸…ç†å¯¹è±¡æ•°é‡: {peak_objects - after_cleanup_objects}")

        # æµ‹è¯•åˆ—è¡¨å†…å­˜ä½¿ç”¨
        print("\n   æµ‹è¯•æ•°æ®ç»“æ„å†…å­˜ä½¿ç”¨:")
        test_lists = []

        # æµ‹è¯•ä¸åŒå¤§å°çš„åˆ—è¡¨
        for size in [100, 1000, 10000]:
            test_list = list(range(size))
            test_lists.append(test_list)

            # ç®€å•ä¼°ç®—å†…å­˜ä½¿ç”¨
            list_size = sys.getsizeof(test_list)
            print(f"     - åˆ—è¡¨å¤§å° {size}: {list_size // 1024} KB")

        # æµ‹è¯•å­—ç¬¦ä¸²å†…å­˜ä½¿ç”¨
        print("\n   æµ‹è¯•å­—ç¬¦ä¸²å†…å­˜ä½¿ç”¨:")
        for size in [100, 1000, 10000]:
            test_string = 'x' * size
            string_size = sys.getsizeof(test_string)
            print(f"     - å­—ç¬¦ä¸²å¤§å° {size}: {string_size} å­—èŠ‚")

        # æ¸…ç†æµ‹è¯•æ•°æ®
        del test_lists

        # å†…å­˜æ•ˆç‡éªŒè¯
        memory_efficient = (
            peak_objects > initial_objects and
            after_cleanup_objects < peak_objects and
            len(gc.get_objects()) < peak_objects + 1000  # å…è®¸ä¸€äº›å¯¹è±¡ä»ç„¶å­˜åœ¨
        )

        print(f"     - å†…å­˜æ•ˆç‡éªŒè¯: {'âœ…' if memory_efficient else 'âŒ'}")
        return memory_efficient

    except Exception as e:
        print(f"âŒ å†…å­˜ä½¿ç”¨ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_performance_metrics_collection():
    """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡æ”¶é›†"""
    print("\nğŸ” æµ‹è¯•æ€§èƒ½æŒ‡æ ‡æ”¶é›†...")

    try:
        from src.utils.cache import CacheManager
        from src.utils.logger import get_logger
        from src.utils.progress import ProgressTracker

        # åˆ›å»ºæ€§èƒ½ç›‘æ§ç»„ä»¶
        cache = CacheManager()
        logger = get_logger()
        progress = ProgressTracker(verbose=False)

        # æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨
        class PerformanceCollector:
            def __init__(self):
                self.metrics = {
                    'operations': [],
                    'timings': {},
                    'counters': {},
                    'start_time': time.time()
                }

            def record_operation(self, operation_type, duration, details=None):
                """è®°å½•æ“ä½œæ€§èƒ½"""
                self.metrics['operations'].append({
                    'type': operation_type,
                    'duration': duration,
                    'timestamp': time.time(),
                    'details': details or {}
                })

            def record_timing(self, key, value):
                """è®°å½•æ—¶é—´æŒ‡æ ‡"""
                if key not in self.metrics['timings']:
                    self.metrics['timings'][key] = []
                self.metrics['timings'][key].append(value)

            def increment_counter(self, key, value=1):
                """å¢åŠ è®¡æ•°å™¨"""
                self.metrics['counters'][key] = self.metrics['counters'].get(key, 0) + value

            def get_summary(self):
                """è·å–æ€§èƒ½æ‘˜è¦"""
                end_time = time.time()
                total_time = end_time - self.metrics['start_time']

                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                operation_stats = {}
                for op in self.metrics['operations']:
                    op_type = op['type']
                    if op_type not in operation_stats:
                        operation_stats[op_type] = {
                            'count': 0,
                            'total_time': 0,
                            'min_time': float('inf'),
                            'max_time': 0
                        }

                    stats = operation_stats[op_type]
                    stats['count'] += 1
                    stats['total_time'] += op['duration']
                    stats['min_time'] = min(stats['min_time'], op['duration'])
                    stats['max_time'] = max(stats['max_time'], op['duration'])

                # è®¡ç®—å¹³å‡å€¼
                for stats in operation_stats.values():
                    stats['avg_time'] = stats['total_time'] / stats['count']

                return {
                    'total_duration': total_time,
                    'operation_stats': operation_stats,
                    'counters': self.metrics['counters'],
                    'timings_summary': {
                        key: {
                            'count': len(values),
                            'sum': sum(values),
                            'avg': sum(values) / len(values),
                            'min': min(values),
                            'max': max(values)
                        }
                        for key, values in self.metrics['timings'].items()
                    }
                }

        collector = PerformanceCollector()

        print("   æ‰§è¡Œæ€§èƒ½æµ‹è¯•å¹¶æ”¶é›†æŒ‡æ ‡:")

        # æµ‹è¯•1: ç¼“å­˜æ“ä½œæ€§èƒ½
        progress.start(total_steps=50)
        for i in range(50):
            start_time = time.time()
            cache.set(f"perf_key_{i}", {"data": f"value_{i}"}, ttl=300)
            duration = time.time() - start_time
            collector.record_operation("cache_set", duration, {"key": f"perf_key_{i}"})

            if i % 10 == 0:
                progress.step(f"ç¼“å­˜æ“ä½œ {i}")

        # æµ‹è¯•2: ç¼“å­˜è¯»å–æ€§èƒ½
        for i in range(50):
            start_time = time.time()
            result = cache.get(f"perf_key_{i}")
            duration = time.time() - start_time
            collector.record_operation("cache_get", duration, {"hit": result is not None})
            collector.increment_counter("cache_reads")

        # æµ‹è¯•3: æ—¥å¿—è®°å½•æ€§èƒ½
        for i in range(30):
            start_time = time.time()
            logger.info(f"Performance log {i}")
            duration = time.time() - start_time
            collector.record_operation("log_write", duration)
            collector.record_timing("log_duration", duration)

        progress.finish()

        # è·å–æ€§èƒ½æ‘˜è¦
        summary = collector.get_summary()
        print("\n   æ€§èƒ½æŒ‡æ ‡æ‘˜è¦:")
        print(f"     - æ€»æ‰§è¡Œæ—¶é—´: {summary['total_duration']:.3f}s")
        print(f"     - æ“ä½œç±»å‹æ•°: {len(summary['operation_stats'])}")

        for op_type, stats in summary['operation_stats'].items():
            print(f"     - {op_type}:")
            print(f"       â€¢ æ‰§è¡Œæ¬¡æ•°: {stats['count']}")
            print(f"       â€¢ æ€»è€—æ—¶: {stats['total_time']:.3f}s")
            print(f"       â€¢ å¹³å‡è€—æ—¶: {stats['avg_time']:.6f}s")
            print(f"       â€¢ æœ€å¿«è€—æ—¶: {stats['min_time']:.6f}s")
            print(f"       â€¢ æœ€æ…¢è€—æ—¶: {stats['max_time']:.6f}s")

        print(f"     - è®¡æ•°å™¨ç»Ÿè®¡: {summary['counters']}")

        # ç¼“å­˜æ€§èƒ½åˆ†æ
        cache_set_stats = summary['operation_stats'].get('cache_set', {})
        cache_get_stats = summary['operation_stats'].get('cache_get', {})

        if cache_set_stats and cache_get_stats:
            cache_efficiency = cache_get_stats['avg_time'] / cache_set_stats['avg_time']
            print(f"     - ç¼“å­˜è¯»å–æ•ˆç‡æ¯”: {cache_efficiency:.2f} (è¯»å–æ—¶é—´/å†™å…¥æ—¶é—´)")

        # æ€§èƒ½åŸºå‡†éªŒè¯
        performance_valid = (
            summary['total_duration'] > 0 and
            len(summary['operation_stats']) >= 2 and
            all(stats['count'] > 0 for stats in summary['operation_stats'].values())
        )

        print(f"     - æ€§èƒ½æŒ‡æ ‡æ”¶é›†éªŒè¯: {'âœ…' if performance_valid else 'âŒ'}")
        return performance_valid

    except Exception as e:
        print(f"âŒ æ€§èƒ½æŒ‡æ ‡æ”¶é›†æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡åŠŸèƒ½æµ‹è¯•ï¼ˆé€‚é…ç‰ˆï¼‰")
    print("=" * 60)

    test_results = []

    # 1. æµ‹è¯•è¿›åº¦è·Ÿè¸ªå™¨æ€§èƒ½ç›‘æ§
    progress_ok = test_progress_tracker_performance()
    test_results.append(progress_ok)

    # 2. æµ‹è¯•æ—¥å¿—ç³»ç»Ÿæ€§èƒ½ç›‘æ§
    logger_ok = test_logger_performance_monitoring()
    test_results.append(logger_ok)

    # 3. æµ‹è¯•ç¼“å­˜æ€§èƒ½ç›‘æ§
    cache_ok = test_cache_performance_monitoring()
    test_results.append(cache_ok)

    # 4. æµ‹è¯•æ–‡ä»¶æ“ä½œæ€§èƒ½
    file_ok = test_file_operation_performance()
    test_results.append(file_ok)

    # 5. æµ‹è¯•å†…å­˜ä½¿ç”¨ç›‘æ§
    memory_ok = test_memory_usage_monitoring()
    test_results.append(memory_ok)

    # 6. æµ‹è¯•æ€§èƒ½æŒ‡æ ‡æ”¶é›†
    metrics_ok = test_performance_metrics_collection()
    test_results.append(metrics_ok)

    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")

    passed = sum(test_results)
    total = len(test_results)

    print(f"âœ… é€šè¿‡: {passed}/{total}")
    print(f"âŒ å¤±è´¥: {total-passed}/{total}")

    if passed >= total * 0.8:  # 80%é€šè¿‡ç‡
        print("\nğŸ‰ æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡åŠŸèƒ½æµ‹è¯•åŸºæœ¬é€šè¿‡ï¼")
        print("æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡åŠŸèƒ½å·²å°±ç»ªã€‚")
        if passed < total:
            print(f"âš ï¸ æœ‰ {total-passed} é¡¹æµ‹è¯•å¤±è´¥ï¼Œä½†ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ã€‚")
        return 0
    else:
        print(f"\nâš ï¸ ä»…æœ‰ {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡ï¼Œéœ€è¦æ£€æŸ¥æ€§èƒ½ç›‘æ§åŠŸèƒ½ã€‚")
        return 1

if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        sys.exit(0)
    except Exception as e:
        print(f"\næµ‹è¯•å¼‚å¸¸: {e}")
        sys.exit(1)