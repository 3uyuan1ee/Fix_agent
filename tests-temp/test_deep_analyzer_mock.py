#!/usr/bin/env python3
"""
æ·±åº¦åˆ†æåŠŸèƒ½æµ‹è¯•è„šæœ¬ï¼ˆMockç‰ˆæœ¬ï¼‰
ç”¨äºéªŒè¯DeepAnalyzerçš„æ ¸å¿ƒåŠŸèƒ½å¯ç”¨æ€§ï¼Œä¸éœ€è¦çœŸå®APIå¯†é’¥
"""

import sys
import os
import asyncio
from pathlib import Path
from unittest.mock import Mock, patch, AsyncMock

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

class MockLLMClient:
    """Mock LLMå®¢æˆ·ç«¯"""
    def __init__(self):
        self.default_model = "glm-4.5"
        self.stats = {"total_requests": 0, "successful_requests": 0}

    def create_request(self, messages, **kwargs):
        """åˆ›å»ºè¯·æ±‚"""
        class MockRequest:
            def __init__(self):
                self.messages = messages
                self.model = kwargs.get('model', 'glm-4.5')
                self.temperature = kwargs.get('temperature', 0.3)
                self.max_tokens = kwargs.get('max_tokens', 4000)

        return MockRequest()

    async def complete(self, request):
        """å®Œæˆè¯·æ±‚"""
        self.stats["total_requests"] += 1
        self.stats["successful_requests"] += 1

        class MockResponse:
            def __init__(self):
                self.content = '''{
    "summary": "ä»£ç è´¨é‡è‰¯å¥½ï¼Œç»“æ„æ¸…æ™°",
    "issues": [
        {
            "type": "suggestion",
            "line": 1,
            "message": "å»ºè®®æ·»åŠ å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²"
        }
    ],
    "recommendations": [
        "æ·»åŠ è¯¦ç»†çš„æ–‡æ¡£è¯´æ˜",
        "è€ƒè™‘æ·»åŠ ç±»å‹æ³¨è§£",
        "æ·»åŠ é”™è¯¯å¤„ç†æœºåˆ¶"
    ],
    "overall_score": 8.5
}'''
                self.model = request.model
                self.provider = "mock"
                self.usage = {"total_tokens": 150}

        return MockResponse()

class MockPromptManager:
    """Mock Promptç®¡ç†å™¨"""
    def get_template(self, template_name):
        """è·å–æ¨¡æ¿"""
        if template_name == "deep_analysis_system":
            return MockTemplate()
        return None

    def render_template(self, template_name, variables):
        """æ¸²æŸ“æ¨¡æ¿"""
        class MockResult:
            def __init__(self):
                self.success = True
                self.content = f"è¯·åˆ†æä»¥ä¸‹ä»£ç ï¼ˆ{variables.get('analysis_type', 'comprehensive')}åˆ†æï¼‰ï¼š\n\n{variables.get('file_content', '')}"

        return MockResult()

class MockTemplate:
    """Mockæ¨¡æ¿"""
    def render(self, variables):
        return f"Mock rendered template with {variables}"

def test_deep_analyzer_initialization():
    """æµ‹è¯•DeepAnalyzeråˆå§‹åŒ–"""
    print("ğŸ” æµ‹è¯•DeepAnalyzeråˆå§‹åŒ–...")

    try:
        from src.tools.deep_analyzer import DeepAnalyzer, DeepAnalysisRequest, DeepAnalysisResult

        # Mock LLMå®¢æˆ·ç«¯å’ŒPromptç®¡ç†å™¨
        with patch('src.tools.deep_analyzer.LLMClient', MockLLMClient), \
             patch('src.tools.deep_analyzer.PromptManager', MockPromptManager):

            # æµ‹è¯•æ— å‚åˆå§‹åŒ–
            analyzer = DeepAnalyzer()
            print("âœ… DeepAnalyzer é»˜è®¤åˆå§‹åŒ–æˆåŠŸ")

            # æµ‹è¯•è·å–æ”¯æŒçš„åˆ†æç±»å‹
            supported_types = analyzer.get_supported_analysis_types()
            print(f"âœ… æ”¯æŒçš„åˆ†æç±»å‹: {supported_types}")

            # æµ‹è¯•é…ç½®
            print(f"   - é»˜è®¤æ¨¡å‹: {analyzer.default_model}")
            print(f"   - é»˜è®¤æ¸©åº¦: {analyzer.default_temperature}")
            print(f"   - æœ€å¤§tokens: {analyzer.max_tokens}")
            print(f"   - æœ€å¤§æ–‡ä»¶å¤§å°: {analyzer.max_file_size} bytes")

            return analyzer

    except Exception as e:
        print(f"âŒ DeepAnalyzer åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def test_deep_analysis_request_creation():
    """æµ‹è¯•DeepAnalysisRequeståˆ›å»º"""
    print("\nğŸ” æµ‹è¯•DeepAnalysisRequeståˆ›å»º...")

    try:
        from src.tools.deep_analyzer import DeepAnalysisRequest

        # åˆ›å»ºè¯·æ±‚å¯¹è±¡
        request = DeepAnalysisRequest(
            file_path="test_file.py",
            analysis_type="comprehensive",
            temperature=0.3,
            max_tokens=4000,
            user_instructions="è¯·åˆ†æè¿™ä¸ªä»£ç çš„è´¨é‡"
        )

        print("âœ… DeepAnalysisRequest åˆ›å»ºæˆåŠŸ")
        print(f"   - æ–‡ä»¶è·¯å¾„: {request.file_path}")
        print(f"   - åˆ†æç±»å‹: {request.analysis_type}")
        print(f"   - æ¸©åº¦: {request.temperature}")
        print(f"   - æœ€å¤§tokens: {request.max_tokens}")
        print(f"   - ç”¨æˆ·æŒ‡ä»¤: {request.user_instructions}")

        return request

    except Exception as e:
        print(f"âŒ DeepAnalysisRequest åˆ›å»ºå¤±è´¥: {e}")
        return None

def test_file_reading():
    """æµ‹è¯•æ–‡ä»¶è¯»å–åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•æ–‡ä»¶è¯»å–åŠŸèƒ½...")

    try:
        from src.tools.deep_analyzer import DeepAnalyzer

        # Mock LLMå®¢æˆ·ç«¯å’ŒPromptç®¡ç†å™¨
        with patch('src.tools.deep_analyzer.LLMClient', MockLLMClient), \
             patch('src.tools.deep_analyzer.PromptManager', MockPromptManager):

            analyzer = DeepAnalyzer()

            # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
            test_file = Path("test_sample.py")
            test_content = '''def calculate_fibonacci(n):
    """è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—"""
    if n <= 1:
        return n
    return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)

def main():
    for i in range(10):
        print(f"F({i}) = {calculate_fibonacci(i)}")

if __name__ == "__main__":
    main()
'''

            with open(test_file, 'w', encoding='utf-8') as f:
                f.write(test_content)

            # æµ‹è¯•è¯»å–æ–‡ä»¶
            content = analyzer._read_file_content(test_file)

            if content:
                print("âœ… æ–‡ä»¶è¯»å–æˆåŠŸ")
                print(f"   - æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
                print(f"   - å†…å®¹é¢„è§ˆ: {content[:100]}...")

                # æ¸…ç†æµ‹è¯•æ–‡ä»¶
                test_file.unlink()
                return content
            else:
                print("âŒ æ–‡ä»¶è¯»å–å¤±è´¥")
                return None

    except Exception as e:
        print(f"âŒ æ–‡ä»¶è¯»å–æµ‹è¯•å¤±è´¥: {e}")
        return None

def test_prompt_construction():
    """æµ‹è¯•Promptæ„é€ åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•Promptæ„é€ åŠŸèƒ½...")

    try:
        from src.tools.deep_analyzer import DeepAnalyzer, DeepAnalysisRequest

        # Mock LLMå®¢æˆ·ç«¯å’ŒPromptç®¡ç†å™¨
        with patch('src.tools.deep_analyzer.LLMClient', MockLLMClient), \
             patch('src.tools.deep_analyzer.PromptManager', MockPromptManager):

            analyzer = DeepAnalyzer()

            # åˆ›å»ºæµ‹è¯•è¯·æ±‚
            request = DeepAnalysisRequest(
                file_path="test_file.py",
                analysis_type="comprehensive",
                user_instructions="è¯·é‡ç‚¹å…³æ³¨ä»£ç çš„å¯è¯»æ€§å’Œæ€§èƒ½"
            )

            test_content = '''def hello_world():
    print("Hello, World!")
'''

            # æ„é€ prompt
            messages = analyzer._construct_prompt(test_content, request)

            if messages:
                print("âœ… Promptæ„é€ æˆåŠŸ")
                print(f"   - æ¶ˆæ¯æ•°é‡: {len(messages)}")
                for i, msg in enumerate(messages):
                    print(f"   - æ¶ˆæ¯ {i+1}: {msg['role']} (é•¿åº¦: {len(msg['content'])})")
                    if i == 0:  # ç³»ç»Ÿæ¶ˆæ¯
                        print(f"     å†…å®¹é¢„è§ˆ: {msg['content'][:100]}...")

                return messages
            else:
                print("âŒ Promptæ„é€ å¤±è´¥")
                return None

    except Exception as e:
        print(f"âŒ Promptæ„é€ æµ‹è¯•å¤±è´¥: {e}")
        return None

def test_response_parsing():
    """æµ‹è¯•å“åº”è§£æåŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•å“åº”è§£æåŠŸèƒ½...")

    try:
        from src.tools.deep_analyzer import DeepAnalyzer

        # Mock LLMå®¢æˆ·ç«¯å’ŒPromptç®¡ç†å™¨
        with patch('src.tools.deep_analyzer.LLMClient', MockLLMClient), \
             patch('src.tools.deep_analyzer.PromptManager', MockPromptManager):

            analyzer = DeepAnalyzer()

            # æµ‹è¯•JSONæ ¼å¼å“åº”
            json_response = '''{
    "summary": "ä»£ç è´¨é‡è‰¯å¥½ï¼Œä½†æœ‰ä¸€äº›æ”¹è¿›å»ºè®®",
    "issues": [
        {
            "type": "style",
            "line": 2,
            "message": "å»ºè®®æ·»åŠ ç±»å‹æ³¨è§£"
        }
    ],
    "recommendations": [
        "æ·»åŠ ç±»å‹æ³¨è§£",
        "æ·»åŠ é”™è¯¯å¤„ç†"
    ]
}'''

            parsed = analyzer._parse_llm_response(json_response)
            print("âœ… JSONå“åº”è§£ææˆåŠŸ")
            print(f"   - è§£ææ ¼å¼: {parsed.get('format', 'unknown')}")
            print(f"   - æ‘˜è¦: {parsed.get('summary', '')[:50]}...")

            # æµ‹è¯•æ–‡æœ¬æ ¼å¼å“åº”
            text_response = """è¿™æ˜¯ä¸€ä¸ªç®€å•çš„ä»£ç åˆ†ææŠ¥å‘Šï¼š

1. æ€»ä½“è¯„ä¼°ï¼šä»£ç ç»“æ„æ¸…æ™°
2. å‘ç°é—®é¢˜ï¼šæ— é”™è¯¯å¤„ç†
3. æ”¹è¿›å»ºè®®ï¼šæ·»åŠ å¼‚å¸¸å¤„ç†æœºåˆ¶

å»ºè®®é‡æ„ä»¥æé«˜ä»£ç å¥å£®æ€§ã€‚"""

            parsed_text = analyzer._parse_llm_response(text_response)
            print("âœ… æ–‡æœ¬å“åº”è§£ææˆåŠŸ")
            print(f"   - è§£ææ ¼å¼: {parsed_text.get('format', 'unknown')}")
            print(f"   - æ‘˜è¦: {parsed_text.get('summary', '')[:50]}...")

            return True

    except Exception as e:
        print(f"âŒ å“åº”è§£ææµ‹è¯•å¤±è´¥: {e}")
        return False

def test_result_formatting():
    """æµ‹è¯•ç»“æœæ ¼å¼åŒ–åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•ç»“æœæ ¼å¼åŒ–åŠŸèƒ½...")

    try:
        from src.tools.deep_analyzer import DeepAnalyzer, DeepAnalysisResult

        # Mock LLMå®¢æˆ·ç«¯å’ŒPromptç®¡ç†å™¨
        with patch('src.tools.deep_analyzer.LLMClient', MockLLMClient), \
             patch('src.tools.deep_analyzer.PromptManager', MockPromptManager):

            analyzer = DeepAnalyzer()

            # åˆ›å»ºæµ‹è¯•ç»“æœ
            result = DeepAnalysisResult(
                file_path="test_file.py",
                analysis_type="comprehensive",
                success=True,
                content="è¿™æ˜¯ä¸€ä¸ªåˆ†æç»“æœç¤ºä¾‹",
                structured_analysis={
                    "summary": "ä»£ç è´¨é‡è‰¯å¥½",
                    "issues": [],
                    "recommendations": ["æ·»åŠ æ–‡æ¡£"]
                },
                execution_time=1.23,
                model_used="glm-4.5",
                token_usage={"total_tokens": 500}
            )

            # æµ‹è¯•æ–‡æœ¬æ ¼å¼åŒ–
            text_output = analyzer.format_analysis_result(result, "text")
            print("âœ… æ–‡æœ¬æ ¼å¼åŒ–æˆåŠŸ")
            print(f"   - è¾“å‡ºé•¿åº¦: {len(text_output)} å­—ç¬¦")
            print(f"   - é¢„è§ˆ: {text_output[:100]}...")

            # æµ‹è¯•JSONæ ¼å¼åŒ–
            json_output = analyzer.format_analysis_result(result, "json")
            print("âœ… JSONæ ¼å¼åŒ–æˆåŠŸ")
            print(f"   - è¾“å‡ºé•¿åº¦: {len(json_output)} å­—ç¬¦")

            # æµ‹è¯•Markdownæ ¼å¼åŒ–
            md_output = analyzer.format_analysis_result(result, "markdown")
            print("âœ… Markdownæ ¼å¼åŒ–æˆåŠŸ")
            print(f"   - è¾“å‡ºé•¿åº¦: {len(md_output)} å­—ç¬¦")

            return True

    except Exception as e:
        print(f"âŒ ç»“æœæ ¼å¼åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_file_analysis():
    """æµ‹è¯•å®Œæ•´çš„æ–‡ä»¶åˆ†ææµç¨‹"""
    print("\nğŸ” æµ‹è¯•å®Œæ•´çš„æ–‡ä»¶åˆ†ææµç¨‹...")

    try:
        from src.tools.deep_analyzer import DeepAnalyzer, DeepAnalysisRequest
        import asyncio

        # Mock LLMå®¢æˆ·ç«¯å’ŒPromptç®¡ç†å™¨
        with patch('src.tools.deep_analyzer.LLMClient', MockLLMClient), \
             patch('src.tools.deep_analyzer.PromptManager', MockPromptManager):

            analyzer = DeepAnalyzer()

            # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
            test_file = Path("test_analysis_sample.py")
            test_content = '''def calculate_average(numbers):
    """è®¡ç®—æ•°å­—åˆ—è¡¨çš„å¹³å‡å€¼"""
    if not numbers:
        return 0
    return sum(numbers) / len(numbers)

def find_duplicates(items):
    """æŸ¥æ‰¾åˆ—è¡¨ä¸­çš„é‡å¤é¡¹"""
    seen = set()
    duplicates = []
    for item in items:
        if item in seen:
            duplicates.append(item)
        seen.add(item)
    return duplicates

def main():
    numbers = [1, 2, 3, 4, 5, 2, 3]
    avg = calculate_average(numbers)
    dups = find_duplicates(numbers)
    print(f"å¹³å‡å€¼: {avg}")
    print(f"é‡å¤é¡¹: {dups}")

if __name__ == "__main__":
    main()
'''

            with open(test_file, 'w', encoding='utf-8') as f:
                f.write(test_content)

            # åˆ›å»ºåˆ†æè¯·æ±‚
            request = DeepAnalysisRequest(
                file_path=str(test_file),
                analysis_type="comprehensive",
                user_instructions="è¯·é‡ç‚¹å…³æ³¨ä»£ç è´¨é‡å’Œæ€§èƒ½ä¼˜åŒ–"
            )

            # æ‰§è¡Œåˆ†æï¼ˆä½¿ç”¨asyncioè¿è¡Œå¼‚æ­¥å‡½æ•°ï¼‰
            print("   å¼€å§‹åˆ†æ...")

            async def run_analysis():
                return await analyzer.analyze_file(request)

            result = asyncio.run(run_analysis())

            if result.success:
                print("âœ… æ–‡ä»¶åˆ†ææˆåŠŸ")
                print(f"   - åˆ†ææ–‡ä»¶: {result.file_path}")
                print(f"   - åˆ†æç±»å‹: {result.analysis_type}")
                print(f"   - æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")
                print(f"   - ä½¿ç”¨æ¨¡å‹: {result.model_used}")
                print(f"   - Tokenä½¿ç”¨: {result.token_usage}")
                print(f"   - å†…å®¹é•¿åº¦: {len(result.content)} å­—ç¬¦")

                # æ¸…ç†æµ‹è¯•æ–‡ä»¶
                test_file.unlink()
                return result
            else:
                print(f"âŒ æ–‡ä»¶åˆ†æå¤±è´¥: {result.error}")
                test_file.unlink()
                return None

    except Exception as e:
        print(f"âŒ æ–‡ä»¶åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return None

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹DeepAnalyzeræ ¸å¿ƒåŠŸèƒ½æµ‹è¯•ï¼ˆMockç‰ˆæœ¬ï¼‰")
    print("=" * 60)

    test_results = []

    # 1. æµ‹è¯•åˆå§‹åŒ–
    analyzer = test_deep_analyzer_initialization()
    test_results.append(analyzer is not None)

    # 2. æµ‹è¯•è¯·æ±‚åˆ›å»º
    request = test_deep_analysis_request_creation()
    test_results.append(request is not None)

    # 3. æµ‹è¯•æ–‡ä»¶è¯»å–
    content = test_file_reading()
    test_results.append(content is not None)

    # 4. æµ‹è¯•Promptæ„é€ 
    messages = test_prompt_construction()
    test_results.append(messages is not None)

    # 5. æµ‹è¯•å“åº”è§£æ
    parsing_ok = test_response_parsing()
    test_results.append(parsing_ok)

    # 6. æµ‹è¯•ç»“æœæ ¼å¼åŒ–
    formatting_ok = test_result_formatting()
    test_results.append(formatting_ok)

    # 7. æµ‹è¯•å®Œæ•´åˆ†ææµç¨‹
    print("\nğŸ” æµ‹è¯•å¼‚æ­¥åˆ†ææµç¨‹...")
    try:
        result = asyncio.run(test_file_analysis())
        test_results.append(result is not None)
    except Exception as e:
        print(f"âŒ å¼‚æ­¥åˆ†ææµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        test_results.append(False)

    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")

    passed = sum(test_results)
    total = len(test_results)

    print(f"âœ… é€šè¿‡: {passed}/{total}")
    print(f"âŒ å¤±è´¥: {total-passed}/{total}")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰DeepAnalyzeræ ¸å¿ƒåŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("æ·±åº¦åˆ†æåŸºç¡€åŠŸèƒ½å·²å°±ç»ªï¼Œå¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥æµ‹è¯•ã€‚")
        return 0
    else:
        print(f"\nâš ï¸ æœ‰ {total-passed} é¡¹æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
        return 1

if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        sys.exit(0)
    except Exception as e:
        print(f"\næµ‹è¯•å¼‚å¸¸: {e}")
        sys.exit(1)