#!/usr/bin/env python3
"""
æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡åŠŸèƒ½æµ‹è¯•è„šæœ¬
éªŒè¯é¡¹ç›®ä¸­çš„æ€§èƒ½ç›‘æ§ã€æ—¶é—´è·Ÿè¸ªã€ç»Ÿè®¡è®°å½•ç­‰åŠŸèƒ½
"""

import sys
import os
import time
import json
import tempfile
import psutil
from pathlib import Path
from unittest.mock import Mock, patch
from datetime import datetime, timedelta
from typing import Dict, List, Any

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_progress_tracker_performance():
    """æµ‹è¯•è¿›åº¦è·Ÿè¸ªå™¨æ€§èƒ½ç›‘æ§"""
    print("ğŸ” æµ‹è¯•è¿›åº¦è·Ÿè¸ªå™¨æ€§èƒ½ç›‘æ§...")

    try:
        from src.utils.progress import ProgressTracker

        # åˆ›å»ºè¿›åº¦è·Ÿè¸ªå™¨
        progress = ProgressTracker(
            total_files=10,
            show_progress=True,
            detailed=True
        )

        print("   æµ‹è¯•åŸºæœ¬æ—¶é—´è·Ÿè¸ª:")
        start_time = time.time()

        # æ¨¡æ‹Ÿæ–‡ä»¶åˆ†æè¿‡ç¨‹
        for i in range(10):
            time.sleep(0.01)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            progress.add_file()
            if i % 3 == 0:  # æ¯3ä¸ªæ–‡ä»¶å‘ç°ä¸€ä¸ªé—®é¢˜
                progress.add_issue()

        elapsed_time = time.time() - start_time
        print(f"     - æ¨¡æ‹Ÿåˆ†æå®Œæˆæ—¶é—´: {elapsed_time:.3f}s")

        # è·å–æ‘˜è¦ä¿¡æ¯
        summary = progress.get_summary()
        print("   è¿›åº¦è·Ÿè¸ªæ‘˜è¦:")
        print(f"     - æ€»æ–‡ä»¶æ•°: {summary.get('total_files', 0)}")
        print(f"     - å¤„ç†æ–‡ä»¶æ•°: {summary.get('processed_files', 0)}")
        print(f"     - å‘ç°é—®é¢˜æ•°: {summary.get('total_issues', 0)}")
        print(f"     - æ€»è€—æ—¶: {summary.get('total_time', 0):.3f}s")
        print(f"     - å¹³å‡å¤„ç†é€Ÿåº¦: {summary.get('files_per_second', 0):.1f} æ–‡ä»¶/ç§’")

        # éªŒè¯æ€§èƒ½æŒ‡æ ‡åˆç†æ€§
        files_per_second = summary.get('files_per_second', 0)
        performance_reasonable = files_per_second > 0 and files_per_second < 1000
        print(f"     - æ€§èƒ½æŒ‡æ ‡åˆç†æ€§: {'âœ…' if performance_reasonable else 'âŒ'}")

        # æµ‹è¯•è¿›åº¦è·Ÿè¸ªå™¨ç¼“å­˜
        print("\n   æµ‹è¯•è¿›åº¦è·Ÿè¸ªå™¨ç¼“å­˜:")
        progress2 = ProgressTracker(
            total_files=5,
            show_progress=False,
            detailed=False
        )

        start_time = time.time()
        for i in range(5):
            progress2.add_file()
            time.sleep(0.005)

        summary2 = progress2.get_summary()
        elapsed_time2 = time.time() - start_time

        speed_comparison = summary2.get('files_per_second', 0) > summary.get('files_per_second', 0)
        print(f"     - ç®€åŒ–æ¨¡å¼æ€§èƒ½æå‡: {'âœ…' if speed_comparison else 'âŒ'}")
        print(f"     - ç®€åŒ–æ¨¡å¼å¤„ç†é€Ÿåº¦: {summary2.get('files_per_second', 0):.1f} æ–‡ä»¶/ç§’")

        return performance_reasonable and len(summary) > 0

    except Exception as e:
        print(f"âŒ è¿›åº¦è·Ÿè¸ªå™¨æ€§èƒ½ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_logger_performance_monitoring():
    """æµ‹è¯•æ—¥å¿—ç³»ç»Ÿæ€§èƒ½ç›‘æ§"""
    print("\nğŸ” æµ‹è¯•æ—¥å¿—ç³»ç»Ÿæ€§èƒ½ç›‘æ§...")

    try:
        from src.utils.logger import get_logger

        logger = get_logger()

        print("   æµ‹è¯•APIè¯·æ±‚æ—¥å¿—è®°å½•:")
        # æ¨¡æ‹ŸAPIè¯·æ±‚æ—¥å¿—è®°å½•
        start_time = time.time()

        logger.log_api_request(
            api_type="LLM",
            endpoint="/analyze",
            status="success",
            response_time=0.234,
            model="glm-4.5",
            tokens=150
        )

        logger.log_api_request(
            api_type="Static Analysis",
            endpoint="/pylint",
            status="success",
            response_time=0.089,
            file_count=5
        )

        api_log_time = time.time() - start_time
        print(f"     - APIæ—¥å¿—è®°å½•æ—¶é—´: {api_log_time:.3f}s")

        print("\n   æµ‹è¯•æ–‡ä»¶æ“ä½œæ—¥å¿—è®°å½•:")
        start_time = time.time()

        # æ¨¡æ‹Ÿæ–‡ä»¶æ“ä½œæ—¥å¿—
        logger.log_file_operation(
            operation="read",
            file_path="test.py",
            file_size=1024,
            success=True
        )

        logger.log_file_operation(
            operation="write",
            file_path="output.json",
            file_size=2048,
            success=True
        )

        file_log_time = time.time() - start_time
        print(f"     - æ–‡ä»¶æ“ä½œæ—¥å¿—è®°å½•æ—¶é—´: {file_log_time:.3f}s")

        print("\n   æµ‹è¯•åˆ†æç»“æœæ—¥å¿—è®°å½•:")
        start_time = time.time()

        # æ¨¡æ‹Ÿåˆ†æç»“æœæ—¥å¿—
        logger.log_analysis_result(
            analysis_type="comprehensive",
            file_path="sample.py",
            result={
                "issues_found": 3,
                "score": 8.5,
                "execution_time": 1.234
            },
            success=True
        )

        analysis_log_time = time.time() - start_time
        print(f"     - åˆ†æç»“æœæ—¥å¿—è®°å½•æ—¶é—´: {analysis_log_time:.3f}s")

        print("\n   æµ‹è¯•æ‰¹é‡æ—¥å¿—æ€§èƒ½:")
        # æµ‹è¯•æ‰¹é‡æ—¥å¿—è®°å½•æ€§èƒ½
        log_count = 100
        start_time = time.time()

        for i in range(log_count):
            logger.info(f"Test log entry {i}")
            if i % 10 == 0:
                logger.warning(f"Warning message {i}")

        batch_log_time = time.time() - start_time
        logs_per_second = log_count / batch_log_time
        print(f"     - æ‰¹é‡æ—¥å¿—æ€§èƒ½: {logs_per_second:.0f} æ¡/ç§’")
        print(f"     - æ€»æ—¥å¿—æ•°: {log_count}")
        print(f"     - æ€»è€—æ—¶: {batch_log_time:.3f}s")

        # æ€§èƒ½åŸºå‡†æµ‹è¯•
        performance_good = (
            api_log_time < 0.01 and
            file_log_time < 0.01 and
            analysis_log_time < 0.01 and
            logs_per_second > 1000
        )

        print(f"     - æ—¥å¿—æ€§èƒ½è¯„ä¼°: {'âœ… ä¼˜ç§€' if performance_good else 'âŒ éœ€ä¼˜åŒ–'}")
        return performance_good

    except Exception as e:
        print(f"âŒ æ—¥å¿—ç³»ç»Ÿæ€§èƒ½ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cache_performance_monitoring():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½ç›‘æ§"""
    print("\nğŸ” æµ‹è¯•ç¼“å­˜æ€§èƒ½ç›‘æ§...")

    try:
        from src.utils.cache import CacheManager

        cache = CacheManager()

        print("   æµ‹è¯•ç¼“å­˜ç»Ÿè®¡åŠŸèƒ½:")
        # åˆå§‹ç»Ÿè®¡
        initial_stats = cache.get_stats()
        print(f"     - åˆå§‹ç¼“å­˜å¤§å°: {initial_stats.get('size', 0)}")
        print(f"     - åˆå§‹æ€»å­—èŠ‚æ•°: {initial_stats.get('total_size_bytes', 0)}")

        # æ·»åŠ æµ‹è¯•æ•°æ®
        test_data = []
        for i in range(100):
            data = {
                'id': i,
                'content': f'test_content_{i}',
                'metadata': {
                    'created_at': datetime.now().isoformat(),
                    'size': len(f'test_content_{i}') * 10,
                    'tags': [f'tag_{j}' for j in range(3)]
                }
            }
            test_data.append(data)
            cache.set(f"cache_key_{i}", data, ttl=300)

        # è·å–ç¼“å­˜ç»Ÿè®¡
        stats_after_write = cache.get_stats()
        print(f"     - å†™å…¥åç¼“å­˜å¤§å°: {stats_after_write.get('size', 0)}")
        print(f"     - å†™å…¥åæ€»å­—èŠ‚æ•°: {stats_after_write.get('total_size_bytes', 0)}")
        print(f"     - åç«¯ç±»å‹: {stats_after_write.get('backend_type', 'unknown')}")

        # æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡
        print("\n   æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡:")
        cache_hits = 0
        cache_misses = 0

        # ç¬¬ä¸€æ¬¡è®¿é—®ï¼ˆåº”è¯¥å…¨éƒ¨å‘½ä¸­ï¼‰
        start_time = time.time()
        for i in range(100):
            result = cache.get(f"cache_key_{i}")
            if result is not None:
                cache_hits += 1
            else:
                cache_misses += 1
        read_time = time.time() - start_time

        hit_rate = cache_hits / (cache_hits + cache_misses) if (cache_hits + cache_misses) > 0 else 0
        print(f"     - ç¼“å­˜å‘½ä¸­æ•°: {cache_hits}")
        print(f"     - ç¼“å­˜æœªå‘½ä¸­æ•°: {cache_misses}")
        print(f"     - å‘½ä¸­ç‡: {hit_rate:.1%}")
        print(f"     - è¯»å–æ€§èƒ½: {100/read_time:.0f} æ¬¡/ç§’")

        # æµ‹è¯•è¿‡æœŸç¼“å­˜æ¸…ç†
        print("\n   æµ‹è¯•è¿‡æœŸç¼“å­˜æ¸…ç†ç»Ÿè®¡:")
        # æ·»åŠ çŸ­æœŸç¼“å­˜
        for i in range(10):
            cache.set(f"short_lived_{i}", f"value_{i}", ttl=1)

        # ç­‰å¾…è¿‡æœŸ
        time.sleep(2)

        # æ¸…ç†è¿‡æœŸç¼“å­˜
        cleaned_count = cache.cleanup_expired()
        stats_after_cleanup = cache.get_stats()

        print(f"     - æ¸…ç†è¿‡æœŸé¡¹æ•°: {cleaned_count}")
        print(f"     - æ¸…ç†åç¼“å­˜å¤§å°: {stats_after_cleanup.get('size', 0)}")

        # æ€§èƒ½éªŒè¯
        performance_valid = (
            stats_after_write.get('size', 0) == 100 and
            hit_rate >= 0.9 and
            cleaned_count >= 5
        )

        print(f"     - ç¼“å­˜æ€§èƒ½éªŒè¯: {'âœ…' if performance_valid else 'âŒ'}")
        return performance_valid

    except Exception as e:
        print(f"âŒ ç¼“å­˜æ€§èƒ½ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_execution_engine_monitoring():
    """æµ‹è¯•æ‰§è¡Œå¼•æ“ç›‘æ§"""
    print("\nğŸ” æµ‹è¯•æ‰§è¡Œå¼•æ“ç›‘æ§...")

    try:
        from src.agent.execution_engine import ExecutionEngine, ExecutionResult

        # åˆ›å»ºæ‰§è¡Œå¼•æ“
        engine = ExecutionEngine()

        print("   æµ‹è¯•æ‰§è¡Œæ—¶é—´è·Ÿè¸ª:")
        # æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œ
        def mock_tool_execution(task_data):
            """æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œ"""
            time.sleep(0.05)  # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´
            return {
                'status': 'success',
                'result': f"Processed: {task_data.get('input', 'default')}",
                'output_size': 1024
            }

        # æ‰§è¡Œå¤šä¸ªä»»åŠ¡
        execution_times = []
        results = []

        for i in range(5):
            task_data = {'input': f'task_{i}', 'tool': 'mock_tool'}

            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()

            # æ‰§è¡Œä»»åŠ¡
            result = engine.execute_tool('mock_tool', task_data, mock_tool_execution)

            # è®°å½•ç»“æŸæ—¶é—´
            end_time = time.time()
            execution_time = end_time - start_time

            execution_times.append(execution_time)
            results.append(result)

        print(f"     - æ‰§è¡Œä»»åŠ¡æ•°: {len(results)}")
        print(f"     - å¹³å‡æ‰§è¡Œæ—¶é—´: {sum(execution_times)/len(execution_times):.3f}s")
        print(f"     - æœ€å¿«æ‰§è¡Œæ—¶é—´: {min(execution_times):.3f}s")
        print(f"     - æœ€æ…¢æ‰§è¡Œæ—¶é—´: {max(execution_times):.3f}s")

        # æµ‹è¯•æ‰§è¡Œç»Ÿè®¡åŠŸèƒ½
        print("\n   æµ‹è¯•æ‰§è¡Œç»Ÿè®¡åŠŸèƒ½:")
        if hasattr(engine, 'get_statistics'):
            stats = engine.get_statistics()
            print("     - æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯:")
            for key, value in stats.items():
                print(f"       {key}: {value}")
        else:
            print("     - æ‰§è¡Œå¼•æ“ä¸æ”¯æŒç»Ÿè®¡åŠŸèƒ½")

        # æµ‹è¯•å¹¶å‘æ‰§è¡Œç›‘æ§
        print("\n   æµ‹è¯•å¹¶å‘æ‰§è¡Œç›‘æ§:")
        start_time = time.time()

        # æ¨¡æ‹Ÿå¹¶å‘æ‰§è¡Œ
        concurrent_tasks = []
        for i in range(3):
            task_data = {'input': f'concurrent_task_{i}', 'tool': 'mock_tool'}
            result = engine.execute_tool('mock_tool', task_data, mock_tool_execution)
            concurrent_tasks.append(result)

        concurrent_time = time.time() - start_time
        print(f"     - å¹¶å‘ä»»åŠ¡æ•°: {len(concurrent_tasks)}")
        print(f"     - å¹¶å‘æ‰§è¡Œæ€»æ—¶é—´: {concurrent_time:.3f}s")
        print(f"     - å¹³å‡å¹¶å‘æ—¶é—´: {concurrent_time/len(concurrent_tasks):.3f}s")

        # æ€§èƒ½éªŒè¯
        performance_valid = (
            len(execution_times) == 5 and
            all(t > 0 for t in execution_times) and
            len(concurrent_tasks) == 3
        )

        print(f"     - æ‰§è¡Œå¼•æ“ç›‘æ§éªŒè¯: {'âœ…' if performance_valid else 'âŒ'}")
        return performance_valid

    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¼•æ“ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_orchestrator_session_monitoring():
    """æµ‹è¯•ç¼–æ’å™¨ä¼šè¯ç›‘æ§"""
    print("\nğŸ” æµ‹è¯•ç¼–æ’å™¨ä¼šè¯ç›‘æ§...")

    try:
        from src.agent.orchestrator import SessionManager, SessionState

        # åˆ›å»ºä¼šè¯ç®¡ç†å™¨
        session_manager = SessionManager()

        print("   æµ‹è¯•ä¼šè¯åˆ›å»ºå’Œç»Ÿè®¡:")
        # åˆ›å»ºå¤šä¸ªä¼šè¯
        session_ids = []
        for i in range(3):
            session_id = session_manager.create_session(
                user_id=f"user_{i}",
                session_type="deep_analysis"
            )
            session_ids.append(session_id)

            # æ·»åŠ ä¸€äº›æ´»åŠ¨
            session_manager.add_message(session_id, {
                'role': 'user',
                'content': f'Test message {i}',
                'timestamp': datetime.now().isoformat()
            })

            time.sleep(0.01)  # æ¨¡æ‹Ÿä¼šè¯æ´»åŠ¨é—´éš”

        print(f"     - åˆ›å»ºä¼šè¯æ•°: {len(session_ids)}")

        # æµ‹è¯•ä¼šè¯ç»Ÿè®¡
        print("\n   æµ‹è¯•ä¼šè¯ç»Ÿè®¡åŠŸèƒ½:")
        if hasattr(session_manager, 'get_session_statistics'):
            stats = session_manager.get_session_statistics()
            print("     - ä¼šè¯ç»Ÿè®¡ä¿¡æ¯:")
            print(f"       - æ€»ä¼šè¯æ•°: {stats.get('total_sessions', 0)}")
            print(f"       - æ´»è·ƒä¼šè¯æ•°: {stats.get('active_sessions', 0)}")
            print(f"       - å¹³å‡ä¼šè¯æ—¶é•¿: {stats.get('avg_session_duration', 0):.3f}s")
            print(f"       - æ€»æ¶ˆæ¯æ•°: {stats.get('total_messages', 0)}")

        # æµ‹è¯•å•ä¸ªä¼šè¯ç»Ÿè®¡
        print("\n   æµ‹è¯•å•ä¸ªä¼šè¯ç»Ÿè®¡:")
        if session_ids:
            session_id = session_ids[0]
            session_info = session_manager.get_session_info(session_id)

            if session_info:
                print(f"     - ä¼šè¯ID: {session_id}")
                print(f"     - ä¼šè¯çŠ¶æ€: {session_info.get('state', 'unknown')}")
                print(f"     - æ¶ˆæ¯æ•°é‡: {len(session_info.get('messages', []))}")
                print(f"     - åˆ›å»ºæ—¶é—´: {session_info.get('created_at', 'unknown')}")

        # æµ‹è¯•ä¼šè¯æ¸…ç†ç›‘æ§
        print("\n   æµ‹è¯•ä¼šè¯æ¸…ç†ç›‘æ§:")
        # æ¨¡æ‹Ÿä¼šè¯è¶…æ—¶
        time.sleep(0.1)

        # æ¸…ç†è¿‡æœŸä¼šè¯ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if hasattr(session_manager, 'cleanup_expired_sessions'):
            cleaned_count = session_manager.cleanup_expired_sessions()
            print(f"     - æ¸…ç†è¿‡æœŸä¼šè¯æ•°: {cleaned_count}")

        # æ€§èƒ½éªŒè¯
        performance_valid = (
            len(session_ids) == 3 and
            session_manager is not None
        )

        print(f"     - ä¼šè¯ç›‘æ§éªŒè¯: {'âœ…' if performance_valid else 'âŒ'}")
        return performance_valid

    except Exception as e:
        print(f"âŒ ç¼–æ’å™¨ä¼šè¯ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_system_resource_monitoring():
    """æµ‹è¯•ç³»ç»Ÿèµ„æºç›‘æ§"""
    print("\nğŸ” æµ‹è¯•ç³»ç»Ÿèµ„æºç›‘æ§...")

    try:
        print("   æµ‹è¯•CPUä½¿ç”¨ç‡ç›‘æ§:")
        # è·å–CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        cpu_count = psutil.cpu_count()
        print(f"     - CPUä½¿ç”¨ç‡: {cpu_percent:.1f}%")
        print(f"     - CPUæ ¸å¿ƒæ•°: {cpu_count}")

        print("\n   æµ‹è¯•å†…å­˜ä½¿ç”¨ç›‘æ§:")
        # è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory = psutil.virtual_memory()
        print(f"     - æ€»å†…å­˜: {memory.total // (1024**3)} GB")
        print(f"     - å·²ä½¿ç”¨å†…å­˜: {memory.used // (1024**3)} GB")
        print(f"     - å†…å­˜ä½¿ç”¨ç‡: {memory.percent:.1f}%")
        print(f"     - å¯ç”¨å†…å­˜: {memory.available // (1024**3)} GB")

        print("\n   æµ‹è¯•ç£ç›˜ä½¿ç”¨ç›‘æ§:")
        # è·å–ç£ç›˜ä½¿ç”¨æƒ…å†µ
        disk = psutil.disk_usage('.')
        print(f"     - æ€»ç£ç›˜ç©ºé—´: {disk.total // (1024**3)} GB")
        print(f"     - å·²ä½¿ç”¨ç£ç›˜: {disk.used // (1024**3)} GB")
        print(f"     - ç£ç›˜ä½¿ç”¨ç‡: {disk.percent:.1f}%")
        print(f"     - å¯ç”¨ç£ç›˜ç©ºé—´: {disk.free // (1024**3)} GB")

        print("\n   æµ‹è¯•è¿›ç¨‹ç›‘æ§:")
        # è·å–å½“å‰è¿›ç¨‹ä¿¡æ¯
        process = psutil.Process()
        process_info = {
            'pid': process.pid,
            'name': process.name(),
            'cpu_percent': process.cpu_percent(),
            'memory_info': process.memory_info(),
            'create_time': process.create_time(),
            'num_threads': process.num_threads()
        }

        print(f"     - è¿›ç¨‹PID: {process_info['pid']}")
        print(f"     - è¿›ç¨‹åç§°: {process_info['name']}")
        print(f"     - è¿›ç¨‹CPUä½¿ç”¨ç‡: {process_info['cpu_percent']:.1f}%")
        print(f"     - è¿›ç¨‹å†…å­˜ä½¿ç”¨: {process_info['memory_info'].rss // (1024**2)} MB")
        print(f"     - è¿›ç¨‹çº¿ç¨‹æ•°: {process_info['num_threads']}")

        print("\n   æµ‹è¯•ç½‘ç»œç›‘æ§:")
        # è·å–ç½‘ç»œç»Ÿè®¡
        network = psutil.net_io_counters()
        print(f"     - å‘é€å­—èŠ‚æ•°: {network.bytes_sent // (1024**2)} MB")
        print(f"     - æ¥æ”¶å­—èŠ‚æ•°: {network.bytes_recv // (1024**2)} MB")
        print(f"     - å‘é€åŒ…æ•°: {network.packets_sent}")
        print(f"     - æ¥æ”¶åŒ…æ•°: {network.packets_recv}")

        # èµ„æºä½¿ç”¨åˆç†æ€§éªŒè¯
        resource_reasonable = (
            0 <= cpu_percent <= 100 and
            0 <= memory.percent <= 100 and
            0 <= disk.percent <= 100 and
            process_info['memory_info'].rss > 0
        )

        print(f"     - èµ„æºç›‘æ§éªŒè¯: {'âœ…' if resource_reasonable else 'âŒ'}")
        return resource_reasonable

    except Exception as e:
        print(f"âŒ ç³»ç»Ÿèµ„æºç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_performance_metrics_aggregation():
    """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡èšåˆ"""
    print("\nğŸ” æµ‹è¯•æ€§èƒ½æŒ‡æ ‡èšåˆ...")

    try:
        from src.utils.cache import CacheManager
        from src.utils.logger import get_logger

        cache = CacheManager()
        logger = get_logger()

        # æ¨¡æ‹Ÿç»¼åˆæ€§èƒ½æ•°æ®æ”¶é›†
        performance_data = {
            'cache_metrics': {},
            'logging_metrics': {},
            'system_metrics': {},
            'application_metrics': {}
        }

        print("   æ”¶é›†ç¼“å­˜æ€§èƒ½æŒ‡æ ‡:")
        # æ·»åŠ å¤§é‡ç¼“å­˜æ•°æ®
        for i in range(50):
            cache.set(f"perf_test_{i}", {
                'data': f'test_data_{i}',
                'timestamp': time.time(),
                'size': 100
            }, ttl=300)

        cache_stats = cache.get_stats()
        performance_data['cache_metrics'] = cache_stats
        print(f"     - ç¼“å­˜æ¡ç›®æ•°: {cache_stats.get('size', 0)}")
        print(f"     - ç¼“å­˜æ€»å­—èŠ‚æ•°: {cache_stats.get('total_size_bytes', 0)}")
        print(f"     - è¿‡æœŸæ¡ç›®æ•°: {cache_stats.get('expired_entries', 0)}")

        print("\n   æ”¶é›†æ—¥å¿—æ€§èƒ½æŒ‡æ ‡:")
        # æ¨¡æ‹Ÿæ—¥å¿—æ€§èƒ½æ•°æ®
        log_start = time.time()
        for i in range(50):
            logger.info(f"Performance test log {i}")
        log_time = time.time() - log_start

        performance_data['logging_metrics'] = {
            'log_count': 50,
            'total_time': log_time,
            'logs_per_second': 50 / log_time
        }
        print(f"     - æ—¥å¿—æ•°é‡: {performance_data['logging_metrics']['log_count']}")
        print(f"     - æ—¥å¿—è®°å½•é€Ÿåº¦: {performance_data['logging_metrics']['logs_per_second']:.0f} æ¡/ç§’")

        print("\n   æ”¶é›†ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡:")
        # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
        cpu_percent = psutil.cpu_percent()
        memory = psutil.virtual_memory()

        performance_data['system_metrics'] = {
            'cpu_percent': cpu_percent,
            'memory_percent': memory.percent,
            'memory_used_gb': memory.used // (1024**3),
            'timestamp': datetime.now().isoformat()
        }
        print(f"     - CPUä½¿ç”¨ç‡: {performance_data['system_metrics']['cpu_percent']:.1f}%")
        print(f"     - å†…å­˜ä½¿ç”¨ç‡: {performance_data['system_metrics']['memory_percent']:.1f}%")

        print("\n   æ”¶é›†åº”ç”¨æ€§èƒ½æŒ‡æ ‡:")
        # åº”ç”¨çº§æ€§èƒ½æŒ‡æ ‡
        process = psutil.Process()
        performance_data['application_metrics'] = {
            'process_memory_mb': process.memory_info().rss // (1024**2),
            'process_cpu_percent': process.cpu_percent(),
            'thread_count': process.num_threads(),
            'uptime': time.time() - process.create_time()
        }
        print(f"     - è¿›ç¨‹å†…å­˜: {performance_data['application_metrics']['process_memory_mb']} MB")
        print(f"     - è¿›ç¨‹CPUä½¿ç”¨ç‡: {performance_data['application_metrics']['process_cpu_percent']:.1f}%")
        print(f"     - è¿è¡Œæ—¶é•¿: {performance_data['application_metrics']['uptime']:.1f}s")

        print("\n   æ€§èƒ½æŒ‡æ ‡èšåˆåˆ†æ:")
        # åˆ†ææ€§èƒ½æ•°æ®
        analysis = {
            'overall_health': 'good',
            'performance_issues': [],
            'recommendations': []
        }

        # ç¼“å­˜æ€§èƒ½åˆ†æ
        cache_hit_rate = cache_stats.get('hit_rate', 0)
        if cache_hit_rate < 0.5:
            analysis['performance_issues'].append('ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½')
            analysis['recommendations'].append('ä¼˜åŒ–ç¼“å­˜ç­–ç•¥')

        # ç³»ç»Ÿèµ„æºåˆ†æ
        if cpu_percent > 80:
            analysis['performance_issues'].append('CPUä½¿ç”¨ç‡è¿‡é«˜')
            analysis['overall_health'] = 'warning'

        if memory.percent > 80:
            analysis['performance_issues'].append('å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜')
            analysis['overall_health'] = 'warning'

        # æ—¥å¿—æ€§èƒ½åˆ†æ
        logs_per_sec = performance_data['logging_metrics']['logs_per_second']
        if logs_per_sec < 100:
            analysis['performance_issues'].append('æ—¥å¿—è®°å½•æ€§èƒ½è¾ƒæ…¢')
            analysis['recommendations'].append('ä¼˜åŒ–æ—¥å¿—é…ç½®')

        print(f"     - æ•´ä½“å¥åº·çŠ¶æ€: {analysis['overall_health']}")
        print(f"     - å‘ç°æ€§èƒ½é—®é¢˜æ•°: {len(analysis['performance_issues'])}")
        print(f"     - ä¼˜åŒ–å»ºè®®æ•°: {len(analysis['recommendations'])}")

        if analysis['performance_issues']:
            print("     - æ€§èƒ½é—®é¢˜:")
            for issue in analysis['performance_issues']:
                print(f"       â€¢ {issue}")

        if analysis['recommendations']:
            print("     - ä¼˜åŒ–å»ºè®®:")
            for rec in analysis['recommendations']:
                print(f"       â€¢ {rec}")

        # éªŒè¯èšåˆç»“æœ
        aggregation_valid = (
            len(performance_data) == 4 and
            all(len(data) > 0 for data in performance_data.values()) and
            len(analysis) >= 3
        )

        print(f"     - æ€§èƒ½èšåˆéªŒè¯: {'âœ…' if aggregation_valid else 'âŒ'}")
        return aggregation_valid

    except Exception as e:
        print(f"âŒ æ€§èƒ½æŒ‡æ ‡èšåˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)

    test_results = []

    # 1. æµ‹è¯•è¿›åº¦è·Ÿè¸ªå™¨æ€§èƒ½ç›‘æ§
    progress_ok = test_progress_tracker_performance()
    test_results.append(progress_ok)

    # 2. æµ‹è¯•æ—¥å¿—ç³»ç»Ÿæ€§èƒ½ç›‘æ§
    logger_ok = test_logger_performance_monitoring()
    test_results.append(logger_ok)

    # 3. æµ‹è¯•ç¼“å­˜æ€§èƒ½ç›‘æ§
    cache_ok = test_cache_performance_monitoring()
    test_results.append(cache_ok)

    # 4. æµ‹è¯•æ‰§è¡Œå¼•æ“ç›‘æ§
    engine_ok = test_execution_engine_monitoring()
    test_results.append(engine_ok)

    # 5. æµ‹è¯•ç¼–æ’å™¨ä¼šè¯ç›‘æ§
    orchestrator_ok = test_orchestrator_session_monitoring()
    test_results.append(orchestrator_ok)

    # 6. æµ‹è¯•ç³»ç»Ÿèµ„æºç›‘æ§
    system_ok = test_system_resource_monitoring()
    test_results.append(system_ok)

    # 7. æµ‹è¯•æ€§èƒ½æŒ‡æ ‡èšåˆ
    aggregation_ok = test_performance_metrics_aggregation()
    test_results.append(aggregation_ok)

    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")

    passed = sum(test_results)
    total = len(test_results)

    print(f"âœ… é€šè¿‡: {passed}/{total}")
    print(f"âŒ å¤±è´¥: {total-passed}/{total}")

    if passed >= total * 0.8:  # 80%é€šè¿‡ç‡
        print("\nğŸ‰ æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡åŠŸèƒ½æµ‹è¯•åŸºæœ¬é€šè¿‡ï¼")
        print("æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡åŠŸèƒ½å·²å°±ç»ªã€‚")
        if passed < total:
            print(f"âš ï¸ æœ‰ {total-passed} é¡¹æµ‹è¯•å¤±è´¥ï¼Œä½†ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ã€‚")
        return 0
    else:
        print(f"\nâš ï¸ ä»…æœ‰ {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡ï¼Œéœ€è¦æ£€æŸ¥æ€§èƒ½ç›‘æ§åŠŸèƒ½ã€‚")
        return 1

if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        sys.exit(0)
    except Exception as e:
        print(f"\næµ‹è¯•å¼‚å¸¸: {e}")
        sys.exit(1)