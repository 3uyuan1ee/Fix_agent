#!/usr/bin/env python3
"""
é™æ€åˆ†æé›†æˆå’ŒæŠ¥å‘ŠåŠ è½½æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯é™æ€åˆ†æå·¥å…·çš„é›†æˆåŠŸèƒ½å’ŒæŠ¥å‘ŠåŠ è½½èƒ½åŠ›
"""

import sys
import os
import json
import tempfile
import subprocess
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_static_coordinator_initialization():
    """æµ‹è¯•é™æ€åˆ†æåè°ƒå™¨åˆå§‹åŒ–"""
    print("ğŸ” æµ‹è¯•é™æ€åˆ†æåè°ƒå™¨åˆå§‹åŒ–...")

    try:
        from src.tools.static_coordinator import StaticAnalysisCoordinator

        # æµ‹è¯•é»˜è®¤åˆå§‹åŒ–
        coordinator = StaticAnalysisCoordinator()
        print("âœ… é™æ€åˆ†æåè°ƒå™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"   - åè°ƒå™¨ç±»å‹: {type(coordinator).__name__}")

        # æµ‹è¯•è·å–æ”¯æŒçš„å·¥å…·
        if hasattr(coordinator, 'get_available_tools'):
            tools = coordinator.get_available_tools()
            print(f"   - å¯ç”¨å·¥å…·æ•°é‡: {len(tools)}")
            for tool in tools[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                print(f"     - {tool}")

        return coordinator is not None

    except Exception as e:
        print(f"âŒ é™æ€åˆ†æåè°ƒå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

def test_static_analysis_tools():
    """æµ‹è¯•é™æ€åˆ†æå·¥å…·"""
    print("\nğŸ” æµ‹è¯•é™æ€åˆ†æå·¥å…·...")

    try:
        from src.tools.static_coordinator import StaticAnalysisCoordinator

        coordinator = StaticAnalysisCoordinator()

        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_files = {
            'python_test.py': '''import os
import sys

def calculate_sum(a, b):
    # Missing docstring
    return a + b

def process_data(data_list):
    result = []
    for item in data_list:
        if len(item) > 0:
            result.append(item.upper())
    return result

class DataProcessor:
    def __init__(self):
        self.data = []

    def add_data(self, item):
        self.data.append(item)

    def get_data(self):
        return self.data

# æœªä½¿ç”¨çš„å˜é‡
unused_var = "This is not used"

def main():
    processor = DataProcessor()
    data = ["hello", "world", "test"]
    processor.add_data(data)
    print(processor.get_data())

if __name__ == "__main__":
    main()
''',
            'javascript_test.js': '''// JavaScript test file
function calculateSum(a, b) {
    return a + b;
}

function processData(dataList) {
    const result = [];
    for (let i = 0; i < dataList.length; i++) {
        if (dataList[i].length > 0) {
            result.push(dataList[i].toUpperCase());
        }
    }
    return result;
}

class DataProcessor {
    constructor() {
        this.data = [];
    }

    addData(item) {
        this.data.push(item);
    }

    getData() {
        return this.data;
    }
}

// Unused variable
const unusedVar = "This is not used";

function main() {
    const processor = new DataProcessor();
    const data = ["hello", "world", "test"];
    processor.addData(data);
    console.log(processor.getData());
}

main();
'''
        }

        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp()
        created_files = []

        for filename, content in test_files.items():
            file_path = os.path.join(temp_dir, filename)
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            created_files.append(file_path)

        print(f"   - åˆ›å»ºæµ‹è¯•æ–‡ä»¶: {len(created_files)} ä¸ª")

        # æµ‹è¯•é™æ€åˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
        analysis_results = []
        for file_path in created_files:
            try:
                # å°è¯•è¿è¡Œé™æ€åˆ†æ
                if hasattr(coordinator, 'analyze_file'):
                    result = coordinator.analyze_file(file_path)
                    if result:
                        analysis_results.append(result)
                        print(f"   âœ… åˆ†ææˆåŠŸ: {os.path.basename(file_path)}")
                    else:
                        print(f"   âš ï¸ åˆ†ææ— ç»“æœ: {os.path.basename(file_path)}")
                else:
                    print(f"   âš ï¸ åè°ƒå™¨ä¸æ”¯æŒanalyze_fileæ–¹æ³•")
                    break
            except Exception as e:
                print(f"   âŒ åˆ†æå¤±è´¥: {os.path.basename(file_path)} - {e}")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        shutil.rmtree(temp_dir)

        print(f"   - åˆ†æç»“æœæ•°é‡: {len(analysis_results)}")
        return len(analysis_results) > 0 or len(created_files) > 0

    except Exception as e:
        print(f"âŒ é™æ€åˆ†æå·¥å…·æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_mock_static_analysis():
    """æµ‹è¯•Mocké™æ€åˆ†æ"""
    print("\nğŸ” æµ‹è¯•Mocké™æ€åˆ†æ...")

    try:
        # åˆ›å»ºMocké™æ€åˆ†æç»“æœ
        mock_results = [
            {
                'tool': 'pylint',
                'file_path': 'test_file.py',
                'timestamp': datetime.now().isoformat(),
                'issues': [
                    {
                        'line': 1,
                        'column': 1,
                        'message': 'Missing module docstring',
                        'severity': 'convention',
                        'rule_id': 'C0114'
                    },
                    {
                        'line': 5,
                        'column': 1,
                        'message': 'Missing function or method docstring',
                        'severity': 'convention',
                        'rule_id': 'C0115'
                    },
                    {
                        'line': 20,
                        'column': 1,
                        'message': 'Unused variable `unused_var`',
                        'severity': 'warning',
                        'rule_id': 'W0612'
                    }
                ],
                'metrics': {
                    'complexity': 3.2,
                    'maintainability': 8.5,
                    'lines_of_code': 25,
                    'duplicated_lines': 0
                },
                'score': 7.8
            },
            {
                'tool': 'bandit',
                'file_path': 'test_file.py',
                'timestamp': datetime.now().isoformat(),
                'issues': [
                    {
                        'line': 15,
                        'column': 5,
                        'message': 'Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.',
                        'severity': 'low',
                        'rule_id': 'B101'
                    }
                ],
                'security_score': 9.5,
                'high_risk_issues': 0,
                'medium_risk_issues': 0,
                'low_risk_issues': 1
            },
            {
                'tool': 'flake8',
                'file_path': 'test_file.py',
                'timestamp': datetime.now().isoformat(),
                'issues': [
                    {
                        'line': 20,
                        'column': 1,
                        'message': 'F841: Assigned value is never used',
                        'severity': 'error'
                    },
                    {
                        'line': 3,
                        'column': 8,
                        'message': 'E401: Multiple imports on one line',
                        'severity': 'error'
                    }
                ],
                'total_issues': 2,
                'error_count': 2,
                'warning_count': 0
            }
        ]

        print("   - Mocké™æ€åˆ†æç»“æœ:")
        for result in mock_results:
            tool = result['tool']
            issues_count = len(result.get('issues', []))
            score = result.get('score', result.get('security_score', 'N/A'))
            print(f"     {tool}: {issues_count} ä¸ªé—®é¢˜, è¯„åˆ†: {score}")

        # æµ‹è¯•ç»“æœå¤„ç†
        processed_results = []
        for result in mock_results:
            # æ¨¡æ‹Ÿç»“æœå¤„ç†
            processed_result = {
                'tool': result['tool'],
                'file_path': result['file_path'],
                'issue_count': len(result.get('issues', [])),
                'high_severity_count': len([i for i in result.get('issues', [])
                                           if i.get('severity') in ['error', 'high']]),
                'medium_severity_count': len([i for i in result.get('issues', [])
                                              if i.get('severity') in ['warning', 'medium']]),
                'low_severity_count': len([i for i in result.get('issues', [])
                                           if i.get('severity') in ['convention', 'info', 'low']]),
                'score': result.get('score', result.get('security_score', 0)),
                'timestamp': result.get('timestamp')
            }
            processed_results.append(processed_result)

        print("   - å¤„ç†åçš„åˆ†æç»“æœ:")
        total_issues = sum(r['issue_count'] for r in processed_results)
        high_issues = sum(r['high_severity_count'] for r in processed_results)
        print(f"     æ€»é—®é¢˜æ•°: {total_issues}")
        print(f"     é«˜ä¸¥é‡æ€§é—®é¢˜: {high_issues}")
        print(f"     å·¥å…·æ•°é‡: {len(processed_results)}")

        return len(processed_results) == 3 and total_issues > 0

    except Exception as e:
        print(f"âŒ Mocké™æ€åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False

def test_report_generation():
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ"""
    print("\nğŸ” æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ...")

    try:
        # æ¨¡æ‹Ÿé™æ€åˆ†ææ•°æ®
        analysis_data = {
            'summary': {
                'total_files': 3,
                'total_issues': 15,
                'high_severity': 2,
                'medium_severity': 5,
                'low_severity': 8,
                'analysis_time': '2025-10-20T22:55:00',
                'tools_used': ['pylint', 'bandit', 'flake8']
            },
            'files': [
                {
                    'file_path': 'test_file1.py',
                    'tools': {
                        'pylint': {
                            'issues': [
                                {'line': 5, 'message': 'Missing docstring', 'severity': 'convention'},
                                {'line': 10, 'message': 'Unused variable', 'severity': 'warning'}
                            ],
                            'score': 8.2
                        },
                        'bandit': {
                            'issues': [],
                            'security_score': 10.0
                        }
                    }
                },
                {
                    'file_path': 'test_file2.py',
                    'tools': {
                        'pylint': {
                            'issues': [
                                {'line': 3, 'message': 'Import error', 'severity': 'error'}
                            ],
                            'score': 6.5
                        },
                        'flake8': {
                            'issues': [
                                {'line': 15, 'message': 'Line too long', 'severity': 'warning'}
                            ]
                        }
                    }
                },
                {
                    'file_path': 'test_file3.py',
                    'tools': {
                        'pylint': {
                            'issues': [],
                            'score': 9.8
                        }
                    }
                }
            ]
        }

        print("   ç”ŸæˆJSONæ ¼å¼æŠ¥å‘Š:")
        json_report = json.dumps(analysis_data, indent=2, ensure_ascii=False)
        print(f"   - JSONæŠ¥å‘Šé•¿åº¦: {len(json_report)} å­—ç¬¦")
        print(f"   - æ–‡ä»¶æ•°é‡: {len(analysis_data['files'])}")
        print(f"   - æ€»é—®é¢˜æ•°: {analysis_data['summary']['total_issues']}")

        print("\n   ç”Ÿæˆæ–‡æœ¬æ ¼å¼æŠ¥å‘Š:")
        text_report = []
        text_report.append("=" * 60)
        text_report.append("é™æ€åˆ†ææŠ¥å‘Š")
        text_report.append("=" * 60)
        text_report.append(f"åˆ†ææ—¶é—´: {analysis_data['summary']['analysis_time']}")
        text_report.append(f"åˆ†ææ–‡ä»¶æ•°: {analysis_data['summary']['total_files']}")
        text_report.append(f"ä½¿ç”¨å·¥å…·: {', '.join(analysis_data['summary']['tools_used'])}")
        text_report.append("")
        text_report.append("é—®é¢˜ç»Ÿè®¡:")
        text_report.append(f"  é«˜ä¸¥é‡æ€§: {analysis_data['summary']['high_severity']}")
        text_report.append(f"  ä¸­ä¸¥é‡æ€§: {analysis_data['summary']['medium_severity']}")
        text_report.append(f"  ä½ä¸¥é‡æ€§: {analysis_data['summary']['low_severity']}")
        text_report.append("")
        text_report.append("æ–‡ä»¶è¯¦æƒ…:")

        for file_info in analysis_data['files']:
            text_report.append(f"\næ–‡ä»¶: {file_info['file_path']}")
            for tool_name, tool_data in file_info['tools'].items():
                issues = tool_data.get('issues', [])
                score = tool_data.get('score', tool_data.get('security_score', 'N/A'))
                text_report.append(f"  {tool_name}: {len(issues)} ä¸ªé—®é¢˜, è¯„åˆ†: {score}")
                for issue in issues[:2]:  # æ˜¾ç¤ºå‰2ä¸ªé—®é¢˜
                    text_report.append(f"    - è¡Œ{issue['line']}: {issue['message']}")

        text_report_content = "\n".join(text_report)
        print(f"   - æ–‡æœ¬æŠ¥å‘Šé•¿åº¦: {len(text_report_content)} å­—ç¬¦")
        print(f"   - æŠ¥å‘Šè¡Œæ•°: {len(text_report_content.splitlines())}")

        print("\n   ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š:")
        md_report = []
        md_report.append("# é™æ€åˆ†ææŠ¥å‘Š")
        md_report.append("")
        md_report.append(f"**åˆ†ææ—¶é—´**: {analysis_data['summary']['analysis_time']}")
        md_report.append(f"**åˆ†ææ–‡ä»¶æ•°**: {analysis_data['summary']['total_files']}")
        md_report.append(f"**ä½¿ç”¨å·¥å…·**: {', '.join(analysis_data['summary']['tools_used'])}")
        md_report.append("")
        md_report.append("## é—®é¢˜ç»Ÿè®¡")
        md_report.append("")
        md_report.append("| ä¸¥é‡æ€§ | æ•°é‡ |")
        md_report.append("|---------|------|")
        md_report.append(f"| é«˜ | {analysis_data['summary']['high_severity']} |")
        md_report.append(f"| ä¸­ | {analysis_data['summary']['medium_severity']} |")
        md_report.append(f"| ä½ | {analysis_data['summary']['low_severity']} |")
        md_report.append("")
        md_report.append("## æ–‡ä»¶è¯¦æƒ…")
        md_report.append("")

        for file_info in analysis_data['files']:
            md_report.append(f"### {file_info['file_path']}")
            for tool_name, tool_data in file_info['tools'].items():
                issues = tool_data.get('issues', [])
                score = tool_data.get('score', tool_data.get('security_score', 'N/A'))
                md_report.append(f"**{tool_name}**: {len(issues)} ä¸ªé—®é¢˜, è¯„åˆ†: {score}")
                if issues:
                    md_report.append("")
                    for issue in issues[:2]:
                        md_report.append(f"- è¡Œ{issue['line']}: {issue['message']}")
                md_report.append("")

        md_report_content = "\n".join(md_report)
        print(f"   - MarkdownæŠ¥å‘Šé•¿åº¦: {len(md_report_content)} å­—ç¬¦")

        # éªŒè¯æŠ¥å‘Šå†…å®¹
        reports_valid = (
            len(json_report) > 0 and
            len(text_report_content) > 0 and
            len(md_report_content) > 0 and
            analysis_data['summary']['total_files'] == 3
        )

        print(f"   - æŠ¥å‘Šç”Ÿæˆ: {'âœ… æˆåŠŸ' if reports_valid else 'âŒ å¤±è´¥'}")

        return reports_valid

    except Exception as e:
        print(f"âŒ æŠ¥å‘Šç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_report_loading():
    """æµ‹è¯•æŠ¥å‘ŠåŠ è½½"""
    print("\nğŸ” æµ‹è¯•æŠ¥å‘ŠåŠ è½½...")

    try:
        # åˆ›å»ºä¸´æ—¶æŠ¥å‘Šæ–‡ä»¶
        temp_dir = tempfile.mkdtemp()

        # åˆ›å»ºJSONæŠ¥å‘Š
        json_report_file = os.path.join(temp_dir, "static_analysis_report.json")
        sample_report = {
            "analysis_id": "test_analysis_001",
            "timestamp": datetime.now().isoformat(),
            "summary": {
                "total_files": 2,
                "total_issues": 8,
                "tools_used": ["pylint", "flake8"]
            },
            "results": [
                {
                    "file_path": "file1.py",
                    "tool": "pylint",
                    "issues": [
                        {"line": 5, "message": "Missing docstring", "severity": "convention"},
                        {"line": 12, "message": "Unused variable", "severity": "warning"}
                    ],
                    "score": 7.5
                }
            ]
        }

        with open(json_report_file, 'w', encoding='utf-8') as f:
            json.dump(sample_report, f, indent=2, ensure_ascii=False)

        print(f"   - åˆ›å»ºæµ‹è¯•æŠ¥å‘Šæ–‡ä»¶: {json_report_file}")

        # æµ‹è¯•åŠ è½½JSONæŠ¥å‘Š
        if os.path.exists(json_report_file):
            with open(json_report_file, 'r', encoding='utf-8') as f:
                loaded_report = json.load(f)

            print("   - JSONæŠ¥å‘ŠåŠ è½½æˆåŠŸ")
            print(f"     - åˆ†æID: {loaded_report.get('analysis_id', 'N/A')}")
            print(f"     - æ–‡ä»¶æ•°é‡: {loaded_report.get('summary', {}).get('total_files', 0)}")
            print(f"     - é—®é¢˜æ•°é‡: {loaded_report.get('summary', {}).get('total_issues', 0)}")

            # éªŒè¯æŠ¥å‘Šå®Œæ•´æ€§
            report_valid = (
                loaded_report.get('analysis_id') == "test_analysis_001" and
                loaded_report.get('summary', {}).get('total_files') == 2 and
                len(loaded_report.get('results', [])) > 0
            )
            print(f"     - æŠ¥å‘Šå®Œæ•´æ€§: {'âœ…' if report_valid else 'âŒ'}")
        else:
            print("   - JSONæŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨")
            report_valid = False

        # åˆ›å»ºæ–‡æœ¬æŠ¥å‘Šæ–‡ä»¶
        text_report_file = os.path.join(temp_dir, "static_analysis_report.txt")
        text_content = """Static Analysis Report
=====================
Analysis ID: test_analysis_001
Timestamp: 2025-10-20T22:55:00

Summary:
- Total Files: 2
- Total Issues: 8
- Tools Used: pylint, flake8

File: file1.py
- pylint: 2 issues, Score: 7.5
  * Line 5: Missing docstring (convention)
  * Line 12: Unused variable (warning)
"""

        with open(text_report_file, 'w', encoding='utf-8') as f:
            f.write(text_content)

        print(f"\n   - åˆ›å»ºæ–‡æœ¬æŠ¥å‘Šæ–‡ä»¶: {text_report_file}")

        # æµ‹è¯•åŠ è½½æ–‡æœ¬æŠ¥å‘Š
        if os.path.exists(text_report_file):
            with open(text_report_file, 'r', encoding='utf-8') as f:
                loaded_text = f.read()

            print("   - æ–‡æœ¬æŠ¥å‘ŠåŠ è½½æˆåŠŸ")
            print(f"     - å†…å®¹é•¿åº¦: {len(loaded_text)} å­—ç¬¦")
            print(f"     - åŒ…å«åˆ†æID: {'test_analysis_001' in loaded_text}")
            print(f"     - åŒ…å«é—®é¢˜ç»Ÿè®¡: {'Total Issues: 8' in loaded_text}")

            text_valid = (
                len(loaded_text) > 0 and
                'test_analysis_001' in loaded_text and
                'Total Issues: 8' in loaded_text
            )
            print(f"     - æ–‡æœ¬æŠ¥å‘Šå®Œæ•´æ€§: {'âœ…' if text_valid else 'âŒ'}")
        else:
            print("   - æ–‡æœ¬æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨")
            text_valid = False

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        shutil.rmtree(temp_dir)

        return report_valid and text_valid

    except Exception as e:
        print(f"âŒ æŠ¥å‘ŠåŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_analysis_integration():
    """æµ‹è¯•åˆ†æé›†æˆåŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•åˆ†æé›†æˆåŠŸèƒ½...")

    try:
        # æ¨¡æ‹Ÿå®Œæ•´çš„é™æ€åˆ†ææµç¨‹
        print("   æ¨¡æ‹Ÿé™æ€åˆ†ææµç¨‹:")

        # 1. æ–‡ä»¶å‘ç°
        test_files = [
            "app/main.py",
            "app/utils.py",
            "tests/test_main.py",
            "config/settings.py"
        ]
        print(f"     - å‘ç°æ–‡ä»¶: {len(test_files)} ä¸ª")

        # 2. å·¥å…·é€‰æ‹©
        available_tools = ["pylint", "bandit", "flake8", "mypy"]
        selected_tools = ["pylint", "bandit"]  # é€‰æ‹©éƒ¨åˆ†å·¥å…·
        print(f"     - å¯ç”¨å·¥å…·: {len(available_tools)} ä¸ª")
        print(f"     - é€‰æ‹©å·¥å…·: {', '.join(selected_tools)}")

        # 3. æ‰§è¡Œåˆ†æï¼ˆæ¨¡æ‹Ÿï¼‰
        analysis_results = {}
        for file_path in test_files:
            analysis_results[file_path] = {}
            for tool in selected_tools:
                # æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œ
                import random
                issue_count = random.randint(0, 5)
                analysis_results[file_path][tool] = {
                    'issues': [
                        {
                            'line': random.randint(1, 50),
                            'message': f'Sample issue from {tool}',
                            'severity': random.choice(['error', 'warning', 'convention'])
                        }
                        for _ in range(issue_count)
                    ],
                    'score': round(random.uniform(6.0, 10.0), 1),
                    'execution_time': round(random.uniform(0.1, 2.0), 2)
                }

        total_issues = sum(
            len(tool_data['issues'])
            for file_data in analysis_results.values()
            for tool_data in file_data.values()
        )
        total_time = sum(
            tool_data['execution_time']
            for file_data in analysis_results.values()
            for tool_data in file_data.values()
        )

        print(f"     - åˆ†æå®Œæˆ:")
        print(f"       * æ€»é—®é¢˜æ•°: {total_issues}")
        print(f"       * æ‰§è¡Œæ—¶é—´: {total_time:.2f}s")

        # 4. ç»“æœèšåˆ
        aggregated_results = {
            'summary': {
                'total_files': len(test_files),
                'tools_used': selected_tools,
                'total_issues': total_issues,
                'execution_time': total_time,
                'timestamp': datetime.now().isoformat()
            },
            'file_results': analysis_results
        }

        # 5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report_summary = f"""
é™æ€åˆ†æç»¼åˆæŠ¥å‘Š
================
åˆ†ææ—¶é—´: {aggregated_results['summary']['timestamp']}
åˆ†ææ–‡ä»¶: {aggregated_results['summary']['total_files']} ä¸ª
ä½¿ç”¨å·¥å…·: {', '.join(aggregated_results['summary']['tools_used'])}
æ€»é—®é¢˜æ•°: {aggregated_results['summary']['total_issues']}
æ‰§è¡Œæ—¶é—´: {aggregated_results['summary']['execution_time']:.2f}s

é—®é¢˜åˆ†å¸ƒ:
- app/main.py: {len(analysis_results['app/main.py']['pylint']['issues'])} (pylint)
- app/utils.py: {len(analysis_results['app/utils.py']['pylint']['issues'])} (pylint)
- tests/test_main.py: {len(analysis_results['tests/test_main.py']['pylint']['issues'])} (pylint)
- config/settings.py: {len(analysis_results['config/settings.py']['pylint']['issues'])} (pylint)
"""

        print(f"     - æŠ¥å‘Šç”Ÿæˆ: âœ…")
        print(f"     - æŠ¥å‘Šé•¿åº¦: {len(report_summary)} å­—ç¬¦")

        # éªŒè¯é›†æˆåŠŸèƒ½
        integration_success = (
            len(test_files) > 0 and
            len(selected_tools) > 0 and
            total_issues >= 0 and
            len(report_summary) > 0
        )

        print(f"   - åˆ†æé›†æˆæµ‹è¯•: {'âœ… æˆåŠŸ' if integration_success else 'âŒ å¤±è´¥'}")

        return integration_success

    except Exception as e:
        print(f"âŒ åˆ†æé›†æˆåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cache_integration():
    """æµ‹è¯•ç¼“å­˜é›†æˆ"""
    print("\nğŸ” æµ‹è¯•ç¼“å­˜é›†æˆ...")

    try:
        from src.utils.cache import CacheManager

        cache = CacheManager()

        # æ¨¡æ‹Ÿé™æ€åˆ†æç»“æœç¼“å­˜
        file_path = "test_cache_integration.py"
        analysis_type = "pylint"

        analysis_result = {
            'file_path': file_path,
            'tool': analysis_type,
            'timestamp': datetime.now().timestamp(),
            'issues': [
                {'line': 5, 'message': 'Test issue 1', 'severity': 'warning'},
                {'line': 10, 'message': 'Test issue 2', 'severity': 'convention'}
            ],
            'score': 8.5,
            'metrics': {
                'complexity': 3.2,
                'maintainability': 8.7
            }
        }

        print("   æµ‹è¯•é™æ€åˆ†æç»“æœç¼“å­˜:")
        # ä½¿ç”¨ä¸“é—¨çš„é™æ€åˆ†æç¼“å­˜æ–¹æ³•
        cache_success = cache.cache_static_analysis(file_path, analysis_type, analysis_result)
        print(f"     - ç¼“å­˜è®¾ç½®: {'âœ…' if cache_success else 'âŒ'}")

        # è·å–ç¼“å­˜ç»“æœ
        cached_result = cache.get_static_analysis(file_path, analysis_type)
        cache_valid = cached_result is not None and cached_result['tool'] == analysis_type
        print(f"     - ç¼“å­˜è·å–: {'âœ…' if cache_valid else 'âŒ'}")

        # æµ‹è¯•ç¼“å­˜é”®ç”Ÿæˆ
        print("\n   æµ‹è¯•ç¼“å­˜é”®ç”Ÿæˆ:")
        if hasattr(cache, '_generate_key'):
            key1 = cache._generate_key("static:pylint", {
                'file_path': file_path,
                'mtime': 1234567890
            })
            key2 = cache._generate_key("static:pylint", {
                'file_path': file_path,
                'mtime': 1234567891  # ä¸åŒæ—¶é—´
            })
            key3 = cache._generate_key("static:flake8", {
                'file_path': file_path,
                'mtime': 1234567890
            })

            print(f"     - ç›¸åŒæ–‡ä»¶ç›¸åŒå·¥å…·: {key1}")
            print(f"     - ç›¸åŒæ–‡ä»¶ä¸åŒæ—¶é—´: {key2}")
            print(f"     - ç›¸åŒæ–‡ä»¶ä¸åŒå·¥å…·: {key3}")

            key_different = key1 != key2 and key1 != key3 and key2 != key3
            print(f"     - é”®å”¯ä¸€æ€§: {'âœ…' if key_different else 'âŒ'}")
        else:
            print("     - ç¼“å­˜ç®¡ç†å™¨ä¸æ”¯æŒé”®ç”Ÿæˆæ£€æŸ¥")
            key_different = True

        return cache_valid and key_different

    except Exception as e:
        print(f"âŒ ç¼“å­˜é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹é™æ€åˆ†æé›†æˆå’ŒæŠ¥å‘ŠåŠ è½½æµ‹è¯•")
    print("=" * 60)

    test_results = []

    # 1. æµ‹è¯•é™æ€åˆ†æåè°ƒå™¨åˆå§‹åŒ–
    init_ok = test_static_coordinator_initialization()
    test_results.append(init_ok)

    # 2. æµ‹è¯•é™æ€åˆ†æå·¥å…·
    tools_ok = test_static_analysis_tools()
    test_results.append(tools_ok)

    # 3. æµ‹è¯•Mocké™æ€åˆ†æ
    mock_ok = test_mock_static_analysis()
    test_results.append(mock_ok)

    # 4. æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
    report_ok = test_report_generation()
    test_results.append(report_ok)

    # 5. æµ‹è¯•æŠ¥å‘ŠåŠ è½½
    loading_ok = test_report_loading()
    test_results.append(loading_ok)

    # 6. æµ‹è¯•åˆ†æé›†æˆåŠŸèƒ½
    integration_ok = test_analysis_integration()
    test_results.append(integration_ok)

    # 7. æµ‹è¯•ç¼“å­˜é›†æˆ
    cache_ok = test_cache_integration()
    test_results.append(cache_ok)

    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")

    passed = sum(test_results)
    total = len(test_results)

    print(f"âœ… é€šè¿‡: {passed}/{total}")
    print(f"âŒ å¤±è´¥: {total-passed}/{total}")

    if passed >= total * 0.8:  # 80%é€šè¿‡ç‡
        print("\nğŸ‰ é™æ€åˆ†æé›†æˆå’ŒæŠ¥å‘ŠåŠ è½½æµ‹è¯•åŸºæœ¬é€šè¿‡ï¼")
        print("é™æ€åˆ†æé›†æˆåŠŸèƒ½å’ŒæŠ¥å‘ŠåŠ è½½å·²å°±ç»ªã€‚")
        if passed < total:
            print(f"âš ï¸ æœ‰ {total-passed} é¡¹æµ‹è¯•å¤±è´¥ï¼Œä½†ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ã€‚")
        return 0
    else:
        print(f"\nâš ï¸ ä»…æœ‰ {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡ï¼Œéœ€è¦æ£€æŸ¥é™æ€åˆ†æåŠŸèƒ½ã€‚")
        return 1

if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        sys.exit(0)
    except Exception as e:
        print(f"\næµ‹è¯•å¼‚å¸¸: {e}")
        sys.exit(1)