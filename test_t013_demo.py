#!/usr/bin/env python3
"""
T013å¤§æ¨¡å‹APIè°ƒç”¨å®ç°åŠŸèƒ½æ¼”ç¤º
éªŒè¯æ‰€æœ‰éªŒæ”¶æ ‡å‡†æ˜¯å¦æ»¡è¶³
"""

import asyncio
import tempfile
import yaml
from src.llm import (
    LLMClient, LLMClientConfig, LLMResponseParser, ParsedAnalysis, ParseResult,
    LLMConfigManager, Message, MessageRole
)


async def test_t013_functionality():
    """æ¼”ç¤ºT013æ‰€æœ‰åŠŸèƒ½çš„å®Œæ•´æ€§"""
    print("=== T013å¤§æ¨¡å‹APIè°ƒç”¨å®ç°åŠŸèƒ½æ¼”ç¤º ===\n")

    # 1. åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
    config_data = {
        "providers": {
            "openai": {
                "provider": "openai",
                "model": "gpt-3.5-turbo",
                "api_key": "demo-key",
                "temperature": 0.7,
                "max_tokens": 1000,
                "timeout": 30,
                "max_retries": 3
            },
            "anthropic": {
                "provider": "anthropic",
                "model": "claude-3-sonnet-20240229",
                "api_key": "demo-key",
                "temperature": 0.5,
                "max_tokens": 2000,
                "timeout": 45,
                "max_retries": 2
            }
        }
    }

    with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:
        yaml.dump(config_data, f)
        temp_config_file = f.name

    try:
        # éªŒæ”¶æ ‡å‡†1ï¼šæœŸæœ›èƒ½å¤Ÿå‘é€åˆ†æè¯·æ±‚åˆ°LLM API
        print("âœ… éªŒæ”¶æ ‡å‡†1ï¼šèƒ½å¤Ÿå‘é€åˆ†æè¯·æ±‚åˆ°LLM API")

        config_manager = LLMConfigManager(config_file=temp_config_file)
        client = LLMClient(config_manager=config_manager)

        print(f"  - å·²åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒçš„æä¾›è€…ï¼š{client.get_provider_names()}")
        print(f"  - é»˜è®¤æä¾›è€…ï¼š{client.config.default_provider}")
        print(f"  - å›é€€æœºåˆ¶ï¼š{'å¯ç”¨' if client.config.enable_fallback else 'ç¦ç”¨'}")

        # éªŒæ”¶æ ‡å‡†2ï¼šæœŸæœ›èƒ½å¤Ÿå¤„ç†APIå“åº”å’Œé”™è¯¯ä¿¡æ¯
        print("\nâœ… éªŒæ”¶æ ‡å‡†2ï¼šèƒ½å¤Ÿå¤„ç†APIå“åº”å’Œé”™è¯¯ä¿¡æ¯")

        print(f"  - æ”¯æŒçš„å¼‚å¸¸ç±»å‹ï¼šLLMError, LLMTimeoutError, LLMRateLimitError, LLMAuthenticationError, LLMQuotaExceededError")
        print(f"  - HTTPå®¢æˆ·ç«¯é‡è¯•æœºåˆ¶ï¼šæœ€å¤§é‡è¯•{client.config.max_retry_attempts}æ¬¡")
        print(f"  - è¶…æ—¶è®¾ç½®ï¼š{client.config.timeout}ç§’")
        print(f"  - é”™è¯¯å¤„ç†ï¼šæ”¯æŒè‡ªåŠ¨å›é€€å’Œè¯¦ç»†é”™è¯¯ä¿¡æ¯")

        # éªŒæ”¶æ ‡å‡†3ï¼šæœŸæœ›èƒ½å¤Ÿè§£æJSONæ ¼å¼çš„åˆ†æç»“æœ
        print("\nâœ… éªŒæ”¶æ ‡å‡†3ï¼šèƒ½å¤Ÿè§£æJSONæ ¼å¼çš„åˆ†æç»“æœ")

        parser = LLMResponseParser()

        # æµ‹è¯•å„ç§JSONæ ¼å¼è§£æ
        test_responses = [
            '{"defects": [{"type": "sql_injection", "severity": "high", "title": "SQLæ³¨å…¥"}], "summary": {"total_defects": 1}}',
            '```json\n{"defects": [], "summary": {}}\n```',
            'åˆ†æç»“æœï¼š\n{\n  "defects": [{"type": "xss", "severity": "medium"}]\n}\nå®Œæˆã€‚',
            'å‘ç°ä»¥ä¸‹é—®é¢˜ï¼š\n1. SQLæ³¨å…¥æ¼æ´\n2. ç¡¬ç¼–ç å¯†ç '
        ]

        for i, response in enumerate(test_responses, 1):
            result = parser.parse_analysis_response(response)
            print(f"  - æµ‹è¯•{i}: è§£æçŠ¶æ€={result.status.value}, ç¼ºé™·æ•°é‡={len(result.defects)}")

        # éªŒæ”¶æ ‡å‡†4ï¼šæœŸæœ›èƒ½å¤Ÿå¤„ç†APIé™æµå’Œé…é¢é—®é¢˜
        print("\nâœ… éªŒæ”¶æ ‡å‡†4ï¼šèƒ½å¤Ÿå¤„ç†APIé™æµå’Œé…é¢é—®é¢˜")

        print("  - LLMRateLimitErrorï¼šå¤„ç†APIè°ƒç”¨é¢‘ç‡é™åˆ¶")
        print("  - LLMQuotaExceededErrorï¼šå¤„ç†APIé…é¢è¶…é™")
        print("  - æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶ï¼šé¿å…é›·ç¾¤æ•ˆåº”")
        print("  - è‡ªåŠ¨é‡è¯•ç­–ç•¥ï¼šæ”¯æŒè‡ªå®šä¹‰é‡è¯•æ¬¡æ•°å’Œå»¶è¿Ÿ")

        # æ¼”ç¤ºå®Œæ•´åŠŸèƒ½
        print("\nğŸš€ å®Œæ•´åŠŸèƒ½æ¼”ç¤ºï¼š")

        # åˆ›å»ºè¯·æ±‚
        request = client.create_request([
            "è¯·åˆ†æä»¥ä¸‹ä»£ç ä¸­çš„å®‰å…¨é—®é¢˜ï¼š\n\n```python\nimport os\npassword = 'admin123'\n```"
        ])

        print("  - å·²åˆ›å»ºLLMåˆ†æè¯·æ±‚")
        print(f"  - è¯·æ±‚åŒ…å«{len(request.messages)}æ¡æ¶ˆæ¯")
        print(f"  - é…ç½®æ¨¡å‹ï¼š{request.config.model}")

        # æ¨¡æ‹Ÿå“åº”è§£æ
        mock_llm_response = '''
        {
            "defects": [
                {
                    "id": "defect_1",
                    "type": "hardcoded_password",
                    "severity": "high",
                    "title": "ç¡¬ç¼–ç å¯†ç ",
                    "description": "ä»£ç ä¸­åŒ…å«ç¡¬ç¼–ç çš„æ•æ„Ÿä¿¡æ¯",
                    "location": {"file": "example.py", "line": 3},
                    "fix_suggestion": "ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®ç®¡ç†ç³»ç»Ÿå­˜å‚¨æ•æ„Ÿä¿¡æ¯"
                }
            ],
            "summary": {
                "total_defects": 1,
                "severity_distribution": {"high": 1},
                "recommendations": ["ç«‹å³ä¿®å¤ç¡¬ç¼–ç å¯†ç é—®é¢˜"]
            }
        }
        '''

        parsed_result = parser.parse_analysis_response(mock_llm_response)

        print(f"  - è§£æçŠ¶æ€ï¼š{parsed_result.status.value}")
        print(f"  - å‘ç°ç¼ºé™·ï¼š{len(parsed_result.defects)}ä¸ª")
        print(f"  - ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒï¼š{parsed_result.summary.get('severity_distribution', {})}")

        if parsed_result.defects:
            defect = parsed_result.defects[0]
            print(f"  - ä¸»è¦ç¼ºé™·ï¼š{defect['title']} ({defect['severity']})")
            print(f"  - ä¿®å¤å»ºè®®ï¼š{defect['fix_suggestion']}")

        # ç»Ÿè®¡ä¿¡æ¯
        stats = client.get_stats()
        print(f"\nğŸ“Š å®¢æˆ·ç«¯ç»Ÿè®¡ä¿¡æ¯ï¼š")
        print(f"  - æ€»è¯·æ±‚æ•°ï¼š{stats['total_requests']}")
        print(f"  - æˆåŠŸè¯·æ±‚æ•°ï¼š{stats['successful_requests']}")
        print(f"  - å¤±è´¥è¯·æ±‚æ•°ï¼š{stats['failed_requests']}")
        print(f"  - å›é€€ä½¿ç”¨æ¬¡æ•°ï¼š{stats['fallback_used']}")
        print(f"  - æä¾›è€…ä½¿ç”¨æƒ…å†µï¼š{stats['provider_usage']}")

        print("\nğŸ‰ T013å¤§æ¨¡å‹APIè°ƒç”¨å®ç° - æ‰€æœ‰éªŒæ”¶æ ‡å‡†éªŒè¯å®Œæˆï¼")
        print("\nâœ… åŠŸèƒ½ç‰¹æ€§æ€»ç»“ï¼š")
        print("  1. ç»Ÿä¸€çš„LLMå®¢æˆ·ç«¯æ¥å£ï¼Œæ”¯æŒå¤šProviderç®¡ç†")
        print("  2. å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶")
        print("  3. æ™ºèƒ½çš„APIå“åº”è§£æï¼Œæ”¯æŒå¤šç§JSONæ ¼å¼")
        print("  4. è‡ªåŠ¨å›é€€æœºåˆ¶ï¼Œæé«˜ç³»ç»Ÿå¯é æ€§")
        print("  5. ç»Ÿè®¡ä¿¡æ¯ç›‘æ§ï¼Œä¾¿äºæ€§èƒ½åˆ†æ")
        print("  6. é™æµå’Œé…é¢é—®é¢˜å¤„ç†")
        print("  7. ç¼ºé™·ä¿¡æ¯æ ‡å‡†åŒ–å’ŒéªŒè¯")
        print("  8. æ”¯æŒæµå¼å’Œéæµå¼å“åº”")

    finally:
        import os
        os.unlink(temp_config_file)


if __name__ == "__main__":
    asyncio.run(test_t013_functionality())