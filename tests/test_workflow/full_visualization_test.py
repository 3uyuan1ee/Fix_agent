"""
å®Œæ•´å¯è§†åŒ–åŠŸèƒ½æµ‹è¯•

æµ‹è¯•æ‰€æœ‰å¯è§†åŒ–åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ€è€ƒè¿‡ç¨‹ã€å·¥å…·è°ƒç”¨ã€todoåˆ—è¡¨æ„å»ºç­‰
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from enhanced_base_agent import create_enhanced_research_agent, VisualizationConfig
from langchain_openai import ChatOpenAI


def test_thinking_visualization():
    """æµ‹è¯•æ€è€ƒè¿‡ç¨‹å¯è§†åŒ–"""
    print("ğŸ§  æµ‹è¯•æ€è€ƒè¿‡ç¨‹å¯è§†åŒ–")
    print("-" * 50)

    try:
        # åˆ›å»ºä¸€ä¸ªå¼ºè°ƒæ€è€ƒè¿‡ç¨‹çš„ä»£ç†
        researcher = create_enhanced_research_agent(
            name="thinking-test",
            description="æ€è€ƒè¿‡ç¨‹æµ‹è¯•ä»£ç†",

            system_prompt="""ä½ æ˜¯ä¸€ä¸ªå–„äºå±•ç¤ºæ€è€ƒè¿‡ç¨‹çš„åŠ©æ‰‹ã€‚åœ¨å›ç­”ä»»ä½•é—®é¢˜ä¹‹å‰ï¼Œè¯·ï¼š
            1. è¯¦ç»†åˆ†æé—®é¢˜çš„è¦æ±‚å’Œå«ä¹‰
            2. è¯´æ˜ä½ çš„æ€è€ƒè¿‡ç¨‹å’Œæ¨ç†æ­¥éª¤
            3. è§£é‡Šä½ ä¸ºä»€ä¹ˆé€‰æ‹©è¿™æ ·çš„å›ç­”æ–¹å¼
            4. å±•ç¤ºä½ çš„å†³ç­–é€»è¾‘

            è¯·æ˜ç¡®ä½¿ç”¨"æ€è€ƒï¼š"ã€"åˆ†æï¼š"ã€"æ¨ç†ï¼š"ç­‰è¯è¯­æ¥å±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚""",

            model=ChatOpenAI(
                temperature=0.5,
                model="glm-4.5-air",
                openai_api_key="4a5b3138f1b447d18ae48b1ece88a7e9.QXy6uJ1RYIoisDG4",
                openai_api_base="https://open.bigmodel.cn/api/paas/v4/",
            ),

            visualization_config=VisualizationConfig(
                show_thinking=True,
                show_tool_calls=True,
                show_todo_updates=True,
                show_timing=True,
                show_subagent_calls=False,
                max_message_length=300,
                colors={
                    "thinking": "ğŸ§ ",
                    "tool_call": "ğŸ”§",
                    "tool_result": "âœ…",
                    "todo": "ğŸ“",
                    "error": "âŒ",
                    "success": "ğŸ‰",
                    "info": "â„¹ï¸",
                }
            )
        )

        researcher.build()
        print("âœ… æ€è€ƒè¿‡ç¨‹æµ‹è¯•ä»£ç†åˆ›å»ºæˆåŠŸ")

        # éœ€è¦æ·±å…¥æ€è€ƒçš„ä»»åŠ¡
        task = """åˆ†æä¸ºä»€ä¹ˆPythonåœ¨æ•°æ®ç§‘å­¦é¢†åŸŸå¦‚æ­¤å—æ¬¢è¿ï¼Œè¯·ä»ä»¥ä¸‹è§’åº¦æ€è€ƒï¼š
        1. è¯­è¨€ç‰¹æ€§æ–¹é¢
        2. ç”Ÿæ€ç³»ç»Ÿæ–¹é¢
        3. ç¤¾åŒºæ”¯æŒæ–¹é¢
        4. å­¦ä¹ æ›²çº¿æ–¹é¢

        è¯·è¯¦ç»†å±•ç¤ºä½ çš„åˆ†æè¿‡ç¨‹ã€‚"""

        print(f"\nğŸ¯ æ€è€ƒä»»åŠ¡: {task[:80]}...")

        # æ‰§è¡Œä»»åŠ¡
        result = researcher.invoke({"messages": [{"role": "user", "content": task}]})

        # è·å–æ‰§è¡Œæ—¥å¿—
        log = researcher.get_execution_log()
        if log and "execution_summary" in log:
            summary = log["execution_summary"]
            print(f"ğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
            print(f"  æ€»æ­¥éª¤æ•°: {summary.get('total_steps', 0)}")
            print(f"  å·¥å…·è°ƒç”¨: {summary.get('tool_calls', 0)}")
            print(f"  æ‰§è¡Œæ—¶é—´: {summary.get('total_time', 0):.2f}ç§’")

        print("âœ… æ€è€ƒè¿‡ç¨‹å¯è§†åŒ–æµ‹è¯•å®Œæˆ")
        return True

    except Exception as e:
        print(f"âŒ æ€è€ƒè¿‡ç¨‹å¯è§†åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_todo_visualization():
    """æµ‹è¯•Todoåˆ—è¡¨å¯è§†åŒ–"""
    print("\nğŸ“ æµ‹è¯•Todoåˆ—è¡¨å¯è§†åŒ–")
    print("-" * 50)

    try:
        # åˆ›å»ºä¸€ä¸ªä¸“é—¨æµ‹è¯•todoçš„ä»£ç†
        todo_researcher = create_enhanced_research_agent(
            name="todo-test",
            description="Todoåˆ—è¡¨æµ‹è¯•ä»£ç†",

            system_prompt="""ä½ æ˜¯ä¸€ä¸ªå–„äºè§„åˆ’å’Œä»»åŠ¡ç®¡ç†çš„åŠ©æ‰‹ã€‚åœ¨æ‰§è¡Œå¤æ‚ä»»åŠ¡æ—¶ï¼š
            1. é¦–å…ˆåˆ›å»ºè¯¦ç»†çš„todoåˆ—è¡¨ï¼Œåˆ†è§£ä»»åŠ¡ä¸ºå…·ä½“æ­¥éª¤
            2. æŒ‰ç…§todoåˆ—è¡¨é€æ­¥æ‰§è¡Œï¼Œæ¯å®Œæˆä¸€é¡¹å°±æ ‡è®°å®Œæˆ
            3. åœ¨è¿‡ç¨‹ä¸­ä¸æ–­æ›´æ–°todoåˆ—è¡¨çŠ¶æ€
            4. æœ€åæ€»ç»“å®Œæˆçš„ä»»åŠ¡å’Œç»“æœ

            è¯·æ˜ç¡®ä½¿ç”¨todoåˆ—è¡¨æ¥è·Ÿè¸ªä½ çš„å·¥ä½œè¿›åº¦ã€‚""",

            model=ChatOpenAI(
                temperature=0.3,
                model="glm-4.5-air",
                openai_api_key="4a5b3138f1b447d18ae48b1ece88a7e9.QXy6uJ1RYIoisDG4",
                openai_api_base="https://open.bigmodel.cn/api/paas/v4/",
            ),

            visualization_config=VisualizationConfig(
                show_thinking=True,
                show_tool_calls=True,
                show_todo_updates=True,  # é‡ç‚¹æ˜¾ç¤ºTodoæ›´æ–°
                show_timing=True,
                show_subagent_calls=False,
                max_message_length=200,
                colors={
                    "thinking": "ğŸ’­",
                    "tool_call": "ğŸ”¨",
                    "tool_result": "âœ¨",
                    "todo": "ğŸ—‚ï¸",
                    "error": "âš ï¸",
                    "success": "ğŸ¯",
                    "info": "ğŸ“‹",
                }
            )
        )

        todo_researcher.build()
        print("âœ… Todoæµ‹è¯•ä»£ç†åˆ›å»ºæˆåŠŸ")

        # éœ€è¦å¤šæ­¥éª¤è§„åˆ’çš„ä»»åŠ¡
        task = """å®Œæˆä¸€ä¸ªå°å‹ç ”ç©¶æŠ¥å‘Šï¼šäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨
        è¦æ±‚ï¼š
        1. è°ƒç ”å½“å‰AIåŒ»ç–—è¯Šæ–­çš„ä¸»è¦æŠ€æœ¯
        2. åˆ†æè¿™äº›æŠ€æœ¯çš„ä¼˜åŠ¿å’Œå±€é™æ€§
        3. æ”¶é›†å®é™…åº”ç”¨æ¡ˆä¾‹
        4. æ€»ç»“æœªæ¥å‘å±•è¶‹åŠ¿
        5. æä¾›å­¦ä¹ èµ„æºå»ºè®®

        è¯·åˆ›å»ºè¯¦ç»†çš„todoåˆ—è¡¨å¹¶é€æ­¥å®Œæˆã€‚"""

        print(f"\nğŸ¯ Todoä»»åŠ¡: {task[:60]}...")

        # æ‰§è¡Œä»»åŠ¡
        result = todo_researcher.invoke({"messages": [{"role": "user", "content": task}]})

        # è·å–æ‰§è¡Œæ—¥å¿—ï¼Œç‰¹åˆ«å…³æ³¨todoæ›´æ–°
        log = todo_researcher.get_execution_log()
        if log and "execution_summary" in log:
            summary = log["execution_summary"]
            print(f"ğŸ“Š Todoç»Ÿè®¡:")
            print(f"  Todoæ›´æ–°æ¬¡æ•°: {summary.get('todo_updates', 0)}")
            print(f"  æ€»æ­¥éª¤æ•°: {summary.get('total_steps', 0)}")
            print(f"  æ‰§è¡Œæ—¶é—´: {summary.get('total_time', 0):.2f}ç§’")

        print("âœ… Todoåˆ—è¡¨å¯è§†åŒ–æµ‹è¯•å®Œæˆ")
        return True

    except Exception as e:
        print(f"âŒ Todoåˆ—è¡¨å¯è§†åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_error_handling_visualization():
    """æµ‹è¯•é”™è¯¯å¤„ç†å¯è§†åŒ–"""
    print("\nâš ï¸ æµ‹è¯•é”™è¯¯å¤„ç†å¯è§†åŒ–")
    print("-" * 50)

    try:
        # åˆ›å»ºä¸€ä¸ªæµ‹è¯•é”™è¯¯å¤„ç†çš„ä»£ç†
        error_researcher = create_enhanced_research_agent(
            name="error-test",
            description="é”™è¯¯å¤„ç†æµ‹è¯•ä»£ç†",

            system_prompt="""ä½ æ˜¯ä¸€ä¸ªå–„äºå¤„ç†é”™è¯¯å’Œå¼‚å¸¸æƒ…å†µçš„åŠ©æ‰‹ã€‚å½“é‡åˆ°é—®é¢˜æ—¶ï¼š
            1. æ¸…æ¥šåœ°åˆ†æé”™è¯¯åŸå› 
            2. è¯´æ˜ä½ çš„è§£å†³æ–¹æ¡ˆæ€è·¯
            3. å°è¯•å¤šç§æ›¿ä»£æ–¹æ¡ˆ
            4. æ€»ç»“ä»é”™è¯¯ä¸­å­¦åˆ°çš„ç»éªŒ

            è¯·å±•ç¤ºä½ çš„é”™è¯¯å¤„ç†å’Œé—®é¢˜è§£å†³è¿‡ç¨‹ã€‚""",

            model=ChatOpenAI(
                temperature=0.2,
                model="glm-4.5-air",
                openai_api_key="4a5b3138f1b447d18ae48b1ece88a7e9.QXy6uJ1RYIoisDG4",
                openai_api_base="https://open.bigmodel.cn/api/paas/v4/",
            ),

            visualization_config=VisualizationConfig(
                show_thinking=True,
                show_tool_calls=True,
                show_todo_updates=True,
                show_timing=True,
                show_subagent_calls=False,
                max_message_length=150,
                colors={
                    "thinking": "ğŸ¤”",
                    "tool_call": "ğŸ”§",
                    "tool_result": "ğŸ“Š",
                    "todo": "ğŸ“‹",
                    "error": "ğŸš¨",
                    "success": "âœ…",
                    "info": "â„¹ï¸",
                }
            )
        )

        error_researcher.build()
        print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•ä»£ç†åˆ›å»ºæˆåŠŸ")

        # å¯èƒ½ä¼šé‡åˆ°é—®é¢˜çš„ä»»åŠ¡
        task = """å°è¯•å®Œæˆä»¥ä¸‹å¯èƒ½æœ‰æŒ‘æˆ˜çš„ä»»åŠ¡ï¼š
        1. æœç´¢ä¸€äº›ä¸å­˜åœ¨çš„ç½‘ç»œèµ„æº
        2. å¦‚æœæœç´¢å¤±è´¥ï¼ŒåŸºäºä½ çš„çŸ¥è¯†å›ç­”
        3. åˆ†æä¸ºä»€ä¹ˆä¼šå‡ºç°é—®é¢˜
        4. æä¾›æ›¿ä»£è§£å†³æ–¹æ¡ˆ

        è¯·å±•ç¤ºä½ çš„é”™è¯¯å¤„ç†è¿‡ç¨‹ã€‚"""

        print(f"\nğŸ¯ é”™è¯¯å¤„ç†ä»»åŠ¡: {task[:60]}...")

        # æ‰§è¡Œä»»åŠ¡
        result = error_researcher.invoke({"messages": [{"role": "user", "content": task}]})

        # è·å–æ‰§è¡Œæ—¥å¿—
        log = error_researcher.get_execution_log()
        if log and "execution_summary" in log:
            summary = log["execution_summary"]
            print(f"ğŸ“Š é”™è¯¯å¤„ç†ç»Ÿè®¡:")
            print(f"  æ€»æ­¥éª¤æ•°: {summary.get('total_steps', 0)}")
            print(f"  å·¥å…·è°ƒç”¨: {summary.get('tool_calls', 0)}")
            print(f"  æ‰§è¡Œæ—¶é—´: {summary.get('total_time', 0):.2f}ç§’")

        print("âœ… é”™è¯¯å¤„ç†å¯è§†åŒ–æµ‹è¯•å®Œæˆ")
        return True

    except Exception as e:
        print(f"âŒ é”™è¯¯å¤„ç†å¯è§†åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_streaming_visualization():
    """æµ‹è¯•æµå¼å¯è§†åŒ–"""
    print("\nğŸŒŠ æµ‹è¯•æµå¼å¯è§†åŒ–")
    print("-" * 50)

    try:
        # åˆ›å»ºæµå¼æµ‹è¯•ä»£ç†
        stream_researcher = create_enhanced_research_agent(
            name="stream-test",
            description="æµå¼æµ‹è¯•ä»£ç†",

            model=ChatOpenAI(
                temperature=0.4,
                model="glm-4.5-air",
                openai_api_key="4a5b3138f1b447d18ae48b1ece88a7e9.QXy6uJ1RYIoisDG4",
                openai_api_base="https://open.bigmodel.cn/api/paas/v4/",
            ),

            visualization_config=VisualizationConfig(
                show_thinking=False,  # æµå¼æ—¶ç®€åŒ–æ˜¾ç¤º
                show_tool_calls=True,
                show_todo_updates=False,
                show_timing=False,
                show_subagent_calls=False,
                max_message_length=100,
            )
        )

        stream_researcher.build()
        print("âœ… æµå¼æµ‹è¯•ä»£ç†åˆ›å»ºæˆåŠŸ")

        # ç®€å•çš„æµå¼ä»»åŠ¡
        task = "ç®€å•ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ"

        print(f"\nğŸ¯ æµå¼ä»»åŠ¡: {task}")
        print("ğŸŒŠ å¼€å§‹æµå¼æ‰§è¡Œ...")

        # æµå¼æ‰§è¡Œ
        chunk_count = 0
        for chunk in stream_researcher.stream({"messages": [{"role": "user", "content": task}]}):
            chunk_count += 1
            if chunk_count <= 3:  # åªæ˜¾ç¤ºå‰å‡ ä¸ªchunké¿å…è¾“å‡ºè¿‡å¤š
                print(f"ğŸ“¦ Chunk {chunk_count}: {type(chunk).__name__}")

        print(f"âœ… æµå¼æ‰§è¡Œå®Œæˆï¼Œå…± {chunk_count} ä¸ªchunks")
        return True

    except Exception as e:
        print(f"âŒ æµå¼å¯è§†åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ­ å®Œæ•´å¯è§†åŒ–åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    print("æµ‹è¯•é¡¹ç›®:")
    print("  ğŸ§  æ€è€ƒè¿‡ç¨‹å¯è§†åŒ–")
    print("  ğŸ“ Todoåˆ—è¡¨æ„å»ºå¯è§†åŒ–")
    print("  âš ï¸ é”™è¯¯å¤„ç†å¯è§†åŒ–")
    print("  ğŸŒŠ æµå¼æ‰§è¡Œå¯è§†åŒ–")
    print("=" * 60)

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("æ€è€ƒè¿‡ç¨‹å¯è§†åŒ–", test_thinking_visualization),
        ("Todoåˆ—è¡¨å¯è§†åŒ–", test_todo_visualization),
        ("é”™è¯¯å¤„ç†å¯è§†åŒ–", test_error_handling_visualization),
        ("æµå¼æ‰§è¡Œå¯è§†åŒ–", test_streaming_visualization),
    ]

    passed_tests = 0
    total_tests = len(tests)

    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            if test_func():
                passed_tests += 1
                print(f"âœ… {test_name} é€šè¿‡")
            else:
                print(f"âŒ {test_name} å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} å¼‚å¸¸: {e}")

    # æœ€ç»ˆæ€»ç»“
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æµ‹è¯•æ€»ç»“: {passed_tests}/{total_tests} é€šè¿‡")

    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰å¯è§†åŒ–åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("\nä½ ç°åœ¨å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°:")
        print("  ğŸ§  Agentçš„æ€è€ƒè¿‡ç¨‹å’Œæ¨ç†é€»è¾‘")
        print("  ğŸ”§ å·¥å…·è°ƒç”¨çš„è¯¦ç»†ä¿¡æ¯å’Œç»“æœ")
        print("  ğŸ“ Todoåˆ—è¡¨çš„æ„å»ºå’Œæ›´æ–°è¿‡ç¨‹")
        print("  âš ï¸ é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶")
        print("  ğŸŒŠ æµå¼æ‰§è¡Œçš„å®æ—¶è¿‡ç¨‹")
        print("\nâœ¨ å¯è§†åŒ–ä¼˜åŒ–å®Œæˆï¼")
    else:
        print(f"âš ï¸ {total_tests - passed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œä½†ä¸»è¦åŠŸèƒ½å·²å®ç°ã€‚")
        print("å¯è§†åŒ–ç³»ç»ŸåŸºæœ¬å¯ç”¨ï¼Œå¯ä»¥è¿›è¡Œè¿›ä¸€æ­¥è°ƒè¯•ã€‚")

    print(f"\nğŸ¯ å»ºè®®:")
    print("  1. åœ¨å®é™…ä½¿ç”¨ä¸­å¯ç”¨å®Œæ•´å¯è§†åŒ–åŠŸèƒ½")
    print("  2. æ ¹æ®éœ€è¦è°ƒæ•´å¯è§†åŒ–é…ç½®")
    print("  3. æŸ¥çœ‹æ‰§è¡Œæ—¥å¿—æ¥åˆ†æagentè¡Œä¸º")
    print("  4. ä½¿ç”¨æµå¼æ¨¡å¼è¿›è¡Œå®æ—¶ç›‘æ§")


if __name__ == "__main__":
    main()