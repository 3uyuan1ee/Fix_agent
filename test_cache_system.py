#!/usr/bin/env python3
"""
é«˜çº§ç¼“å­˜ç³»ç»Ÿæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯ç¼“å­˜ç³»ç»Ÿçš„åˆå§‹åŒ–ã€åŸºæœ¬æ“ä½œå’Œé«˜çº§åŠŸèƒ½
"""

import sys
import os
import time
import json
import tempfile
from pathlib import Path
from unittest.mock import Mock, patch
from datetime import datetime, timedelta

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_cache_manager_initialization():
    """æµ‹è¯•ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–"""
    print("ğŸ” æµ‹è¯•ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–...")

    try:
        from src.utils.cache import CacheManager

        # æµ‹è¯•é»˜è®¤åˆå§‹åŒ–
        cache_manager = CacheManager()
        print("âœ… é»˜è®¤ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"   - ç¼“å­˜ç±»å‹: {type(cache_manager.backend).__name__}")
        print(f"   - é»˜è®¤TTL: {getattr(cache_manager, 'default_ttl', 'N/A')}")

        # æµ‹è¯•ä¸åŒåç«¯ç±»å‹
        with patch('src.utils.cache.get_config_manager') as mock_config:
            for backend_type in ['memory', 'redis']:
                try:
                    # Mocké…ç½®
                    mock_config_instance = Mock()
                    mock_config_instance.get_section.return_value = {
                        'type': backend_type,
                        'max_size': 100,
                        'ttl': 3600
                    }
                    mock_config.return_value = mock_config_instance

                    manager = CacheManager(config_manager=mock_config_instance)
                    print(f"âœ… {backend_type} åç«¯åˆå§‹åŒ–æˆåŠŸ")
                except Exception as e:
                    print(f"âŒ {backend_type} åç«¯åˆå§‹åŒ–å¤±è´¥: {e}")

        return cache_manager is not None

    except Exception as e:
        print(f"âŒ ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

def test_memory_cache_operations():
    """æµ‹è¯•å†…å­˜ç¼“å­˜æ“ä½œ"""
    print("\nğŸ” æµ‹è¯•å†…å­˜ç¼“å­˜æ“ä½œ...")

    try:
        from src.utils.cache import CacheManager

        cache = CacheManager(backend_type='memory')

        # æµ‹è¯•åŸºæœ¬æ“ä½œ
        test_data = {
            'string': 'test_value',
            'number': 42,
            'list': [1, 2, 3],
            'dict': {'key': 'value', 'nested': {'data': 'test'}},
            'complex': {
                'analysis_result': {
                    'file': 'test.py',
                    'issues': [{'type': 'style', 'line': 10}],
                    'score': 8.5
                }
            }
        }

        print("   æµ‹è¯•ç¼“å­˜è®¾ç½®å’Œè·å–:")
        results = []

        for key, value in test_data.items():
            # è®¾ç½®ç¼“å­˜
            success = cache.set(f"test_{key}", value, ttl=60)
            if success:
                # è·å–ç¼“å­˜
                retrieved = cache.get(f"test_{key}")
                if retrieved == value:
                    print(f"   âœ… {key}: ç¼“å­˜æˆåŠŸ")
                    results.append(True)
                else:
                    print(f"   âŒ {key}: è·å–å€¼ä¸åŒ¹é…")
                    results.append(False)
            else:
                print(f"   âŒ {key}: ç¼“å­˜è®¾ç½®å¤±è´¥")
                results.append(False)

        # æµ‹è¯•ç¼“å­˜å­˜åœ¨æ€§æ£€æŸ¥
        print("\n   æµ‹è¯•ç¼“å­˜å­˜åœ¨æ€§æ£€æŸ¥:")
        exists = cache.exists("test_string")
        not_exists = cache.exists("nonexistent_key")
        print(f"   - å­˜åœ¨çš„é”®: {exists}")
        print(f"   - ä¸å­˜åœ¨çš„é”®: {not_exists}")

        # æµ‹è¯•ç¼“å­˜å¤§å°
        print("\n   æµ‹è¯•ç¼“å­˜å¤§å°å’Œç»Ÿè®¡:")
        size = cache.size()
        print(f"   - ç¼“å­˜æ¡ç›®æ•°: {size}")

        # æµ‹è¯•é”®åˆ—è¡¨
        keys = cache.keys()
        print(f"   - ç¼“å­˜é”®åˆ—è¡¨: {len(keys)} ä¸ªé”®")

        # æµ‹è¯•åˆ é™¤æ“ä½œ
        print("\n   æµ‹è¯•åˆ é™¤æ“ä½œ:")
        delete_success = cache.delete("test_string")
        after_delete = cache.get("test_string")
        print(f"   - åˆ é™¤æˆåŠŸ: {delete_success}")
        print(f"   - åˆ é™¤åè·å–å€¼: {after_delete}")

        # æµ‹è¯•æ¸…ç©ºæ“ä½œ
        cache.clear()
        empty_size = cache.size()
        print(f"   - æ¸…ç©ºåå¤§å°: {empty_size}")

        return all(results) and empty_size == 0

    except Exception as e:
        print(f"âŒ å†…å­˜ç¼“å­˜æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cache_ttl_functionality():
    """æµ‹è¯•ç¼“å­˜TTLåŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•ç¼“å­˜TTLåŠŸèƒ½...")

    try:
        from src.utils.cache import CacheManager

        cache = CacheManager(backend_type='memory')

        print("   æµ‹è¯•TTLè¿‡æœŸ:")
        # è®¾ç½®çŸ­TTLçš„ç¼“å­˜
        cache.set("ttl_test", "expires_soon", ttl=1)  # 1ç§’TTL

        # ç«‹å³è·å–åº”è¯¥æˆåŠŸ
        immediate = cache.get("ttl_test")
        print(f"   - ç«‹å³è·å–: {immediate}")

        # ç­‰å¾…è¿‡æœŸ
        print("   ç­‰å¾…2ç§’è®©ç¼“å­˜è¿‡æœŸ...")
        time.sleep(2)

        # è¿‡æœŸåè·å–åº”è¯¥å¤±è´¥
        expired = cache.get("ttl_test")
        print(f"   - è¿‡æœŸåè·å–: {expired}")

        ttl_working = immediate == "expires_soon" and expired is None

        print("   æµ‹è¯•ä¸åŒTTLå€¼:")
        # æµ‹è¯•ä¸åŒTTLå€¼
        ttl_tests = [
            ("short_ttl", "short", 1),
            ("medium_ttl", "medium", 5),
            ("long_ttl", "long", 10)
        ]

        for key, value, ttl in ttl_tests:
            cache.set(key, value, ttl=ttl)
            retrieved = cache.get(key)
            print(f"   - {key} (TTL={ttl}s): {'âœ…' if retrieved == value else 'âŒ'}")

        return ttl_working

    except Exception as e:
        print(f"âŒ ç¼“å­˜TTLåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cache_advanced_operations():
    """æµ‹è¯•ç¼“å­˜é«˜çº§æ“ä½œ"""
    print("\nğŸ” æµ‹è¯•ç¼“å­˜é«˜çº§æ“ä½œ...")

    try:
        from src.utils.cache import CacheManager

        cache = CacheManager(backend_type='memory')

        print("   æµ‹è¯•get_or_setæ–¹æ³•:")
        def expensive_operation(key):
            """æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ"""
            time.sleep(0.1)  # æ¨¡æ‹Ÿå»¶è¿Ÿ
            return f"computed_value_for_{key}"

        # ç¬¬ä¸€æ¬¡è°ƒç”¨ä¼šæ‰§è¡Œè®¡ç®—
        start_time = time.time()
        result1 = cache.get_or_set("compute_key", lambda: expensive_operation("compute_key"), ttl=60)
        first_call_time = time.time() - start_time

        # ç¬¬äºŒæ¬¡è°ƒç”¨ä»ç¼“å­˜è·å–
        start_time = time.time()
        result2 = cache.get_or_set("compute_key", lambda: expensive_operation("compute_key"), ttl=60)
        second_call_time = time.time() - start_time

        print(f"   - ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶é—´: {first_call_time:.3f}s (åŒ…å«è®¡ç®—)")
        print(f"   - ç¬¬äºŒæ¬¡è°ƒç”¨æ—¶é—´: {second_call_time:.3f}s (ä»ç¼“å­˜)")
        print(f"   - ç»“æœä¸€è‡´æ€§: {'âœ…' if result1 == result2 else 'âŒ'}")
        print(f"   - ç¼“å­˜åŠ é€Ÿæ•ˆæœ: {'âœ…' if second_call_time < first_call_time / 2 else 'âŒ'}")

        print("\n   æµ‹è¯•æ‰¹é‡æ“ä½œ:")
        # æ‰¹é‡è®¾ç½®
        batch_data = {
            "batch_key_1": "value1",
            "batch_key_2": "value2",
            "batch_key_3": "value3"
        }

        for key, value in batch_data.items():
            cache.set(key, value, ttl=60)

        # æ‰¹é‡è·å–
        batch_keys = list(batch_data.keys())
        batch_results = {}
        for key in batch_keys:
            batch_results[key] = cache.get(key)

        print(f"   - æ‰¹é‡è®¾ç½®é”®æ•°: {len(batch_data)}")
        print(f"   - æ‰¹é‡è·å–é”®æ•°: {len(batch_results)}")
        print(f"   - æ•°æ®å®Œæ•´æ€§: {'âœ…' if batch_results == batch_data else 'âŒ'}")

        print("\n   æµ‹è¯•ç¼“å­˜ç»Ÿè®¡:")
        stats = cache.get_stats() if hasattr(cache, 'get_stats') else {}
        if stats:
            print("   - ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯:")
            for key, value in stats.items():
                print(f"     {key}: {value}")
        else:
            print("   - å½“å‰ç¼“å­˜åç«¯ä¸æ”¯æŒç»Ÿè®¡")

        return result1 == result2 and second_call_time < first_call_time / 2

    except Exception as e:
        print(f"âŒ ç¼“å­˜é«˜çº§æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cache_with_analysis_data():
    """æµ‹è¯•ç¼“å­˜åˆ†ææ•°æ®"""
    print("\nğŸ” æµ‹è¯•ç¼“å­˜åˆ†ææ•°æ®...")

    try:
        from src.utils.cache import CacheManager

        cache = CacheManager(backend_type='memory')

        print("   æµ‹è¯•åˆ†æç»“æœç¼“å­˜:")
        # æ¨¡æ‹Ÿæ·±åº¦åˆ†æç»“æœ
        analysis_result = {
            "file_path": "test_analysis.py",
            "analysis_type": "comprehensive",
            "success": True,
            "content": "ä»£ç åˆ†æå®Œæˆï¼Œå‘ç°3ä¸ªé—®é¢˜",
            "structured_analysis": {
                "summary": "ä»£ç è´¨é‡è‰¯å¥½",
                "issues": [
                    {"type": "style", "line": 5, "message": "ç¼ºå°‘ç±»å‹æ³¨è§£"},
                    {"type": "performance", "line": 15, "message": "å¯ä»¥ä¼˜åŒ–ç®—æ³•"}
                ],
                "recommendations": ["æ·»åŠ ç±»å‹æ³¨è§£", "ä¼˜åŒ–ç®—æ³•"],
                "score": 8.5
            },
            "execution_time": 2.34,
            "model_used": "glm-4.5",
            "token_usage": {"total_tokens": 450},
            "timestamp": datetime.now().isoformat()
        }

        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"analysis:{analysis_result['file_path']}:{analysis_result['analysis_type']}"

        # ç¼“å­˜åˆ†æç»“æœ
        cache_success = cache.set(cache_key, analysis_result, ttl=3600)  # 1å°æ—¶
        print(f"   - åˆ†æç»“æœç¼“å­˜: {'âœ…' if cache_success else 'âŒ'}")

        # è·å–ç¼“å­˜ç»“æœ
        cached_result = cache.get(cache_key)
        cache_valid = cached_result is not None and cached_result['file_path'] == analysis_result['file_path']
        print(f"   - ç¼“å­˜ç»“æœéªŒè¯: {'âœ…' if cache_valid else 'âŒ'}")

        print("\n   æµ‹è¯•é™æ€åˆ†æç»“æœç¼“å­˜:")
        # æ¨¡æ‹Ÿé™æ€åˆ†æç»“æœ
        static_result = {
            "tool": "pylint",
            "file_path": "test_static.py",
            "timestamp": datetime.now().timestamp(),
            "issues": [
                {"line": 10, "column": 5, "message": "Unused variable", "severity": "warning"},
                {"line": 20, "column": 1, "message": "Missing docstring", "severity": "convention"}
            ],
            "metrics": {
                "complexity": 5.2,
                "maintainability": 8.1,
                "lines_of_code": 150
            }
        }

        static_key = f"static:{static_result['tool']}:{static_result['file_path']}"
        static_cache_success = cache.set(static_key, static_result, ttl=1800)  # 30åˆ†é’Ÿ
        print(f"   - é™æ€åˆ†æç¼“å­˜: {'âœ…' if static_cache_success else 'âŒ'}")

        cached_static = cache.get(static_key)
        static_valid = cached_static is not None and len(cached_static['issues']) == 2
        print(f"   - é™æ€ç¼“å­˜éªŒè¯: {'âœ…' if static_valid else 'âŒ'}")

        print("\n   æµ‹è¯•LLMå“åº”ç¼“å­˜:")
        # æ¨¡æ‹ŸLLMå“åº”
        llm_response = {
            "model": "glm-4.5",
            "prompt_hash": "abc123def456",
            "content": "è¿™æ˜¯LLMçš„åˆ†æå“åº”...",
            "usage": {"prompt_tokens": 200, "completion_tokens": 300, "total_tokens": 500},
            "response_time": 1.23,
            "timestamp": datetime.now().isoformat()
        }

        llm_key = f"llm:{llm_response['model']}:{llm_response['prompt_hash']}"
        llm_cache_success = cache.set(llm_key, llm_response, ttl=7200)  # 2å°æ—¶
        print(f"   - LLMå“åº”ç¼“å­˜: {'âœ…' if llm_cache_success else 'âŒ'}")

        cached_llm = cache.get(llm_key)
        llm_valid = cached_llm is not None and cached_llm['model'] == llm_response['model']
        print(f"   - LLMç¼“å­˜éªŒè¯: {'âœ…' if llm_valid else 'âŒ'}")

        # æµ‹è¯•ç¼“å­˜é”®ç”Ÿæˆ
        print("\n   æµ‹è¯•æ™ºèƒ½ç¼“å­˜é”®ç”Ÿæˆ:")
        def generate_cache_key(file_path, analysis_type, model=None, user_instructions=None):
            """ç”Ÿæˆæ™ºèƒ½ç¼“å­˜é”®"""
            key_parts = [analysis_type, file_path]
            if model:
                key_parts.append(model)
            if user_instructions:
                # å¯¹ç”¨æˆ·æŒ‡ä»¤è¿›è¡Œå“ˆå¸Œä»¥ä¿æŒé”®é•¿åº¦åˆç†
                import hashlib
                instruction_hash = hashlib.md5(user_instructions.encode()).hexdigest()[:8]
                key_parts.append(f"instr_{instruction_hash}")
            return ":".join(key_parts)

        test_key = generate_cache_key(
            "test_file.py",
            "security",
            model="glm-4.5",
            user_instructions="é‡ç‚¹å…³æ³¨å®‰å…¨é—®é¢˜"
        )
        print(f"   - æ™ºèƒ½é”®ç”Ÿæˆ: {test_key}")

        return cache_valid and static_valid and llm_valid

    except Exception as e:
        print(f"âŒ ç¼“å­˜åˆ†ææ•°æ®æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cache_persistence():
    """æµ‹è¯•ç¼“å­˜æŒä¹…åŒ–"""
    print("\nğŸ” æµ‹è¯•ç¼“å­˜æŒä¹…åŒ–...")

    try:
        from src.utils.cache import CacheManager

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç”¨äºæŒä¹…åŒ–ç¼“å­˜
        temp_dir = tempfile.mkdtemp()
        cache_file = os.path.join(temp_dir, "test_cache.json")

        print("   æµ‹è¯•ç¼“å­˜ä¿å­˜å’ŒåŠ è½½:")

        # åˆ›å»ºç¼“å­˜å¹¶æ·»åŠ æ•°æ®
        cache = CacheManager(backend_type='memory')
        test_data = {
            "persistent_key_1": "persistent_value_1",
            "persistent_key_2": {"nested": "data", "number": 42},
            "persistent_key_3": [1, 2, 3, 4, 5]
        }

        for key, value in test_data.items():
            cache.set(key, value, ttl=3600)

        print(f"   - åŸå§‹ç¼“å­˜æ¡ç›®: {cache.size()}")

        # å°è¯•ä¿å­˜ç¼“å­˜ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if hasattr(cache, 'save_to_file'):
            save_success = cache.save_to_file(cache_file)
            print(f"   - ç¼“å­˜ä¿å­˜: {'âœ…' if save_success else 'âŒ'}")

            # åˆ›å»ºæ–°çš„ç¼“å­˜å®ä¾‹å¹¶åŠ è½½
            new_cache = CacheManager(backend_type='memory')
            if hasattr(new_cache, 'load_from_file'):
                load_success = new_cache.load_from_file(cache_file)
                print(f"   - ç¼“å­˜åŠ è½½: {'âœ…' if load_success else 'âŒ'}")

                # éªŒè¯åŠ è½½çš„æ•°æ®
                loaded_correct = True
                for key, expected_value in test_data.items():
                    loaded_value = new_cache.get(key)
                    if loaded_value != expected_value:
                        print(f"   - é”® {key} åŠ è½½å¤±è´¥")
                        loaded_correct = False

                print(f"   - æ•°æ®å®Œæ•´æ€§: {'âœ…' if loaded_correct else 'âŒ'}")
        else:
            print("   - å½“å‰ç¼“å­˜åç«¯ä¸æ”¯æŒæŒä¹…åŒ–")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        shutil.rmtree(temp_dir)

        return True

    except Exception as e:
        print(f"âŒ ç¼“å­˜æŒä¹…åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    print("\nğŸ” æµ‹è¯•ç¼“å­˜æ€§èƒ½...")

    try:
        from src.utils.cache import CacheManager

        cache = CacheManager(backend_type='memory')

        print("   æµ‹è¯•å¤§é‡æ•°æ®ç¼“å­˜æ€§èƒ½:")
        # å¤§é‡æ•°æ®æµ‹è¯•
        large_data_sets = []

        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        for i in range(1000):
            large_data_sets.append({
                'id': i,
                'data': f'test_data_{i}',
                'metadata': {
                    'created_at': datetime.now().isoformat(),
                    'size': len(f'test_data_{i}') * 10,
                    'tags': [f'tag_{j}' for j in range(5)]
                }
            })

        print(f"   - ç”Ÿæˆæµ‹è¯•æ•°æ®: {len(large_data_sets)} æ¡")

        # æµ‹è¯•æ‰¹é‡å†™å…¥æ€§èƒ½
        start_time = time.time()
        successful_writes = 0
        for i, data in enumerate(large_data_sets):
            if cache.set(f"perf_test_{i}", data, ttl=300):
                successful_writes += 1

        write_time = time.time() - start_time
        write_rate = successful_writes / write_time

        print(f"   - å†™å…¥æ€§èƒ½: {write_rate:.0f} æ¡/ç§’")
        print(f"   - å†™å…¥æˆåŠŸç‡: {successful_writes}/{len(large_data_sets)} ({successful_writes/len(large_data_sets):.1%})")

        # æµ‹è¯•æ‰¹é‡è¯»å–æ€§èƒ½
        start_time = time.time()
        successful_reads = 0
        for i in range(len(large_data_sets)):
            if cache.get(f"perf_test_{i}") is not None:
                successful_reads += 1

        read_time = time.time() - start_time
        read_rate = successful_reads / read_time

        print(f"   - è¯»å–æ€§èƒ½: {read_rate:.0f} æ¡/ç§’")
        print(f"   - è¯»å–æˆåŠŸç‡: {successful_reads}/{len(large_data_sets)} ({successful_reads/len(large_data_sets):.1%})")

        print("\n   æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ:")
        cache_size = cache.size()
        print(f"   - ç¼“å­˜æ¡ç›®æ•°: {cache_size}")

        # æµ‹è¯•ç¼“å­˜æ¸…ç†
        print("\n   æµ‹è¯•ç¼“å­˜æ¸…ç†æ€§èƒ½:")
        start_time = time.time()
        cache.clear()
        clear_time = time.time() - start_time
        final_size = cache.size()

        print(f"   - æ¸…ç†æ—¶é—´: {clear_time:.3f}ç§’")
        print(f"   - æ¸…ç†åå¤§å°: {final_size}")

        # æ€§èƒ½åŸºå‡†æµ‹è¯•
        performance_good = write_rate > 1000 and read_rate > 5000 and final_size == 0
        print(f"   - æ€§èƒ½è¯„ä¼°: {'âœ… è‰¯å¥½' if performance_good else 'âŒ éœ€è¦ä¼˜åŒ–'}")

        return performance_good

    except Exception as e:
        print(f"âŒ ç¼“å­˜æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cache_integration():
    """æµ‹è¯•ç¼“å­˜é›†æˆåŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•ç¼“å­˜é›†æˆåŠŸèƒ½...")

    try:
        from src.utils.cache import CacheManager

        cache = CacheManager(backend_type='memory')

        print("   æµ‹è¯•ä¸åˆ†æå·¥å…·é›†æˆ:")

        # æ¨¡æ‹Ÿæ–‡ä»¶åˆ†æç¼“å­˜
        def mock_file_analysis(file_path, analysis_type):
            """Mockæ–‡ä»¶åˆ†æå‡½æ•°"""
            time.sleep(0.1)  # æ¨¡æ‹Ÿåˆ†ææ—¶é—´
            return {
                "file_path": file_path,
                "analysis_type": analysis_type,
                "result": f"Analysis of {file_path} for {analysis_type}",
                "timestamp": datetime.now().isoformat()
            }

        def cached_file_analysis(file_path, analysis_type):
            """å¸¦ç¼“å­˜çš„æ–‡ä»¶åˆ†æå‡½æ•°"""
            cache_key = f"analysis:{file_path}:{analysis_type}"
            return cache.get_or_set(cache_key,
                                   lambda: mock_file_analysis(file_path, analysis_type),
                                   ttl=3600)

        # æµ‹è¯•ç¼“å­˜æ•ˆæœ
        test_files = ["test1.py", "test2.js", "test3.java"]
        analysis_types = ["comprehensive", "security", "performance"]

        print("   ç¬¬ä¸€æ¬¡åˆ†æï¼ˆæ— ç¼“å­˜ï¼‰:")
        start_time = time.time()
        first_results = []
        for file_path in test_files:
            for analysis_type in analysis_types:
                result = cached_file_analysis(file_path, analysis_type)
                first_results.append(result)
        first_time = time.time() - start_time

        print("   ç¬¬äºŒæ¬¡åˆ†æï¼ˆæœ‰ç¼“å­˜ï¼‰:")
        start_time = time.time()
        second_results = []
        for file_path in test_files:
            for analysis_type in analysis_types:
                result = cached_file_analysis(file_path, analysis_type)
                second_results.append(result)
        second_time = time.time() - start_time

        speedup = first_time / second_time if second_time > 0 else float('inf')
        print(f"   - ç¬¬ä¸€æ¬¡åˆ†ææ—¶é—´: {first_time:.3f}ç§’")
        print(f"   - ç¬¬äºŒæ¬¡åˆ†ææ—¶é—´: {second_time:.3f}ç§’")
        print(f"   - ç¼“å­˜åŠ é€Ÿæ¯”: {speedup:.1f}x")
        print(f"   - ç»“æœä¸€è‡´æ€§: {'âœ…' if first_results == second_results else 'âŒ'}")

        print("\n   æµ‹è¯•ç¼“å­˜å¤±æ•ˆç­–ç•¥:")
        # æ¨¡æ‹Ÿç¼“å­˜å¤±æ•ˆ
        cache.set("will_expire", "value", ttl=1)
        before_expire = cache.get("will_expire")
        time.sleep(2)
        after_expire = cache.get("will_expire")

        print(f"   - è¿‡æœŸå‰è·å–: {before_expire}")
        print(f"   - è¿‡æœŸåè·å–: {after_expire}")
        expire_working = before_expire == "value" and after_expire is None

        return speedup > 5 and first_results == second_results and expire_working

    except Exception as e:
        print(f"âŒ ç¼“å­˜é›†æˆåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹é«˜çº§ç¼“å­˜ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)

    test_results = []

    # 1. æµ‹è¯•ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–
    init_ok = test_cache_manager_initialization()
    test_results.append(init_ok)

    # 2. æµ‹è¯•å†…å­˜ç¼“å­˜æ“ä½œ
    memory_ok = test_memory_cache_operations()
    test_results.append(memory_ok)

    # 3. æµ‹è¯•ç¼“å­˜TTLåŠŸèƒ½
    ttl_ok = test_cache_ttl_functionality()
    test_results.append(ttl_ok)

    # 4. æµ‹è¯•ç¼“å­˜é«˜çº§æ“ä½œ
    advanced_ok = test_cache_advanced_operations()
    test_results.append(advanced_ok)

    # 5. æµ‹è¯•ç¼“å­˜åˆ†ææ•°æ®
    analysis_ok = test_cache_with_analysis_data()
    test_results.append(analysis_ok)

    # 6. æµ‹è¯•ç¼“å­˜æŒä¹…åŒ–
    persistence_ok = test_cache_persistence()
    test_results.append(persistence_ok)

    # 7. æµ‹è¯•ç¼“å­˜æ€§èƒ½
    performance_ok = test_cache_performance()
    test_results.append(performance_ok)

    # 8. æµ‹è¯•ç¼“å­˜é›†æˆåŠŸèƒ½
    integration_ok = test_cache_integration()
    test_results.append(integration_ok)

    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")

    passed = sum(test_results)
    total = len(test_results)

    print(f"âœ… é€šè¿‡: {passed}/{total}")
    print(f"âŒ å¤±è´¥: {total-passed}/{total}")

    if passed >= total * 0.8:  # 80%é€šè¿‡ç‡
        print("\nğŸ‰ é«˜çº§ç¼“å­˜ç³»ç»Ÿæµ‹è¯•åŸºæœ¬é€šè¿‡ï¼")
        print("ç¼“å­˜ç³»ç»Ÿçš„åˆå§‹åŒ–å’Œæ ¸å¿ƒåŠŸèƒ½å·²å°±ç»ªã€‚")
        if passed < total:
            print(f"âš ï¸ æœ‰ {total-passed} é¡¹æµ‹è¯•å¤±è´¥ï¼Œä½†ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ã€‚")
        return 0
    else:
        print(f"\nâš ï¸ ä»…æœ‰ {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡ï¼Œéœ€è¦æ£€æŸ¥ç¼“å­˜ç³»ç»Ÿã€‚")
        return 1

if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        sys.exit(0)
    except Exception as e:
        print(f"\næµ‹è¯•å¼‚å¸¸: {e}")
        sys.exit(1)