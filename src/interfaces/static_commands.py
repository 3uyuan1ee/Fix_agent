#!/usr/bin/env python3
"""
é™æ€åˆ†æå‘½ä»¤æ¨¡å—
å®ç°`analyze static`å‘½ä»¤çš„å¤„ç†é€»è¾‘
"""

import sys
import time
import threading
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
import json

from ..utils.logger import get_logger
from ..utils.config import ConfigManager
from ..agent.orchestrator import AgentOrchestrator
from ..agent.planner import AnalysisMode
from ..agent.user_interaction import ResponseFormatter, OutputFormat

logger = get_logger()


@dataclass
class StaticAnalysisResult:
    """é™æ€åˆ†æç»“æœæ•°æ®ç±»"""
    success: bool
    total_files: int
    analyzed_files: int
    total_issues: int
    issues_by_severity: Dict[str, int]
    issues_by_type: Dict[str, int]
    tool_results: Dict[str, Any]
    execution_time: float
    summary: str


class ProgressTracker:
    """è¿›åº¦è·Ÿè¸ªå™¨"""

    def __init__(self, total_files: int):
        self.total_files = total_files
        self.processed_files = 0
        self.current_tool = ""
        self.start_time = time.time()
        self._lock = threading.Lock()

    def update(self, processed_files: int = None, current_tool: str = ""):
        """æ›´æ–°è¿›åº¦"""
        with self._lock:
            # åªæ›´æ–°æ–‡ä»¶æ•°é‡ï¼ˆå¦‚æœæ˜ç¡®æä¾›äº†processed_fileså‚æ•°ï¼‰
            if processed_files is not None and processed_files > 0:
                self.processed_files += processed_files
            # æ›´æ–°å½“å‰å·¥å…·ï¼ˆå¦‚æœæä¾›äº†current_toolå‚æ•°ï¼‰
            if current_tool:
                self.current_tool = current_tool

    def get_progress_info(self) -> Dict[str, Any]:
        """è·å–è¿›åº¦ä¿¡æ¯"""
        with self._lock:
            elapsed = time.time() - self.start_time
            percentage = (self.processed_files / self.total_files * 100) if self.total_files > 0 else 0

            return {
                "processed_files": self.processed_files,
                "total_files": self.total_files,
                "percentage": percentage,
                "current_tool": self.current_tool,
                "elapsed_time": elapsed,
                "estimated_remaining": (elapsed / self.processed_files * (self.total_files - self.processed_files)) if self.processed_files > 0 else 0
            }


class StaticAnalysisCommand:
    """é™æ€åˆ†æå‘½ä»¤å¤„ç†å™¨"""

    def __init__(self, config: Optional[ConfigManager] = None):
        """åˆå§‹åŒ–é™æ€åˆ†æå‘½ä»¤å¤„ç†å™¨"""
        self.config = config or ConfigManager()
        # ç¡®ä¿é…ç½®å·²åŠ è½½
        if not hasattr(self.config, '_config') or self.config._config is None:
            try:
                self.config.load_config()
            except Exception:
                # å¦‚æœé…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
                self.config._config = {
                    'static_analysis': {
                        'tools': {
                            'pylint': {'enabled': True},
                            'bandit': {'enabled': True},
                            'flake8': {'enabled': True},
                            'mypy': {'enabled': True}
                        }
                    }
                }
        self.orchestrator = AgentOrchestrator()
        self.formatter = ResponseFormatter()

    def execute_static_analysis(
        self,
        target: str,
        tools: Optional[List[str]] = None,
        output_format: str = "simple",
        output_file: Optional[str] = None,
        verbose: bool = False,
        quiet: bool = False,
        dry_run: bool = False
    ) -> StaticAnalysisResult:
        """
        æ‰§è¡Œé™æ€åˆ†æ

        Args:
            target: ç›®æ ‡æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
            tools: æŒ‡å®šçš„åˆ†æå·¥å…·åˆ—è¡¨
            output_format: è¾“å‡ºæ ¼å¼
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            verbose: è¯¦ç»†æ¨¡å¼
            quiet: é™é»˜æ¨¡å¼
            dry_run: æ¨¡æ‹Ÿè¿è¡Œ

        Returns:
            StaticAnalysisResult: åˆ†æç»“æœ
        """
        start_time = time.time()
        target_path = Path(target)

        if not target_path.exists():
            raise FileNotFoundError(f"ç›®æ ‡è·¯å¾„ä¸å­˜åœ¨: {target}")

        # 1. è·å–è¦åˆ†æçš„æ–‡ä»¶åˆ—è¡¨
        if not quiet:
            print(f"ğŸ” æ‰«æç›®æ ‡è·¯å¾„: {target}")

        files_to_analyze = self._get_files_to_analyze(target_path)
        if not files_to_analyze:
            if not quiet:
                print("âš ï¸  æœªæ‰¾åˆ°å¯åˆ†æçš„Pythonæ–‡ä»¶")
            return StaticAnalysisResult(
                success=False,
                total_files=0,
                analyzed_files=0,
                total_issues=0,
                issues_by_severity={},
                issues_by_type={},
                tool_results={},
                execution_time=0,
                summary="æœªæ‰¾åˆ°å¯åˆ†æçš„Pythonæ–‡ä»¶"
            )

        if not quiet:
            print(f"ğŸ“ æ‰¾åˆ° {len(files_to_analyze)} ä¸ªPythonæ–‡ä»¶")

        # 2. ç¡®å®šè¦ä½¿ç”¨çš„å·¥å…·
        selected_tools = self._get_selected_tools(tools)
        if not selected_tools:
            if not quiet:
                print("âš ï¸  æ²¡æœ‰å¯ç”¨çš„åˆ†æå·¥å…·")
            return StaticAnalysisResult(
                success=False,
                total_files=len(files_to_analyze),
                analyzed_files=0,
                total_issues=0,
                issues_by_severity={},
                issues_by_type={},
                tool_results={},
                execution_time=0,
                summary="æ²¡æœ‰å¯ç”¨çš„åˆ†æå·¥å…·"
            )

        if not quiet:
            print(f"ğŸ”§ ä½¿ç”¨å·¥å…·: {', '.join(selected_tools)}")

        # 3. æ¨¡æ‹Ÿè¿è¡Œ
        if dry_run:
            if not quiet:
                print("ğŸƒ æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ - ä¸ä¼šæ‰§è¡Œå®é™…åˆ†æ")
            return StaticAnalysisResult(
                success=True,
                total_files=len(files_to_analyze),
                analyzed_files=len(files_to_analyze),
                total_issues=0,
                issues_by_severity={},
                issues_by_type={},
                tool_results={tool: "dry_run" for tool in selected_tools},
                execution_time=0.1,
                summary="æ¨¡æ‹Ÿè¿è¡Œå®Œæˆ"
            )

        # 4. æ‰§è¡Œåˆ†æ
        if not quiet:
            print("ğŸš€ å¼€å§‹é™æ€åˆ†æ...")

        progress_tracker = ProgressTracker(len(files_to_analyze))

        # æ˜¾ç¤ºè¿›åº¦
        if not quiet and not verbose:
            progress_thread = threading.Thread(
                target=self._show_progress,
                args=(progress_tracker,),
                daemon=True
            )
            progress_thread.start()

        # æ‰§è¡Œåˆ†æ
        analysis_results = self._run_analysis(
            files_to_analyze,
            selected_tools,
            progress_tracker,
            verbose
        )

        execution_time = time.time() - start_time

        # 5. å¤„ç†ç»“æœ
        result = self._process_analysis_results(
            analysis_results,
            selected_tools,
            len(files_to_analyze),
            execution_time
        )

        # 6. è¾“å‡ºç»“æœ
        if not quiet:
            self._display_results(result, output_format, verbose)

        # 7. ä¿å­˜åˆ°æ–‡ä»¶
        if output_file:
            self._save_results(result, output_file, output_format)

        return result

    def _get_files_to_analyze(self, target_path: Path) -> List[str]:
        """è·å–è¦åˆ†æçš„æ–‡ä»¶åˆ—è¡¨"""
        files = []

        if target_path.is_file():
            if target_path.suffix == '.py':
                files.append(str(target_path))
        elif target_path.is_dir():
            # é€’å½’æŸ¥æ‰¾Pythonæ–‡ä»¶
            for py_file in target_path.rglob('*.py'):
                # è·³è¿‡éšè—æ–‡ä»¶å’Œæµ‹è¯•æ–‡ä»¶ï¼ˆæ ¹æ®é…ç½®ï¼‰
                if not self._should_skip_file(py_file):
                    files.append(str(py_file))

        return sorted(files)

    def _should_skip_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶"""
        # è·³è¿‡éšè—æ–‡ä»¶
        if file_path.name.startswith('.'):
            return True

        # å¯ä»¥æ ¹æ®é…ç½®æ·»åŠ æ›´å¤šè·³è¿‡è§„åˆ™
        skip_patterns = ['__pycache__', '.git', '.pytest_cache', 'venv', 'env']
        return any(pattern in str(file_path) for pattern in skip_patterns)

    def _get_selected_tools(self, requested_tools: Optional[List[str]]) -> List[str]:
        """è·å–é€‰ä¸­çš„åˆ†æå·¥å…·"""
        try:
            # æ£€æŸ¥é…ç½®æ˜¯å¦å·²åŠ è½½
            if not hasattr(self.config, '_config') or self.config._config is None:
                # ä½¿ç”¨é»˜è®¤å·¥å…·é…ç½®
                enabled_tools = ['pylint', 'bandit', 'flake8', 'mypy']
            else:
                tools_config = self.config.get_section('static_analysis')

                # é€‚é…å®é™…é…ç½®æ–‡ä»¶æ ¼å¼
                if 'enabled_tools' in tools_config:
                    # æ–°æ ¼å¼ï¼šä½¿ç”¨ enabled_tools åˆ—è¡¨
                    enabled_tools = tools_config['enabled_tools']
                elif 'tools' in tools_config:
                    # æ—§æ ¼å¼ï¼šä½¿ç”¨ tools å­—å…¸
                    available_tools = tools_config['tools']
                    enabled_tools = [
                        name for name, config in available_tools.items()
                        if config.get('enabled', True)
                    ]
                else:
                    # é»˜è®¤å·¥å…·åˆ—è¡¨
                    enabled_tools = ['pylint', 'bandit', 'flake8', 'mypy']

            # å¦‚æœç”¨æˆ·æŒ‡å®šäº†å·¥å…·ï¼Œè¿›è¡Œè¿‡æ»¤
            if requested_tools:
                selected_tools = []
                for tool in requested_tools:
                    if tool in enabled_tools:
                        selected_tools.append(tool)
                    else:
                        logger.warning(f"å·¥å…· '{tool}' ä¸å¯ç”¨æˆ–æœªå¯ç”¨")
                return selected_tools

            return enabled_tools

        except Exception as e:
            logger.error(f"è·å–å·¥å…·é…ç½®å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤å·¥å…·åˆ—è¡¨
            return ['pylint', 'bandit', 'flake8', 'mypy']

    def _run_analysis(
        self,
        files: List[str],
        tools: List[str],
        progress_tracker: ProgressTracker,
        verbose: bool
    ) -> Dict[str, Any]:
        """è¿è¡Œåˆ†æ"""
        results = {}

        for tool in tools:
            if verbose:
                print(f"  ğŸ”„ è¿è¡Œ {tool} åˆ†æ...")

            tool_results = self._run_tool_analysis(tool, files, progress_tracker, verbose)
            results[tool] = tool_results

        return results

    def _run_tool_analysis(
        self,
        tool: str,
        files: List[str],
        progress_tracker: ProgressTracker,
        verbose: bool
    ) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªå·¥å…·çš„åˆ†æ"""
        progress_tracker.update(processed_files=0, current_tool=tool)

        # åˆ›å»ºä¸´æ—¶ä¼šè¯
        session = self.orchestrator.create_session()

        try:
            # æ„å»ºåˆ†æå‘½ä»¤
            command = f"{tool}åˆ†æ {' '.join(files[:5])}"  # é™åˆ¶æ–‡ä»¶æ•°é‡é¿å…å‘½ä»¤è¿‡é•¿

            if verbose:
                print(f"    ğŸ“ åˆ†æå‘½ä»¤: {command[:100]}...")

            # æ‰§è¡Œåˆ†æ
            result = self.orchestrator.process_user_input(session, command)

            progress_tracker.update(len(files))

            return {
                "success": result.get("success", False),
                "message": result.get("message", ""),
                "data": result.get("data", {}),
                "issues": result.get("issues", [])
            }

        except Exception as e:
            logger.error(f"å·¥å…· {tool} åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "message": f"åˆ†æå¤±è´¥: {e}",
                "data": {},
                "issues": []
            }
        finally:
            self.orchestrator.close_session(session)

    def _show_progress(self, progress_tracker: ProgressTracker):
        """æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯"""
        import sys

        while progress_tracker.processed_files < progress_tracker.total_files:
            info = progress_tracker.get_progress_info()

            # æ„å»ºè¿›åº¦æ¡
            bar_length = 30
            filled_length = int(bar_length * info['percentage'] / 100)
            bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)

            # æ˜¾ç¤ºè¿›åº¦
            sys.stdout.write(f'\rğŸ”„ åˆ†æè¿›åº¦: |{bar}| {info["percentage"]:.1f}% '
                           f'({info["processed_files"]}/{info["total_files"]}) '
                           f'å·¥å…·: {info["current_tool"]} '
                           f'è€—æ—¶: {info["elapsed_time"]:.1f}s')
            sys.stdout.flush()

            time.sleep(0.5)

        # è¿›åº¦å®Œæˆ
        sys.stdout.write(f'\râœ… åˆ†æå®Œæˆ! æ€»å…±åˆ†æäº† {progress_tracker.total_files} ä¸ªæ–‡ä»¶\n')
        sys.stdout.flush()

    def _process_analysis_results(
        self,
        analysis_results: Dict[str, Any],
        tools: List[str],
        total_files: int,
        execution_time: float
    ) -> StaticAnalysisResult:
        """å¤„ç†åˆ†æç»“æœ"""
        total_issues = 0
        issues_by_severity = {"error": 0, "warning": 0, "info": 0}
        issues_by_type = {}
        analyzed_files = 0

        for tool, result in analysis_results.items():
            if result.get("success", False):
                analyzed_files += 1
                issues = result.get("issues", [])

                for issue in issues:
                    total_issues += 1

                    # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»
                    severity = issue.get("severity", "info").lower()
                    if severity in issues_by_severity:
                        issues_by_severity[severity] += 1

                    # æŒ‰ç±»å‹åˆ†ç±»
                    issue_type = issue.get("type", "other")
                    issues_by_type[issue_type] = issues_by_type.get(issue_type, 0) + 1

        # ç”Ÿæˆæ‘˜è¦
        summary_parts = []
        if total_issues > 0:
            summary_parts.append(f"å‘ç° {total_issues} ä¸ªé—®é¢˜")
            if issues_by_severity["error"] > 0:
                summary_parts.append(f"{issues_by_severity['error']} ä¸ªé”™è¯¯")
            if issues_by_severity["warning"] > 0:
                summary_parts.append(f"{issues_by_severity['warning']} ä¸ªè­¦å‘Š")
        else:
            summary_parts.append("æœªå‘ç°é—®é¢˜")

        summary = "ï¼Œ".join(summary_parts)

        return StaticAnalysisResult(
            success=True,
            total_files=total_files,
            analyzed_files=analyzed_files,
            total_issues=total_issues,
            issues_by_severity=issues_by_severity,
            issues_by_type=issues_by_type,
            tool_results=analysis_results,
            execution_time=execution_time,
            summary=summary
        )

    def _display_results(self, result: StaticAnalysisResult, output_format: str, verbose: bool):
        """æ˜¾ç¤ºåˆ†æç»“æœ"""
        if output_format == "simple":
            self._display_simple_results(result)
        elif output_format == "detailed":
            self._display_detailed_results(result, verbose)
        elif output_format == "json":
            self._display_json_results(result)
        elif output_format == "table":
            self._display_table_results(result)
        elif output_format == "markdown":
            self._display_markdown_results(result)

    def _display_simple_results(self, result: StaticAnalysisResult):
        """æ˜¾ç¤ºç®€æ´ç»“æœ"""
        print(f"\nğŸ“Š åˆ†æç»“æœæ‘˜è¦:")
        print(f"   åˆ†ææ–‡ä»¶: {result.analyzed_files}/{result.total_files}")
        print(f"   æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")
        print(f"   é—®é¢˜æ€»æ•°: {result.total_issues}")

        if result.issues_by_severity:
            print(f"   ä¸¥é‡ç¨‹åº¦: é”™è¯¯({result.issues_by_severity.get('error', 0)}) "
                  f"è­¦å‘Š({result.issues_by_severity.get('warning', 0)}) "
                  f"ä¿¡æ¯({result.issues_by_severity.get('info', 0)})")

        print(f"   ğŸ“ {result.summary}")

    def _display_detailed_results(self, result: StaticAnalysisResult, verbose: bool):
        """æ˜¾ç¤ºè¯¦ç»†ç»“æœ"""
        self._display_simple_results(result)

        print(f"\nğŸ”§ å·¥å…·æ‰§è¡Œç»“æœ:")
        for tool, tool_result in result.tool_results.items():
            status = "âœ…" if tool_result.get("success", False) else "âŒ"
            message = tool_result.get("message", "")
            issues_count = len(tool_result.get("issues", []))
            print(f"   {status} {tool}: {issues_count} ä¸ªé—®é¢˜ - {message}")

        if result.issues_by_type and verbose:
            print(f"\nğŸ“ˆ é—®é¢˜ç±»å‹åˆ†å¸ƒ:")
            for issue_type, count in result.issues_by_type.items():
                print(f"   {issue_type}: {count}")

    def _display_json_results(self, result: StaticAnalysisResult):
        """æ˜¾ç¤ºJSONç»“æœ"""
        result_dict = {
            "success": result.success,
            "summary": result.summary,
            "statistics": {
                "total_files": result.total_files,
                "analyzed_files": result.analyzed_files,
                "total_issues": result.total_issues,
                "execution_time": result.execution_time
            },
            "issues_by_severity": result.issues_by_severity,
            "issues_by_type": result.issues_by_type,
            "tool_results": result.tool_results
        }
        print(json.dumps(result_dict, indent=2, ensure_ascii=False))

    def _display_table_results(self, result: StaticAnalysisResult):
        """æ˜¾ç¤ºè¡¨æ ¼ç»“æœ"""
        print(f"\nğŸ“Š é™æ€åˆ†æç»“æœè¡¨")
        print("=" * 60)
        print(f"{'é¡¹ç›®':<15} {'æ•°é‡':<10}")
        print("-" * 60)
        print(f"{'åˆ†ææ–‡ä»¶':<15} {result.analyzed_files:<10}")
        print(f"{'æ€»æ–‡ä»¶æ•°':<15} {result.total_files:<10}")
        print(f"{'å‘ç°é—®é¢˜':<15} {result.total_issues:<10}")
        print("=" * 60)

        if result.issues_by_severity:
            print(f"\næŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»:")
            print("-" * 60)
            for severity, count in result.issues_by_severity.items():
                print(f"{severity.capitalize():<15} {count:<10}")

    def _display_markdown_results(self, result: StaticAnalysisResult):
        """æ˜¾ç¤ºMarkdownç»“æœ"""
        print(f"\n# é™æ€åˆ†ææŠ¥å‘Š\n")
        print(f"## æ‘˜è¦")
        print(f"- **åˆ†ææ–‡ä»¶**: {result.analyzed_files}/{result.total_files}")
        print(f"- **æ‰§è¡Œæ—¶é—´**: {result.execution_time:.2f}ç§’")
        print(f"- **å‘ç°é—®é¢˜**: {result.total_issues}")
        print(f"- **ç»“æœ**: {result.summary}\n")

        if result.issues_by_severity:
            print(f"## ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ")
            for severity, count in result.issues_by_severity.items():
                print(f"- **{severity.capitalize()}**: {count}")

    def _save_results(self, result: StaticAnalysisResult, output_file: str, output_format: str):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        try:
            output_path = Path(output_file)

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(output_path, 'w', encoding='utf-8') as f:
                if output_format == 'json':
                    result_dict = {
                        "success": result.success,
                        "summary": result.summary,
                        "statistics": {
                            "total_files": result.total_files,
                            "analyzed_files": result.analyzed_files,
                            "total_issues": result.total_issues,
                            "execution_time": result.execution_time
                        },
                        "issues_by_severity": result.issues_by_severity,
                        "issues_by_type": result.issues_by_type,
                        "tool_results": result.tool_results
                    }
                    json.dump(result_dict, f, indent=2, ensure_ascii=False)
                else:
                    # ä¿å­˜æ–‡æœ¬æ ¼å¼
                    f.write(f"é™æ€åˆ†ææŠ¥å‘Š\n")
                    f.write(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"åˆ†ææ–‡ä»¶: {result.analyzed_files}/{result.total_files}\n")
                    f.write(f"æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’\n")
                    f.write(f"é—®é¢˜æ€»æ•°: {result.total_issues}\n")
                    f.write(f"æ‘˜è¦: {result.summary}\n")

                    if result.issues_by_severity:
                        f.write(f"\nä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ:\n")
                        for severity, count in result.issues_by_severity.items():
                            f.write(f"  {severity}: {count}\n")

            print(f"ğŸ“„ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

        except Exception as e:
            logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")