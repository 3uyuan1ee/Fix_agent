#!/usr/bin/env python3
"""
CLIåˆ†æåè°ƒå™¨
ä¸ºCLIå‘½ä»¤è¡Œæ¥å£æä¾›ç®€åŒ–çš„åˆ†æåè°ƒåŠŸèƒ½
"""

import json
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

from ..utils.logger import get_logger
from ..utils.progress import ProgressTracker
from .static_coordinator import StaticAnalysisCoordinator


class ConversationContext:
    """å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def __init__(self, target: str, max_context_length: int = 10):
        """
        åˆå§‹åŒ–å¯¹è¯ä¸Šä¸‹æ–‡

        Args:
            target: åˆ†æç›®æ ‡
            max_context_length: æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆè½®å¯¹è¯ï¼‰
        """
        self.target = target
        self.max_context_length = max_context_length
        self.session_start = self._get_current_time()
        self.conversation_history = []
        self.analysis_context = {
            'target': target,
            'analysis_type': 'comprehensive',
            'current_file': None,
            'previous_results': [],
            'preferences': {},
            'user_patterns': {},
            'session_stats': {
                'total_analyses': 0,
                'successful_analyses': 0,
                'failed_analyses': 0,
                'total_time': 0.0
            }
        }

    def add_message(self, user_input: str, ai_response: str, message_type: str = 'general'):
        """æ·»åŠ å¯¹è¯æ¶ˆæ¯"""
        message = {
            'timestamp': self._get_current_time(),
            'type': message_type,
            'user_input': user_input,
            'ai_response': ai_response,
            'session_time': self._get_session_duration()
        }

        self.conversation_history.append(message)
        self._trim_context()

    def add_analysis_result(self, file_path: str, analysis_type: str, result: dict, execution_time: float):
        """æ·»åŠ åˆ†æç»“æœ"""
        analysis_entry = {
            'timestamp': self._get_current_time(),
            'type': 'file_analysis',
            'file_path': file_path,
            'analysis_type': analysis_type,
            'result': result,
            'execution_time': execution_time,
            'success': result.get('success', False),
            'session_time': self._get_session_duration()
        }

        self.conversation_history.append(analysis_entry)
        self.analysis_context['previous_results'].append(analysis_entry)
        self.analysis_context['current_file'] = file_path

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.analysis_context['session_stats']['total_analyses'] += 1
        if result.get('success', False):
            self.analysis_context['session_stats']['successful_analyses'] += 1
        else:
            self.analysis_context['session_stats']['failed_analyses'] += 1
        self.analysis_context['session_stats']['total_time'] += execution_time

        self._trim_context()

    def set_analysis_type(self, analysis_type: str):
        """è®¾ç½®åˆ†æç±»å‹"""
        self.analysis_context['analysis_type'] = analysis_type
        # è®°å½•ç”¨æˆ·åå¥½
        if 'analysis_type' not in self.analysis_context['user_patterns']:
            self.analysis_context['user_patterns']['analysis_type'] = {}
        if analysis_type not in self.analysis_context['user_patterns']['analysis_type']:
            self.analysis_context['user_patterns']['analysis_type'][analysis_type] = 0
        self.analysis_context['user_patterns']['analysis_type'][analysis_type] += 1

    def set_preference(self, key: str, value: any):
        """è®¾ç½®ç”¨æˆ·åå¥½"""
        self.analysis_context['preferences'][key] = value

    def get_context_summary(self) -> str:
        """è·å–ä¸Šä¸‹æ–‡æ‘˜è¦"""
        history = self.conversation_history
        if not history:
            return "è¿™æ˜¯æˆ‘ä»¬çš„ç¬¬ä¸€æ¬¡å¯¹è¯"

        recent_analyses = [entry for entry in history[-5:] if entry.get('type') == 'file_analysis']
        if recent_analyses:
            last_file = recent_analyses[-1].get('file_path', 'unknown')
            last_type = recent_analyses[-1].get('analysis_type', 'unknown')
            return f"æœ€è¿‘åˆ†æäº† {Path(last_file).name} (ç±»å‹: {last_type})"

        recent_messages = history[-3:]
        if recent_messages:
            return f"æˆ‘ä»¬æœ€è¿‘è®¨è®ºäº† {len(recent_messages)} ä¸ªè¯é¢˜"

        return f"æˆ‘ä»¬å·²ç»è¿›è¡Œäº† {len(history)} è½®å¯¹è¯"

    def get_recent_context(self, num_entries: int = 3) -> list:
        """è·å–æœ€è¿‘çš„ä¸Šä¸‹æ–‡"""
        return self.conversation_history[-num_entries:]

    def get_file_analysis_history(self, file_path: str = None) -> list:
        """è·å–æ–‡ä»¶åˆ†æå†å²"""
        analyses = [entry for entry in self.conversation_history if entry.get('type') == 'file_analysis']

        if file_path:
            analyses = [entry for entry in analyses if file_path in entry.get('file_path', '')]

        return analyses

    def get_session_stats(self) -> dict:
        """è·å–ä¼šè¯ç»Ÿè®¡"""
        stats = self.analysis_context['session_stats'].copy()
        stats.update({
            'session_duration': self._get_session_duration(),
            'total_messages': len(self.conversation_history),
            'files_analyzed': len(set(entry.get('file_path', '') for entry in self.conversation_history if entry.get('type') == 'file_analysis')),
            'most_used_analysis_type': self._get_most_used_analysis_type()
        })
        return stats

    def _trim_context(self):
        """ä¿®å‰ªä¸Šä¸‹æ–‡ä»¥ä¿æŒåœ¨æœ€å¤§é•¿åº¦å†…"""
        if len(self.conversation_history) > self.max_context_length:
            # ä¿ç•™é‡è¦çš„åˆ†æç»“æœ
            important_entries = []
            regular_entries = []

            for entry in self.conversation_history:
                if entry.get('type') == 'file_analysis' and entry.get('success', False):
                    important_entries.append(entry)
                else:
                    regular_entries.append(entry)

            # ä¼˜å…ˆä¿ç•™é‡è¦çš„åˆ†æç»“æœ
            self.conversation_history = important_entries + regular_entries[-(self.max_context_length - len(important_entries)):]

    def _get_most_used_analysis_type(self) -> str:
        """è·å–æœ€å¸¸ç”¨çš„åˆ†æç±»å‹"""
        patterns = self.analysis_context['user_patterns'].get('analysis_type', {})
        if patterns:
            return max(patterns.items(), key=lambda x: x[1])[0]
        return 'comprehensive'

    def _get_session_duration(self) -> float:
        """è·å–ä¼šè¯æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰"""
        from datetime import datetime
        start_time = datetime.strptime(self.session_start, "%Y-%m-%d %H:%M:%S")
        current_time = datetime.now()
        return (current_time - start_time).total_seconds()

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'target': self.target,
            'session_start': self.session_start,
            'conversation_history': self.conversation_history,
            'analysis_context': self.analysis_context,
            'max_context_length': self.max_context_length
        }


@dataclass
class CLIStaticCoordinator:
    """CLIé™æ€åˆ†æåè°ƒå™¨"""

    def __init__(self, tools: Optional[List[str]] = None, format: str = "simple",
                 output_file: Optional[str] = None, dry_run: bool = False,
                 progress: Optional[ProgressTracker] = None):
        """
        åˆå§‹åŒ–CLIé™æ€åˆ†æåè°ƒå™¨

        Args:
            tools: æŒ‡å®šçš„å·¥å…·åˆ—è¡¨
            format: è¾“å‡ºæ ¼å¼
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œ
            progress: è¿›åº¦è·Ÿè¸ªå™¨
        """
        self.tools = tools or ['ast', 'pylint', 'flake8']
        self.format = format
        self.output_file = output_file
        self.dry_run = dry_run
        self.progress = progress or ProgressTracker()
        self.logger = get_logger()

        # åˆ›å»ºé™æ€åˆ†æåè°ƒå™¨
        self.coordinator = StaticAnalysisCoordinator()
        if tools:
            self.coordinator.set_enabled_tools(tools)

    def analyze(self, target: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œé™æ€åˆ†æ

        Args:
            target: ç›®æ ‡è·¯å¾„

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            if self.dry_run:
                print(f"ğŸ” [è¯•è¿è¡Œ] å°†åˆ†æ: {target}")
                return {
                    'dry_run': True,
                    'target': target,
                    'tools': self.tools,
                    'format': self.format
                }

            target_path = Path(target)

            if not target_path.exists():
                print(f"âŒ é”™è¯¯: ç›®æ ‡è·¯å¾„ä¸å­˜åœ¨: {target}")
                return {'error': f"Target path does not exist: {target}"}

            # æ”¶é›†æ–‡ä»¶
            files = self._collect_files(target_path)
            if not files:
                print(f"âš ï¸  è­¦å‘Š: åœ¨ {target} ä¸­æœªæ‰¾åˆ°Pythonæ–‡ä»¶")
                return {
                    'target': target,
                    'files_analyzed': 0,
                    'total_issues': 0,
                    'files': []
                }

            # å¼€å§‹åˆ†æ
            self.progress.start(len(files))
            self.progress.update_file_count(0)

            all_results = []
            total_issues = 0

            for i, file_path in enumerate(files):
                self.progress.show_file_progress(file_path, i, len(files))

                try:
                    result = self.coordinator.analyze_file(file_path)
                    all_results.append(result)
                    total_issues += len(result.issues)
                    self.progress.update_issue_count(total_issues)

                    # æ˜¾ç¤ºå®æ—¶è¿›åº¦
                    if self.progress.verbose:
                        for issue in result.issues[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
                            print(f"  ğŸ“ {result.file_path}:{issue.line} - {issue.message}")

                except Exception as e:
                    self.logger.error(f"Failed to analyze {file_path}: {e}")
                    if self.progress.verbose:
                        print(f"  âŒ åˆ†æå¤±è´¥: {e}")

            self.progress.finish()
            self.progress.update_file_count(len(files))

            # ç”ŸæˆæŠ¥å‘Š
            report = self._generate_report(all_results, target)

            # ä¿å­˜ç»“æœ
            if self.output_file:
                self._save_report(report, self.output_file)

            return report

        except Exception as e:
            self.logger.error(f"Analysis failed: {e}")
            print(f"âŒ åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}

    def _collect_files(self, target_path: Path) -> List[str]:
        """æ”¶é›†Pythonæ–‡ä»¶"""
        files = []

        if target_path.is_file():
            if target_path.suffix == '.py':
                files.append(str(target_path))
        elif target_path.is_dir():
            # é€’å½’æ”¶é›†Pythonæ–‡ä»¶
            for py_file in target_path.rglob("*.py"):
                files.append(str(py_file))

        # æ’åºæ–‡ä»¶
        files.sort()
        return files

    def _generate_report(self, results: List[Any], target: str) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        total_issues = sum(len(result.issues) for result in results)

        report = {
            'target': target,
            'files_analyzed': len(results),
            'total_issues': total_issues,
            'format': self.format,
            'tools_used': self.tools,
            'files': [],
            'summary': {
                'total_files': len(results),
                'total_issues': total_issues,
                'severity_distribution': {},
                'tool_distribution': {}
            },
            'execution_time': sum(getattr(result, 'execution_time', 0) for result in results)
        }

        # ç»Ÿè®¡ä¸¥é‡ç¨‹åº¦å’Œå·¥å…·åˆ†å¸ƒ
        for result in results:
            for issue in result.issues:
                severity = issue.severity.value
                tool = issue.tool_name

                if severity not in report['summary']['severity_distribution']:
                    report['summary']['severity_distribution'][severity] = 0
                if tool not in report['summary']['tool_distribution']:
                    report['summary']['tool_distribution'][tool] = 0

                report['summary']['severity_distribution'][severity] += 1
                report['summary']['tool_distribution'][tool] += 1

        # æ·»åŠ æ–‡ä»¶è¯¦æƒ…
        for result in results:
            file_info = {
                'file_path': result.file_path,
                'issues_count': len(result.issues),
                'execution_time': result.execution_time,
                'summary': result.summary
            }

            # æ ¹æ®è¾“å‡ºæ ¼å¼æ·»åŠ è¯¦ç»†ä¿¡æ¯
            if self.format in ['detailed', 'json']:
                file_info['issues'] = [
                    {
                        'tool': issue.tool_name,
                        'line': issue.line,
                        'column': issue.column,
                        'severity': issue.severity.value,
                        'message': issue.message,
                        'type': issue.issue_type,
                        'code': issue.code
                    }
                    for issue in result.issues
                ]

            report['files'].append(file_info)

        return report

    def _save_report(self, report: Dict[str, Any], output_file: str):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        try:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            if output_file.endswith('.json'):
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(report, f, indent=2, ensure_ascii=False)
            elif output_file.endswith('.md'):
                self._save_markdown_report(report, output_path)
            else:
                # ç®€å•æ–‡æœ¬æ ¼å¼
                with open(output_path, 'w', encoding='utf-8') as f:
                    self._save_text_report(report, f)

        except Exception as e:
            self.logger.error(f"Failed to save report: {e}")
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")


    def _save_text_report(self, report: Dict[str, Any], file):
        """ä¿å­˜æ–‡æœ¬æ ¼å¼æŠ¥å‘Š"""
        file.write(f"é™æ€åˆ†ææŠ¥å‘Š\n")
        file.write("=" * 50 + "\n")
        file.write(f"ç›®æ ‡: {report['target']}\n")
        file.write(f"åˆ†ææ–‡ä»¶æ•°: {report['files_analyzed']}\n")
        file.write(f"å‘ç°é—®é¢˜æ•°: {report['total_issues']}\n")
        file.write(f"æ‰§è¡Œæ—¶é—´: {report['execution_time']:.2f}ç§’\n")
        file.write(f"ä½¿ç”¨å·¥å…·: {', '.join(report['tools_used'])}\n\n")

        if report['files']:
            file.write("æ–‡ä»¶è¯¦æƒ…:\n")
            file.write("-" * 30 + "\n")
            for file_info in report['files']:
                file.write(f"æ–‡ä»¶: {file_info['file_path']}\n")
                file.write(f"é—®é¢˜æ•°: {file_info['issues_count']}\n")
                file.write(f"æ‰§è¡Œæ—¶é—´: {file_info['execution_time']:.2f}ç§’\n")
                file.write("-" * 30 + "\n")

    def _save_markdown_report(self, report: Dict[str, Any], file):
        """ä¿å­˜Markdownæ ¼å¼æŠ¥å‘Š"""
        file.write("# é™æ€åˆ†ææŠ¥å‘Š\n\n")
        file.write(f"**ç›®æ ‡è·¯å¾„**: `{report['target']}`\n")
        file.write(f"**åˆ†ææ–‡ä»¶æ•°**: {report['files_analyzed']}\n")
        file.write(f"**å‘ç°é—®é¢˜æ•°**: {report['total_issues']}\n")
        file.write(f"**æ‰§è¡Œæ—¶é—´**: {report['execution_time']:.2f}ç§’\n")
        file.write(f"**ä½¿ç”¨å·¥å…·**: {', '.join(report['tools_used'])}\n\n")

        # ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
        if report['summary']['severity_distribution']:
            file.write("## é—®é¢˜ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ\n\n")
            file.write("| ä¸¥é‡ç¨‹åº¦ | æ•°é‡ |\n")
            file.write("|----------|------|\n")
            for severity, count in report['summary']['severity_distribution'].items():
                file.write(f"| {severity} | {count} |\n")
            file.write("\n")

        # å·¥å…·åˆ†å¸ƒ
        if report['summary']['tool_distribution']:
            file.write("## å·¥å…·å‘ç°é—®é¢˜åˆ†å¸ƒ\n\n")
            file.write("| å·¥å…· | å‘ç°é—®é¢˜æ•° |\n")
            file.write("|------|------------|\n")
            for tool, count in report['summary']['tool_distribution'].items():
                file.write(f"| {tool} | {count} |\n")
            file.write("\n")

        # æ–‡ä»¶è¯¦æƒ…
        if report['files']:
            file.write("## æ–‡ä»¶åˆ†æè¯¦æƒ…\n\n")
            for file_info in report['files']:
                file.write(f"### {file_info['file_path']}\n\n")
                file.write(f"- **é—®é¢˜æ•°**: {file_info['issues_count']}\n")
                file.write(f"- **æ‰§è¡Œæ—¶é—´**: {file_info['execution_time']:.2f}ç§’\n")

                if 'issues' in file_info and file_info['issues']:
                    file.write("- **é—®é¢˜åˆ—è¡¨**:\n")
                    for issue in file_info['issues'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé—®é¢˜
                        file.write(f"  - **{issue['tool']}**: [{issue['severity']}] {issue['message']}\n")
                        file.write(f"    - ä½ç½®: ç¬¬{issue['line']}è¡Œ\n")
                    if len(file_info['issues']) > 10:
                        file.write(f"  - ... è¿˜æœ‰ {len(file_info['issues']) - 10} ä¸ªé—®é¢˜\n")

                file.write("\n")


class CLIInteractiveCoordinator:
    """CLIäº¤äº’å¼åˆ†æåè°ƒå™¨"""

    def __init__(self, mode: str = 'deep', output_file: Optional[str] = None,
                 progress: Optional[ProgressTracker] = None, max_context_length: int = 15):
        """
        åˆå§‹åŒ–CLIäº¤äº’å¼åè°ƒå™¨

        Args:
            mode: åˆ†ææ¨¡å¼ (deep/fix)
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            progress: è¿›åº¦è·Ÿè¸ªå™¨
            max_context_length: æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
        """
        self.mode = mode
        self.output_file = output_file
        self.progress = progress or ProgressTracker(verbose=True)
        self.logger = get_logger()
        self.max_context_length = max_context_length
        self.conversation_context = None

    def run_interactive(self, target: str) -> Dict[str, Any]:
        """è¿è¡Œäº¤äº’å¼åˆ†æ"""
        if self.mode == 'deep':
            return self._run_deep_analysis(target)
        elif self.mode == 'fix':
            return self._run_fix_analysis(target)
        else:
            raise ValueError(f"Unsupported interactive mode: {self.mode}")

    def _run_deep_analysis(self, target: str) -> Dict[str, Any]:
        """è¿è¡Œæ·±åº¦åˆ†æ"""
        from .deep_analyzer import DeepAnalyzer, DeepAnalysisRequest
        import asyncio
        import time
        from threading import Thread
        import sys

        # å¢å¼ºçš„å¯åŠ¨ç•Œé¢
        self._show_enhanced_startup_banner(target)

        try:
            # æ˜¾ç¤ºåˆå§‹åŒ–è¿›åº¦
            self._show_initialization_progress()

            # åˆå§‹åŒ–å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨
            self.conversation_context = ConversationContext(target, self.max_context_length)

            analyzer = DeepAnalyzer()

            # æ˜¾ç¤ºä¼šè¯ä¿¡æ¯
            self._show_enhanced_session_info(self.conversation_context, analyzer)
            print()

            # äº¤äº’å¼å¯¹è¯å¾ªç¯
            while True:
                try:
                    user_input = input("ğŸ¤– AIåˆ†æåŠ©æ‰‹> ").strip()

                    if not user_input:
                        continue

                    # å¤„ç†é€€å‡ºå‘½ä»¤
                    if user_input.lower() in ['quit', 'exit', 'q']:
                        print("ğŸ‘‹ é€€å‡ºæ·±åº¦åˆ†ææ¨¡å¼")
                        break

                    # å¤„ç†å¸®åŠ©å‘½ä»¤
                    elif user_input.lower() == 'help':
                        self._show_deep_analysis_help()
                        continue

                    # å¤„ç†ç±»å‹è®¾ç½®å‘½ä»¤
                    elif user_input.lower().startswith('type '):
                        new_type = user_input[5:].strip()
                        try:
                            supported_types = analyzer.get_supported_analysis_types()
                        except:
                            supported_types = ['comprehensive', 'security', 'performance', 'architecture', 'code_review', 'refactoring']

                        if new_type in supported_types:
                            self.conversation_context.set_analysis_type(new_type)
                            print(f"âœ… åˆ†æç±»å‹å·²è®¾ç½®ä¸º: {new_type}")
                            print(f"ğŸ’¾ å·²è®°å½•æ‚¨çš„åå¥½è®¾ç½®")
                        else:
                            print(f"âŒ ä¸æ”¯æŒçš„åˆ†æç±»å‹: {new_type}")
                            print(f"æ”¯æŒçš„ç±»å‹: {', '.join(supported_types)}")
                        continue

                    # å¤„ç†åˆ†æå‘½ä»¤
                    elif user_input.lower().startswith('analyze '):
                        file_path = user_input[8:].strip()
                        result = self._analyze_file_interactive_with_context(analyzer, file_path)
                        continue

                    # å¤„ç†æ€»ç»“å‘½ä»¤
                    elif user_input.lower() == 'summary':
                        self._show_analysis_summary(analysis_context)
                        continue

                    # å¤„ç†å¯¼å‡ºå‘½ä»¤
                    elif user_input.lower().startswith('export '):
                        export_file = user_input[7:].strip()
                        self._export_conversation_with_context(export_file)
                        continue

                    # å¤„ç†æ™®é€šå¯¹è¯è¾“å…¥
                    else:
                        print(f"ğŸ’­ æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜: {user_input}")
                        print("ğŸ” AIæ­£åœ¨æ€è€ƒ...")

                        # ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å¯¹è¯å¤„ç†
                        response = self._generate_contextual_response(user_input)
                        print(f"ğŸ¤– AI: {response}")

                        # è®°å½•å¯¹è¯å†å²åˆ°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
                        self.conversation_context.add_message(user_input, response, 'general')

                except KeyboardInterrupt:
                    print("\nğŸ‘‹ ä½¿ç”¨Ctrl+Cé€€å‡ºæ·±åº¦åˆ†ææ¨¡å¼")
                    break
                except EOFError:
                    print("\nğŸ‘‹ åˆ°è¾¾è¾“å…¥æœ«å°¾ï¼Œé€€å‡ºæ·±åº¦åˆ†ææ¨¡å¼")
                    break

            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            result = {
                'mode': 'deep',
                'target': target,
                'status': 'completed',
                'conversation_history': conversation_history,
                'analysis_context': analysis_context,
                'files_analyzed': len(analysis_context['previous_results']),
                'total_execution_time': sum(r.get('execution_time', 0) for r in analysis_context['previous_results'])
            }

            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            if self.output_file:
                self._save_deep_analysis_result(result, self.output_file)

            print("âœ… æ·±åº¦åˆ†æå®Œæˆ")
            return result

        except Exception as e:
            self.logger.error(f"Deep analysis failed: {e}")
            print(f"âŒ æ·±åº¦åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}

    def _run_fix_analysis(self, target: str) -> Dict[str, Any]:
        """è¿è¡Œä¿®å¤åˆ†æ"""
        from .fix_coordinator import FixCoordinator, FixAnalysisRequest
        from .static_coordinator import StaticAnalysisCoordinator
        import asyncio

        print(f"ğŸ”§ å¼€å§‹ä¿®å¤åˆ†æ: {target}")
        print("=" * 60)
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºä¿®å¤æ¨¡å¼")
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'scan' æ‰«ææ–‡ä»¶é—®é¢˜")
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'fix <file_path>' ä¿®å¤æŒ‡å®šæ–‡ä»¶")
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'batch fix' æ‰¹é‡ä¿®å¤")
        print()

        try:
            # åˆå§‹åŒ–åè°ƒå™¨
            static_coordinator = StaticAnalysisCoordinator()
            fix_coordinator = FixCoordinator()

            # ä¿®å¤ä¼šè¯çŠ¶æ€
            fix_session = {
                'target': target,
                'scanned_files': [],
                'identified_issues': {},
                'fix_history': [],
                'current_file': None,
                'auto_confirm': False
            }

            print(f"ğŸ“ ç›®æ ‡è·¯å¾„: {target}")
            print(f"ğŸ”§ ä¿®å¤æ¨¡å¼: æ‰‹åŠ¨ç¡®è®¤ (å¯ä½¿ç”¨ 'auto confirm' åˆ‡æ¢)")
            print()

            # äº¤äº’å¼ä¿®å¤å¾ªç¯
            while True:
                try:
                    user_input = input("ğŸ”§ ä¿®å¤åŠ©æ‰‹> ").strip()

                    if not user_input:
                        continue

                    # å¤„ç†é€€å‡ºå‘½ä»¤
                    if user_input.lower() in ['quit', 'exit', 'q']:
                        print("ğŸ‘‹ é€€å‡ºä¿®å¤æ¨¡å¼")
                        break

                    # å¤„ç†å¸®åŠ©å‘½ä»¤
                    elif user_input.lower() == 'help':
                        self._show_fix_analysis_help()
                        continue

                    # å¤„ç†æ‰«æå‘½ä»¤
                    elif user_input.lower() == 'scan':
                        self._scan_files_for_issues(static_coordinator, target, fix_session)
                        continue

                    # å¤„ç†è‡ªåŠ¨ç¡®è®¤åˆ‡æ¢
                    elif user_input.lower() == 'auto confirm':
                        fix_session['auto_confirm'] = not fix_session['auto_confirm']
                        status = "å¯ç”¨" if fix_session['auto_confirm'] else "ç¦ç”¨"
                        print(f"âœ… è‡ªåŠ¨ç¡®è®¤å·²{status}")
                        continue

                    # å¤„ç†ä¿®å¤å‘½ä»¤
                    elif user_input.lower().startswith('fix '):
                        file_path = user_input[4:].strip()
                        result = self._fix_file_interactive(fix_coordinator, file_path, fix_session)
                        if result:
                            fix_session['fix_history'].append(result)
                        continue

                    # å¤„ç†æ‰¹é‡ä¿®å¤å‘½ä»¤
                    elif user_input.lower() == 'batch fix':
                        result = self._batch_fix_interactive(fix_coordinator, fix_session)
                        if result:
                            fix_session['fix_history'].extend(result.get('process_results', []))
                        continue

                    # å¤„ç†çŠ¶æ€å‘½ä»¤
                    elif user_input.lower() == 'status':
                        self._show_fix_status(fix_session)
                        continue

                    # å¤„ç†å†å²å‘½ä»¤
                    elif user_input.lower() == 'history':
                        self._show_fix_history(fix_session)
                        continue

                    # å¤„ç†å¯¼å‡ºå‘½ä»¤
                    elif user_input.lower().startswith('export '):
                        export_file = user_input[7:].strip()
                        self._export_fix_session(fix_session, export_file)
                        continue

                    # å¤„ç†æ™®é€šå¯¹è¯è¾“å…¥
                    else:
                        print(f"ğŸ’­ æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜: {user_input}")
                        response = self._generate_fix_response(user_input, fix_session)
                        print(f"ğŸ¤– ä¿®å¤åŠ©æ‰‹: {response}")

                except KeyboardInterrupt:
                    print("\nğŸ‘‹ ä½¿ç”¨Ctrl+Cé€€å‡ºä¿®å¤æ¨¡å¼")
                    break
                except EOFError:
                    print("\nğŸ‘‹ åˆ°è¾¾è¾“å…¥æœ«å°¾ï¼Œé€€å‡ºä¿®å¤æ¨¡å¼")
                    break

            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            result = {
                'mode': 'fix',
                'target': target,
                'status': 'completed',
                'fix_session': fix_session,
                'files_scanned': len(fix_session['scanned_files']),
                'total_issues_found': sum(len(issues) for issues in fix_session['identified_issues'].values()),
                'fixes_attempted': len(fix_session['fix_history']),
                'successful_fixes': len([f for f in fix_session['fix_history'] if f.get('success', False)])
            }

            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            if self.output_file:
                self._save_fix_analysis_result(result, self.output_file)

            print("âœ… ä¿®å¤åˆ†æå®Œæˆ")
            return result

        except Exception as e:
            self.logger.error(f"Fix analysis failed: {e}")
            print(f"âŒ ä¿®å¤åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}

    def _show_deep_analysis_help(self):
        """æ˜¾ç¤ºæ·±åº¦åˆ†æå¸®åŠ©ä¿¡æ¯"""
        print("\nğŸ“– æ·±åº¦åˆ†æå¸®åŠ©")
        print("-" * 40)
        print("å¯ç”¨å‘½ä»¤:")
        print("  help                    - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
        print("  analyze <file_path>     - åˆ†ææŒ‡å®šæ–‡ä»¶")
        print("  type <analysis_type>    - è®¾ç½®åˆ†æç±»å‹")
        print("  summary                 - æ˜¾ç¤ºåˆ†ææ€»ç»“")
        print("  export <filename>       - å¯¼å‡ºå¯¹è¯å†å²")
        print("  quit/exit/q             - é€€å‡ºåˆ†æ")
        print("\nåˆ†æç±»å‹:")
        print("  comprehensive           - ç»¼åˆåˆ†æ")
        print("  security                - å®‰å…¨åˆ†æ")
        print("  performance             - æ€§èƒ½åˆ†æ")
        print("  architecture            - æ¶æ„åˆ†æ")
        print("  code_review             - ä»£ç å®¡æŸ¥")
        print("  refactoring             - é‡æ„å»ºè®®")
        print("\nç¤ºä¾‹:")
        print("  analyze src/main.py")
        print("  type security")
        print("  export conversation.json")
        print()

    def _analyze_file_interactive_with_context(self, analyzer, file_path: str) -> dict:
        """ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„äº¤äº’å¼æ–‡ä»¶åˆ†æ"""
        from pathlib import Path
        import asyncio
        import time

        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            full_path = Path(self.conversation_context.target) / file_path
            if not full_path.exists():
                full_path = Path(file_path)  # å°è¯•ç»å¯¹è·¯å¾„

            if not full_path.exists():
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                print("ğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")

                # è®°å½•å¤±è´¥å°è¯•åˆ°ä¸Šä¸‹æ–‡
                self.conversation_context.add_message(
                    f"analyze {file_path}",
                    f"åˆ†æå¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨",
                    'file_analysis'
                )
                return None

            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            file_name = full_path.name
            file_size = self._format_file_size(full_path.stat().st_size)

            print(f"\nğŸ” å‡†å¤‡åˆ†ææ–‡ä»¶: {file_name}")
            print(f"ğŸ“„ æ–‡ä»¶å¤§å°: {file_size}")
            print(f"ğŸ“Š åˆ†æç±»å‹: {self.conversation_context.analysis_context['analysis_type']}")
            print(f"ğŸ• å¼€å§‹æ—¶é—´: {self._get_current_time()}")

            # æ˜¾ç¤ºä¸Šä¸‹æ–‡ä¿¡æ¯
            context_summary = self.conversation_context.get_context_summary()
            print(f"ğŸ’­ ä¸Šä¸‹æ–‡: {context_summary}")
            print("-" * 50)

            # æ˜¾ç¤ºåˆ†æè¿›åº¦
            self._show_analyzing_animation("AIæ­£åœ¨æ·±åº¦åˆ†æä»£ç ç»“æ„")

            start_time = time.time()

            # åˆ›å»ºåˆ†æè¯·æ±‚ï¼ˆåŒ…å«ä¸Šä¸‹æ–‡ï¼‰
            request = DeepAnalysisRequest(
                file_path=str(full_path),
                analysis_type=self.conversation_context.analysis_context['analysis_type'],
                context=self.conversation_context.analysis_context
            )

            # æ‰§è¡Œå¼‚æ­¥åˆ†æ
            result = asyncio.run(analyzer.analyze_file(request))

            execution_time = time.time() - start_time

            # æ˜¾ç¤ºåˆ†æç»“æœæ¨ªå¹…
            self._show_analysis_result_banner(result.success, file_name)

            if result.success:
                print(f"\nğŸ‰ åˆ†ææˆåŠŸå®Œæˆï¼")
                print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")

                if hasattr(result, 'model_used') and result.model_used:
                    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {result.model_used}")

                print(f"ğŸ“Š åˆ†æç±»å‹: {self.conversation_context.analysis_context['analysis_type']}")
                print("-" * 50)

                # æ˜¾ç¤ºåˆ†æç»“æœæ‘˜è¦
                if result.structured_analysis and result.structured_analysis.get('structured'):
                    self._show_enhanced_structured_result(result.structured_analysis)
                else:
                    # æ˜¾ç¤ºæ–‡æœ¬ç»“æœçš„æ‘˜è¦
                    self._show_text_result_preview(result.content)

                # æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
                self.conversation_context.add_analysis_result(
                    str(full_path),
                    self.conversation_context.analysis_context['analysis_type'],
                    result.to_dict(),
                    execution_time
                )

                print(f"\nğŸ’¡ æç¤º: ä½¿ç”¨ 'summary' æŸ¥çœ‹ä¼šè¯æ€»ç»“")
                print(f"ğŸ’¡ æç¤º: ä½¿ç”¨ 'export <filename>' å¯¼å‡ºå¯¹è¯å†å²")

                return result.to_dict()
            else:
                print(f"\nâŒ åˆ†æå¤±è´¥")
                error_msg = getattr(result, 'error', 'æœªçŸ¥é”™è¯¯')
                print(f"ğŸ”´ é”™è¯¯ä¿¡æ¯: {error_msg}")
                print(f"â±ï¸ è€—æ—¶: {execution_time:.2f}ç§’")

                # è®°å½•å¤±è´¥çš„åˆ†æåˆ°ä¸Šä¸‹æ–‡
                self.conversation_context.add_analysis_result(
                    str(full_path),
                    self.conversation_context.analysis_context['analysis_type'],
                    {'success': False, 'error': error_msg},
                    execution_time
                )

                print(f"\nğŸ’¡ å»ºè®®:")
                print(f"  â€¢ æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºæœ‰æ•ˆçš„Pythonä»£ç ")
                print(f"  â€¢ ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸")
                print(f"  â€¢ å°è¯•æ›´æ¢åˆ†æç±»å‹")

                return None

        except Exception as e:
            print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸")
            print(f"ğŸ”´ å¼‚å¸¸ä¿¡æ¯: {e}")
            self.logger.error(f"Interactive analysis failed: {e}")

            # è®°å½•å¼‚å¸¸åˆ°ä¸Šä¸‹æ–‡
            self.conversation_context.add_message(
                f"analyze {file_path}",
                f"åˆ†æå¼‚å¸¸: {e}",
                'file_analysis'
            )

            print(f"\nğŸ’¡ æ•…éšœæ’é™¤:")
            print(f"  â€¢ æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            print(f"  â€¢ ç¡®è®¤æ–‡ä»¶æƒé™å¯è¯»")
            print(f"  â€¢ æ£€æŸ¥ç³»ç»Ÿèµ„æºæ˜¯å¦å……è¶³")

            return None

    def _analyze_file_interactive(self, analyzer, file_path: str, context: dict, history: list) -> dict:
        """äº¤äº’å¼æ–‡ä»¶åˆ†æ"""
        from pathlib import Path
        import asyncio
        import time

        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            full_path = Path(context['target']) / file_path
            if not full_path.exists():
                full_path = Path(file_path)  # å°è¯•ç»å¯¹è·¯å¾„

            if not full_path.exists():
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                print("ğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
                return None

            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            file_name = full_path.name
            file_size = self._format_file_size(full_path.stat().st_size)

            print(f"\nğŸ” å‡†å¤‡åˆ†ææ–‡ä»¶: {file_name}")
            print(f"ğŸ“„ æ–‡ä»¶å¤§å°: {file_size}")
            print(f"ğŸ“Š åˆ†æç±»å‹: {context['analysis_type']}")
            print(f"ğŸ• å¼€å§‹æ—¶é—´: {self._get_current_time()}")
            print("-" * 50)

            # æ˜¾ç¤ºåˆ†æè¿›åº¦
            self._show_analyzing_animation("AIæ­£åœ¨æ·±åº¦åˆ†æä»£ç ç»“æ„")

            start_time = time.time()

            # åˆ›å»ºåˆ†æè¯·æ±‚
            request = DeepAnalysisRequest(
                file_path=str(full_path),
                analysis_type=context['analysis_type'],
                context=context
            )

            # æ‰§è¡Œå¼‚æ­¥åˆ†æ
            result = asyncio.run(analyzer.analyze_file(request))

            execution_time = time.time() - start_time

            # æ˜¾ç¤ºåˆ†æç»“æœæ¨ªå¹…
            self._show_analysis_result_banner(result.success, file_name)

            if result.success:
                print(f"\nğŸ‰ åˆ†ææˆåŠŸå®Œæˆï¼")
                print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")

                if hasattr(result, 'model_used') and result.model_used:
                    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {result.model_used}")

                print(f"ğŸ“Š åˆ†æç±»å‹: {context['analysis_type']}")
                print("-" * 50)

                # æ˜¾ç¤ºåˆ†æç»“æœæ‘˜è¦
                if result.structured_analysis and result.structured_analysis.get('structured'):
                    self._show_enhanced_structured_result(result.structured_analysis)
                else:
                    # æ˜¾ç¤ºæ–‡æœ¬ç»“æœçš„æ‘˜è¦
                    self._show_text_result_preview(result.content)

                # æ›´æ–°ä¸Šä¸‹æ–‡
                context['current_file'] = str(full_path)
                context['previous_results'].append({
                    'file_path': str(full_path),
                    'analysis_type': context['analysis_type'],
                    'execution_time': execution_time,
                    'success': True,
                    'timestamp': self._get_current_time()
                })

                # è®°å½•åˆ°å¯¹è¯å†å²
                history.append({
                    'timestamp': self._get_current_time(),
                    'type': 'file_analysis',
                    'file_path': str(full_path),
                    'analysis_type': context['analysis_type'],
                    'result': result.to_dict(),
                    'execution_time': execution_time
                })

                print(f"\nğŸ’¡ æç¤º: ä½¿ç”¨ 'summary' æŸ¥çœ‹ä¼šè¯æ€»ç»“")
                print(f"ğŸ’¡ æç¤º: ä½¿ç”¨ 'export <filename>' å¯¼å‡ºå¯¹è¯å†å²")

                return result.to_dict()
            else:
                print(f"\nâŒ åˆ†æå¤±è´¥")
                error_msg = getattr(result, 'error', 'æœªçŸ¥é”™è¯¯')
                print(f"ğŸ”´ é”™è¯¯ä¿¡æ¯: {error_msg}")
                print(f"â±ï¸ è€—æ—¶: {execution_time:.2f}ç§’")

                # è®°å½•å¤±è´¥çš„åˆ†æ
                history.append({
                    'timestamp': self._get_current_time(),
                    'type': 'file_analysis',
                    'file_path': str(full_path),
                    'analysis_type': context['analysis_type'],
                    'success': False,
                    'error': error_msg,
                    'execution_time': execution_time
                })

                print(f"\nğŸ’¡ å»ºè®®:")
                print(f"  â€¢ æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºæœ‰æ•ˆçš„Pythonä»£ç ")
                print(f"  â€¢ ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸")
                print(f"  â€¢ å°è¯•æ›´æ¢åˆ†æç±»å‹")

                return None

        except Exception as e:
            print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸")
            print(f"ğŸ”´ å¼‚å¸¸ä¿¡æ¯: {e}")
            self.logger.error(f"Interactive analysis failed: {e}")

            print(f"\nğŸ’¡ æ•…éšœæ’é™¤:")
            print(f"  â€¢ æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            print(f"  â€¢ ç¡®è®¤æ–‡ä»¶æƒé™å¯è¯»")
            print(f"  â€¢ æ£€æŸ¥ç³»ç»Ÿèµ„æºæ˜¯å¦å……è¶³")

            return None

    def _show_enhanced_structured_result(self, structured_result: dict):
        """æ˜¾ç¤ºå¢å¼ºçš„ç»“æ„åŒ–åˆ†æç»“æœ"""
        print("\nğŸ“Š ç»“æ„åŒ–åˆ†æç»“æœ:")
        print("ğŸ¯" * 35)
        print()

        # æ˜¾ç¤ºæ‘˜è¦
        if 'summary' in structured_result:
            print(f"ğŸ“ åˆ†ææ‘˜è¦:")
            print(f"   {structured_result['summary']}")
            print()

        # æ˜¾ç¤ºä»£ç è´¨é‡è¯„åˆ†
        if 'quality_score' in structured_result:
            score = structured_result['quality_score']
            emoji = self._get_score_emoji(score)
            print(f"ğŸ“ˆ ä»£ç è´¨é‡è¯„åˆ†: {emoji} {score}/10")
            print(f"   {self._get_score_description(score)}")
            print()

        # æ˜¾ç¤ºå¤æ‚åº¦åˆ†æ
        if 'complexity' in structured_result:
            complexity = structured_result['complexity']
            print(f"ğŸ”€ å¤æ‚åº¦åˆ†æ:")
            print(f"   åœˆå¤æ‚åº¦: {complexity.get('cyclomatic', 'N/A')}")
            print(f"   è®¤çŸ¥å¤æ‚åº¦: {complexity.get('cognitive', 'N/A')}")
            print(f"   å¤æ‚åº¦ç­‰çº§: {self._get_complexity_level(complexity.get('cyclomatic', 0))}")
            print()

        # æ˜¾ç¤ºé—®é¢˜åˆ†æ
        if 'issues' in structured_result and structured_result['issues']:
            issues = structured_result['issues']
            print(f"ğŸ” å‘ç°é—®é¢˜ ({len(issues)}ä¸ª):")
            print("-" * 40)

            # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
            severity_groups = {}
            for issue in issues:
                severity = issue.get('severity', 'info')
                if severity not in severity_groups:
                    severity_groups[severity] = []
                severity_groups[severity].append(issue)

            for severity in ['error', 'warning', 'info']:
                if severity in severity_groups:
                    emoji = {'error': 'ğŸ”´', 'warning': 'ğŸŸ¡', 'info': 'ğŸ”µ'}[severity]
                    print(f"\n{emoji} {severity.upper()}çº§åˆ«é—®é¢˜ ({len(severity_groups[severity])}ä¸ª):")

                    for i, issue in enumerate(severity_groups[severity][:5], 1):
                        message = issue.get('message', 'No message')
                        line = issue.get('line', 'N/A')
                        print(f"  {i}. ç¬¬{line}è¡Œ: {message}")

                        if issue.get('suggestion'):
                            print(f"     ğŸ’¡ å»ºè®®: {issue['suggestion']}")

                    if len(severity_groups[severity]) > 5:
                        print(f"     ... è¿˜æœ‰ {len(severity_groups[severity]) - 5} ä¸ª{severity}çº§åˆ«é—®é¢˜")

        # æ˜¾ç¤ºæ”¹è¿›å»ºè®®
        if 'recommendations' in structured_result and structured_result['recommendations']:
            recommendations = structured_result['recommendations']
            print(f"\nğŸ’¡ æ”¹è¿›å»ºè®® ({len(recommendations)}æ¡):")
            print("-" * 40)

            for i, rec in enumerate(recommendations[:5], 1):
                priority = rec.get('priority', 'medium')
                priority_emoji = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(priority, 'âšª')
                print(f"  {i}. {priority_emoji} {rec.get('text', rec)}")

                if rec.get('effort'):
                    effort = rec.get('effort')
                    print(f"     å®æ–½éš¾åº¦: {effort}")

            if len(recommendations) > 5:
                print(f"     ... è¿˜æœ‰ {len(recommendations) - 5} æ¡å»ºè®®")

        print()

    def _show_text_result_preview(self, content: str):
        """æ˜¾ç¤ºæ–‡æœ¬ç»“æœé¢„è§ˆ"""
        print(f"\nğŸ“‹ AIåˆ†æç»“æœ:")
        print("-" * 50)

        if not content:
            print("âš ï¸ åˆ†æç»“æœä¸ºç©º")
            return

        # æ˜¾ç¤ºå‰500å­—ç¬¦çš„é¢„è§ˆ
        preview_length = 500
        if len(content) <= preview_length:
            print(content)
        else:
            preview = content[:preview_length]
            print(preview)
            print(f"\n... (è¿˜æœ‰ {len(content) - preview_length} å­—ç¬¦ï¼Œè¯¦è§å®Œæ•´æŠ¥å‘Š)")

        print("-" * 50)

    def _get_score_emoji(self, score: float) -> str:
        """æ ¹æ®è¯„åˆ†è·å–emoji"""
        if score >= 8.5:
            return "ğŸŸ¢"
        elif score >= 7.0:
            return "ğŸŸ¡"
        elif score >= 5.0:
            return "ğŸŸ "
        else:
            return "ğŸ”´"

    def _get_score_description(self, score: float) -> str:
        """è·å–è¯„åˆ†æè¿°"""
        if score >= 9.0:
            return "ä¼˜ç§€ - ä»£ç è´¨é‡éå¸¸é«˜"
        elif score >= 8.0:
            return "è‰¯å¥½ - ä»£ç è´¨é‡è¾ƒé«˜"
        elif score >= 7.0:
            return "ä¸­ç­‰ - ä»£ç è´¨é‡ä¸€èˆ¬"
        elif score >= 6.0:
            return "è¾ƒå·® - éœ€è¦ä¸€äº›æ”¹è¿›"
        else:
            return "å¾ˆå·® - éœ€è¦é‡å¤§æ”¹è¿›"

    def _get_complexity_level(self, complexity: int) -> str:
        """è·å–å¤æ‚åº¦ç­‰çº§"""
        if complexity <= 5:
            return "ç®€å•"
        elif complexity <= 10:
            return "ä¸­ç­‰"
        elif complexity <= 15:
            return "å¤æ‚"
        else:
            return "éå¸¸å¤æ‚"

    def _show_structured_result(self, structured_result: dict):
        """æ˜¾ç¤ºç»“æ„åŒ–åˆ†æç»“æœï¼ˆä¿ç•™åŸæ–¹æ³•å…¼å®¹æ€§ï¼‰"""
        self._show_enhanced_structured_result(structured_result)

    def _show_analysis_summary(self, context: dict):
        """æ˜¾ç¤ºåˆ†ææ€»ç»“"""
        print("\nğŸ“Š åˆ†ææ€»ç»“")
        print("=" * 40)
        print(f"ğŸ“ ç›®æ ‡è·¯å¾„: {context['target']}")
        print(f"ğŸ” å½“å‰åˆ†æç±»å‹: {context['analysis_type']}")
        print(f"ğŸ“„ å·²åˆ†ææ–‡ä»¶: {len(context['previous_results'])}")

        if context['previous_results']:
            total_time = sum(r.get('execution_time', 0) for r in context['previous_results'])
            successful_files = len([r for r in context['previous_results'] if r.get('success', False)])
            print(f"âœ… æˆåŠŸåˆ†æ: {successful_files}/{len(context['previous_results'])} æ–‡ä»¶")
            print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")

            # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
            print("\nğŸ“‹ å·²åˆ†ææ–‡ä»¶åˆ—è¡¨:")
            for i, result in enumerate(context['previous_results'], 1):
                file_path = result.get('file_path', 'Unknown')
                success = result.get('success', False)
                status = "âœ…" if success else "âŒ"
                print(f"  {i}. {status} {Path(file_path).name}")

        print()

    def _export_conversation(self, history: list, export_file: str):
        """å¯¼å‡ºå¯¹è¯å†å²"""
        try:
            export_path = Path(export_file)
            if not export_path.suffix:
                export_path = export_path.with_suffix('.json')

            export_data = {
                'export_time': self._get_current_time(),
                'total_entries': len(history),
                'conversation_history': history
            }

            with open(export_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)

            print(f"âœ… å¯¹è¯å†å²å·²å¯¼å‡ºåˆ°: {export_path}")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")

    def _generate_contextual_response(self, user_input: str) -> str:
        """ç”Ÿæˆä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å¯¹è¯å“åº”"""
        user_lower = user_input.lower()

        # è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯
        context_summary = self.conversation_context.get_context_summary()
        recent_context = self.conversation_context.get_recent_context(3)
        session_stats = self.conversation_context.get_session_stats()

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®åˆ†æç›¸å…³çš„é—®é¢˜
        if any(keyword in user_lower for keyword in ['å¦‚ä½•åˆ†æ', 'æ€ä¹ˆåˆ†æ', 'åˆ†æä»€ä¹ˆ', 'å¦‚ä½•ä½¿ç”¨']):
            current_type = self.conversation_context.analysis_context['analysis_type']
            return f"æ‚¨å¯ä»¥ä½¿ç”¨ 'analyze <æ–‡ä»¶è·¯å¾„>' å‘½ä»¤æ¥åˆ†ææŒ‡å®šæ–‡ä»¶ã€‚å½“å‰åˆ†æç±»å‹æ˜¯ {current_type}ï¼Œå¯ä»¥ä½¿ç”¨ 'type <ç±»å‹>' å‘½ä»¤æ›´æ”¹ã€‚{context_summary}"

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®è¿›åº¦ç›¸å…³çš„é—®é¢˜
        elif any(keyword in user_lower for keyword in ['è¿›åº¦', 'å¦‚ä½•äº†', 'çŠ¶æ€', 'ç»Ÿè®¡']):
            if session_stats['total_analyses'] > 0:
                success_rate = (session_stats['successful_analyses'] / session_stats['total_analyses']) * 100
                return f"ä¼šè¯ç»Ÿè®¡: å·²åˆ†æ {session_stats['files_analyzed']} ä¸ªæ–‡ä»¶ï¼ŒæˆåŠŸç‡ {success_rate:.1f}%ï¼Œæ€»è€—æ—¶ {session_stats['total_time']:.1f}ç§’ã€‚{context_summary}"
            else:
                return f"è¿˜æ²¡æœ‰å¼€å§‹åˆ†æã€‚ä½¿ç”¨ 'analyze <æ–‡ä»¶è·¯å¾„>' å‘½ä»¤å¼€å§‹åˆ†ææ–‡ä»¶ã€‚"

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®æ–‡ä»¶ç›¸å…³çš„é—®é¢˜
        elif any(keyword in user_lower for keyword in ['æ–‡ä»¶', 'ä»£ç ', 'project', 'åˆšæ‰']):
            if session_stats['total_analyses'] > 0:
                most_used_type = session_stats['most_used_analysis_type']
                return f"æˆ‘ä»¬å·²ç»åˆ†æäº† {session_stats['files_analyzed']} ä¸ªæ–‡ä»¶ï¼Œæœ€å¸¸ç”¨çš„åˆ†æç±»å‹æ˜¯ {most_used_type}ã€‚{context_summary}"
            else:
                return "è¿˜æ²¡æœ‰åˆ†æä»»ä½•æ–‡ä»¶ã€‚ä½¿ç”¨ 'analyze <æ–‡ä»¶è·¯å¾„>' å‘½ä»¤å¼€å§‹åˆ†æã€‚"

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®ç±»å‹ç›¸å…³çš„é—®é¢˜
        elif any(keyword in user_lower for keyword in ['ç±»å‹', 'type', 'åˆ†æç±»å‹', 'å“ªç§åˆ†æ']):
            current_type = self.conversation_context.analysis_context['analysis_type']
            most_used_type = session_stats['most_used_analysis_type']
            return f"å½“å‰åˆ†æç±»å‹æ˜¯ {current_type}ï¼Œæ‚¨æœ€å¸¸ç”¨çš„ç±»å‹æ˜¯ {most_used_type}ã€‚æ”¯æŒçš„ç±»å‹åŒ…æ‹¬: comprehensive, security, performance, architecture, code_review, refactoringã€‚"

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®å†å²ç›¸å…³çš„é—®é¢˜
        elif any(keyword in user_lower for keyword in ['å†å²', 'è®°å½•', 'ä¹‹å‰', 'åˆšæ‰è¯´ä»€ä¹ˆ']):
            if recent_context:
                last_entry = recent_context[-1]
                if last_entry.get('type') == 'file_analysis':
                    file_name = Path(last_entry.get('file_path', 'unknown')).name
                    return f"æœ€è¿‘æˆ‘ä»¬åˆ†æäº† {file_name}ã€‚ä½¿ç”¨ 'summary' æŸ¥çœ‹å®Œæ•´ä¼šè¯æ€»ç»“ã€‚"
                else:
                    return f"æˆ‘ä»¬åˆšæ‰è®¨è®ºäº†: {last_entry.get('user_input', 'æŸä¸ªè¯é¢˜')}"
            else:
                return "è¿™æ˜¯æˆ‘ä»¬å¯¹è¯çš„å¼€å§‹ã€‚ä½¿ç”¨ 'analyze <æ–‡ä»¶è·¯å¾„>' å¼€å§‹åˆ†ææ–‡ä»¶ã€‚"

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®å»ºè®®ç›¸å…³çš„é—®é¢˜
        elif any(keyword in user_lower for keyword in ['å»ºè®®', 'æ¨è', 'åº”è¯¥', 'ä¸‹ä¸€æ­¥']):
            if session_stats['total_analyses'] > 0:
                return f"åŸºäºæ‚¨çš„åˆ†æå†å²ï¼Œå»ºè®®æ‚¨: 1) ç»§ç»­åˆ†æå…¶ä»–é‡è¦æ–‡ä»¶ 2) å°è¯•ä¸åŒçš„åˆ†æç±»å‹ 3) ä½¿ç”¨ 'summary' æŸ¥çœ‹ä¼šè¯æ€»ç»“ 4) ä½¿ç”¨ 'export' ä¿å­˜å¯¹è¯å†å²ã€‚{context_summary}"
            else:
                return "å»ºè®®æ‚¨å…ˆåˆ†æä¸€äº›å…³é”®æ–‡ä»¶ï¼Œæ¯”å¦‚ä¸»ç¨‹åºæ–‡ä»¶æˆ–æ ¸å¿ƒæ¨¡å—ã€‚ä½¿ç”¨ 'analyze <æ–‡ä»¶è·¯å¾„>' å¼€å§‹ã€‚"

        # æ£€æŸ¥æ„Ÿè°¢æˆ–ç»“æŸç›¸å…³çš„è¯é¢˜
        elif any(keyword in user_lower for keyword in ['è°¢è°¢', 'æ„Ÿè°¢', 'å¥½çš„', 'å¯ä»¥', 'æ˜ç™½äº†']):
            return "ä¸å®¢æ°”ï¼å¦‚æœæ‚¨éœ€è¦æ›´å¤šå¸®åŠ©ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ã€‚æˆ‘å¯ä»¥å¸®æ‚¨åˆ†æä»£ç ã€è§£ç­”é—®é¢˜æˆ–æä¾›å»ºè®®ã€‚"

        # é»˜è®¤å“åº”ï¼ˆåŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼‰
        else:
            return f"æˆ‘æ˜¯AIä»£ç åˆ†æåŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œæ·±åº¦ä»£ç åˆ†æã€‚{context_summary} è¾“å…¥ 'help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤ï¼Œæˆ–ç›´æ¥ä½¿ç”¨ 'analyze <æ–‡ä»¶è·¯å¾„>' å¼€å§‹åˆ†ææ–‡ä»¶ã€‚"

    def _export_conversation_with_context(self, export_file: str):
        """ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¯¼å‡ºå¯¹è¯å†å²"""
        try:
            export_path = Path(export_file)

            # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šå¯¼å‡ºæ ¼å¼
            if not export_path.suffix:
                # é»˜è®¤å¯¼å‡ºä¸ºJSON
                export_path = export_path.with_suffix('.json')
                format_type = 'json'
            else:
                format_type = export_path.suffix.lower().lstrip('.')

            # æ”¯æŒçš„å¯¼å‡ºæ ¼å¼
            if format_type not in ['json', 'md', 'markdown', 'txt', 'html']:
                print(f"âŒ ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format_type}")
                print("ğŸ’¡ æ”¯æŒçš„æ ¼å¼: json, md/markdown, txt, html")
                return

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            export_path.parent.mkdir(parents=True, exist_ok=True)

            # æ ¹æ®æ ¼å¼è°ƒç”¨ç›¸åº”çš„å¯¼å‡ºæ–¹æ³•
            if format_type == 'json':
                self._export_as_json(export_path)
            elif format_type in ['md', 'markdown']:
                self._export_as_markdown(export_path)
            elif format_type == 'txt':
                self._export_as_text(export_path)
            elif format_type == 'html':
                self._export_as_html(export_path)

            print(f"âœ… å¯¹è¯å†å²å·²å¯¼å‡ºåˆ°: {export_path}")
            print(f"ğŸ“Š å¯¼å‡ºæ ¼å¼: {format_type.upper()}")
            print(f"ğŸ“ è®°å½•æ•°é‡: {len(self.conversation_context.conversation_history)} æ¡")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            self.logger.error(f"Export failed: {e}")

    def _export_as_json(self, export_path: Path):
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        export_data = {
            'export_info': {
                'export_time': self._get_current_time(),
                'target': self.conversation_context.target,
                'total_entries': len(self.conversation_context.conversation_history),
                'session_duration': self.conversation_context._get_session_duration(),
                'version': '2.0',
                'format': 'json'
            },
            'session_stats': self.conversation_context.get_session_stats(),
            'analysis_context': self.conversation_context.analysis_context,
            'conversation_history': self.conversation_context.conversation_history,
            'user_preferences': self.conversation_context.analysis_context['preferences'],
            'user_patterns': self.conversation_context.analysis_context['user_patterns'],
            'metadata': {
                'generator': 'AIDefectDetector Deep Analysis',
                'platform': 'CLI Interactive Mode',
                'max_context_length': self.conversation_context.max_context_length
            }
        }

        with open(export_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False, default=str)

    def _export_as_markdown(self, export_path: Path):
        """å¯¼å‡ºä¸ºMarkdownæ ¼å¼"""
        with open(export_path, 'w', encoding='utf-8') as f:
            f.write("# AIæ·±åº¦åˆ†æå¯¹è¯å†å²\n\n")

            # å¯¼å‡ºä¿¡æ¯
            f.write("## å¯¼å‡ºä¿¡æ¯\n\n")
            f.write(f"- **å¯¼å‡ºæ—¶é—´**: {self._get_current_time()}\n")
            f.write(f"- **åˆ†æç›®æ ‡**: `{self.conversation_context.target}`\n")
            f.write(f"- **ä¼šè¯æ—¶é•¿**: {self._format_duration(self.conversation_context._get_session_duration())}\n")
            f.write(f"- **å¯¹è¯è®°å½•**: {len(self.conversation_context.conversation_history)} æ¡\n\n")

            # ä¼šè¯ç»Ÿè®¡
            stats = self.conversation_context.get_session_stats()
            f.write("## ä¼šè¯ç»Ÿè®¡\n\n")
            f.write(f"- **åˆ†ææ–‡ä»¶æ•°**: {stats['files_analyzed']}\n")
            f.write(f"- **æˆåŠŸåˆ†æ**: {stats['successful_analyses']}\n")
            f.write(f"- **å¤±è´¥åˆ†æ**: {stats['failed_analyses']}\n")
            f.write(f"- **æ€»è€—æ—¶**: {stats['total_time']:.2f}ç§’\n")
            f.write(f"- **æœ€å¸¸ç”¨ç±»å‹**: {stats['most_used_analysis_type']}\n\n")

            # å¯¹è¯å†å²
            f.write("## å¯¹è¯å†å²\n\n")

            for i, entry in enumerate(self.conversation_context.conversation_history, 1):
                f.write(f"### å¯¹è¯ {i} - {entry.get('timestamp', 'N/A')}\n\n")

                if entry.get('type') == 'file_analysis':
                    file_path = entry.get('file_path', 'Unknown')
                    analysis_type = entry.get('analysis_type', 'Unknown')
                    success = entry.get('success', False)
                    exec_time = entry.get('execution_time', 0)

                    f.write(f"**ç±»å‹**: æ–‡ä»¶åˆ†æ\n")
                    f.write(f"**æ–‡ä»¶**: `{file_path}`\n")
                    f.write(f"**åˆ†æç±»å‹**: {analysis_type}\n")
                    f.write(f"**ç»“æœ**: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}\n")
                    f.write(f"**è€—æ—¶**: {exec_time:.2f}ç§’\n\n")

                    if entry.get('result') and entry['result'].get('success'):
                        result = entry['result']
                        if result.get('content'):
                            content = result['content']
                            preview = content[:300] + "..." if len(content) > 300 else content
                            f.write("**åˆ†æç»“æœé¢„è§ˆ**:\n")
                            f.write("```\n")
                            f.write(preview)
                            f.write("\n```\n\n")

                    if entry.get('result') and not entry['result'].get('success'):
                        error_msg = entry['result'].get('error', 'æœªçŸ¥é”™è¯¯')
                        f.write(f"**é”™è¯¯ä¿¡æ¯**: {error_msg}\n\n")

                else:
                    # æ™®é€šå¯¹è¯
                    user_input = entry.get('user_input', '')
                    ai_response = entry.get('ai_response', '')

                    f.write("**ç”¨æˆ·**: ")
                    f.write(f"{user_input}\n\n")
                    f.write("**AI**: ")
                    f.write(f"{ai_response}\n\n")

                f.write("---\n\n")

    def _export_as_text(self, export_path: Path):
        """å¯¼å‡ºä¸ºçº¯æ–‡æœ¬æ ¼å¼"""
        with open(export_path, 'w', encoding='utf-8') as f:
            f.write("AIæ·±åº¦åˆ†æå¯¹è¯å†å²\n")
            f.write("=" * 50 + "\n\n")

            # å¯¼å‡ºä¿¡æ¯
            f.write("å¯¼å‡ºä¿¡æ¯:\n")
            f.write(f"  å¯¼å‡ºæ—¶é—´: {self._get_current_time()}\n")
            f.write(f"  åˆ†æç›®æ ‡: {self.conversation_context.target}\n")
            f.write(f"  ä¼šè¯æ—¶é•¿: {self._format_duration(self.conversation_context._get_session_duration())}\n")
            f.write(f"  å¯¹è¯è®°å½•: {len(self.conversation_context.conversation_history)} æ¡\n\n")

            # ä¼šè¯ç»Ÿè®¡
            stats = self.conversation_context.get_session_stats()
            f.write("ä¼šè¯ç»Ÿè®¡:\n")
            f.write(f"  åˆ†ææ–‡ä»¶æ•°: {stats['files_analyzed']}\n")
            f.write(f"  æˆåŠŸåˆ†æ: {stats['successful_analyses']}\n")
            f.write(f"  å¤±è´¥åˆ†æ: {stats['failed_analyses']}\n")
            f.write(f"  æ€»è€—æ—¶: {stats['total_time']:.2f}ç§’\n")
            f.write(f"  æœ€å¸¸ç”¨ç±»å‹: {stats['most_used_analysis_type']}\n\n")

            # å¯¹è¯å†å²
            f.write("å¯¹è¯å†å²:\n")
            f.write("-" * 50 + "\n\n")

            for i, entry in enumerate(self.conversation_context.conversation_history, 1):
                f.write(f"[{i}] {entry.get('timestamp', 'N/A')}\n")

                if entry.get('type') == 'file_analysis':
                    f.write(f"  ç±»å‹: æ–‡ä»¶åˆ†æ\n")
                    f.write(f"  æ–‡ä»¶: {entry.get('file_path', 'Unknown')}\n")
                    f.write(f"  åˆ†æç±»å‹: {entry.get('analysis_type', 'Unknown')}\n")
                    f.write(f"  ç»“æœ: {'æˆåŠŸ' if entry.get('success', False) else 'å¤±è´¥'}\n")
                    f.write(f"  è€—æ—¶: {entry.get('execution_time', 0):.2f}ç§’\n")
                else:
                    f.write(f"  ç”¨æˆ·: {entry.get('user_input', '')}\n")
                    f.write(f"  AI: {entry.get('ai_response', '')}\n")

                f.write("\n")

    def _export_as_html(self, export_path: Path):
        """å¯¼å‡ºä¸ºHTMLæ ¼å¼"""
        html_template = """<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AIæ·±åº¦åˆ†æå¯¹è¯å†å²</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; line-height: 1.6; margin: 0; padding: 20px; background: #f5f5f5; }}
        .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        h1 {{ color: #333; border-bottom: 3px solid #007bff; padding-bottom: 10px; }}
        h2 {{ color: #007bff; margin-top: 30px; }}
        h3 {{ color: #495057; margin-top: 25px; }}
        .stats {{ background: #f8f9fa; padding: 15px; border-radius: 5px; margin: 20px 0; }}
        .conversation {{ margin: 20px 0; }}
        .message {{ padding: 15px; margin: 10px 0; border-radius: 8px; }}
        .user {{ background: #e3f2fd; border-left: 4px solid #2196f3; }}
        .ai {{ background: #f3e5f5; border-left: 4px solid #9c27b0; }}
        .analysis {{ background: #e8f5e8; border-left: 4px solid #4caf50; }}
        .file-info {{ background: #fff3cd; padding: 10px; border-radius: 5px; margin: 10px 0; }}
        .success {{ color: #28a745; }}
        .failure {{ color: #dc3545; }}
        code {{ background: #f1f1f1; padding: 2px 4px; border-radius: 3px; }}
        pre {{ background: #f8f9fa; padding: 15px; border-radius: 5px; overflow-x: auto; }}
        .timestamp {{ color: #6c757d; font-size: 0.9em; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ§  AIæ·±åº¦åˆ†æå¯¹è¯å†å²</h1>

        <div class="stats">
            <h2>ğŸ“Š ä¼šè¯ç»Ÿè®¡</h2>
            <p><strong>å¯¼å‡ºæ—¶é—´</strong>: {export_time}</p>
            <p><strong>åˆ†æç›®æ ‡</strong>: <code>{target}</code></p>
            <p><strong>ä¼šè¯æ—¶é•¿</strong>: {session_duration}</p>
            <p><strong>å¯¹è¯è®°å½•</strong>: {total_entries} æ¡</p>
            <p><strong>åˆ†ææ–‡ä»¶æ•°</strong>: {files_analyzed}</p>
            <p><strong>æˆåŠŸåˆ†æ</strong>: {successful_analyses}</p>
            <p><strong>å¤±è´¥åˆ†æ</strong>: {failed_analyses}</p>
            <p><strong>æ€»è€—æ—¶</strong>: {total_time:.2f}ç§’</p>
        </div>

        <div class="conversation">
            <h2>ğŸ’¬ å¯¹è¯å†å²</h2>
            {conversation_content}
        </div>
    </div>
</body>
</html>"""

        # ç”Ÿæˆå¯¹è¯å†…å®¹
        conversation_html = ""
        for i, entry in enumerate(self.conversation_context.conversation_history, 1):
            timestamp = entry.get('timestamp', 'N/A')

            if entry.get('type') == 'file_analysis':
                file_path = entry.get('file_path', 'Unknown')
                analysis_type = entry.get('analysis_type', 'Unknown')
                success = entry.get('success', False)
                exec_time = entry.get('execution_time', 0)

                conversation_html += f"""
                <div class="message analysis">
                    <h3>ğŸ“Š æ–‡ä»¶åˆ†æ #{i} <span class="timestamp">({timestamp})</span></h3>
                    <div class="file-info">
                        <p><strong>æ–‡ä»¶</strong>: <code>{file_path}</code></p>
                        <p><strong>åˆ†æç±»å‹</strong>: {analysis_type}</p>
                        <p><strong>ç»“æœ</strong>: <span class="{'success' if success else 'failure'}">{'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}</span></p>
                        <p><strong>è€—æ—¶</strong>: {exec_time:.2f}ç§’</p>
                    </div>
                </div>"""

                if entry.get('result') and entry['result'].get('success'):
                    result = entry['result']
                    if result.get('content'):
                        content = result['content'][:500] + "..." if len(result['content']) > 500 else result['content']
                        conversation_html += f"""
                        <div class="message ai">
                            <p><strong>AIåˆ†æç»“æœ</strong>:</p>
                            <pre>{content}</pre>
                        </div>"""

            else:
                user_input = entry.get('user_input', '')
                ai_response = entry.get('ai_response', '')

                conversation_html += f"""
                <div class="conversation">
                    <div class="message user">
                        <p><strong>ç”¨æˆ·</strong> <span class="timestamp">({timestamp})</span>:</p>
                        <p>{user_input}</p>
                    </div>
                    <div class="message ai">
                        <p><strong>AIåŠ©æ‰‹</strong>:</p>
                        <p>{ai_response}</p>
                    </div>
                </div>"""

        # å¡«å……æ¨¡æ¿
        stats = self.conversation_context.get_session_stats()
        html_content = html_template.format(
            export_time=self._get_current_time(),
            target=self.conversation_context.target,
            session_duration=self._format_duration(self.conversation_context._get_session_duration()),
            total_entries=len(self.conversation_context.conversation_history),
            files_analyzed=stats['files_analyzed'],
            successful_analyses=stats['successful_analyses'],
            failed_analyses=stats['failed_analyses'],
            total_time=stats['total_time'],
            conversation_content=conversation_html
        )

        with open(export_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

    def _format_duration(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é•¿æ˜¾ç¤º"""
        if seconds < 60:
            return f"{seconds:.1f}ç§’"
        elif seconds < 3600:
            minutes = seconds / 60
            return f"{minutes:.1f}åˆ†é’Ÿ"
        else:
            hours = seconds / 3600
            return f"{hours:.1f}å°æ—¶"

    def _generate_conversational_response(self, user_input: str, context: dict) -> str:
        """ç”Ÿæˆå¯¹è¯å“åº”ï¼ˆä¿ç•™åŸæ–¹æ³•å…¼å®¹æ€§ï¼‰"""
        return self._generate_contextual_response(user_input)

    def _save_deep_analysis_result(self, result: dict, output_file: str):
        """ä¿å­˜æ·±åº¦åˆ†æç»“æœ"""
        try:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            if output_file.endswith('.json'):
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(result, f, indent=2, ensure_ascii=False, default=str)
            elif output_file.endswith('.md'):
                self._save_deep_analysis_markdown(result, output_path)
            else:
                # ç®€å•æ–‡æœ¬æ ¼å¼
                with open(output_path, 'w', encoding='utf-8') as f:
                    self._save_deep_analysis_text(result, f)

            print(f"ğŸ“„ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_path}")

        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def _save_deep_analysis_text(self, result: dict, file):
        """ä¿å­˜æ·±åº¦åˆ†ææ–‡æœ¬ç»“æœ"""
        file.write(f"æ·±åº¦åˆ†ææŠ¥å‘Š\n")
        file.write("=" * 50 + "\n")
        file.write(f"ç›®æ ‡è·¯å¾„: {result['target']}\n")
        file.write(f"åˆ†ææ¨¡å¼: {result['mode']}\n")
        file.write(f"åˆ†ææ–‡ä»¶æ•°: {result['files_analyzed']}\n")
        file.write(f"æ€»æ‰§è¡Œæ—¶é—´: {result['total_execution_time']:.2f}ç§’\n")
        file.write(f"å¯¹è¯è½®æ¬¡: {len(result.get('conversation_history', []))}\n\n")

        if result.get('conversation_history'):
            file.write("å¯¹è¯å†å²:\n")
            file.write("-" * 30 + "\n")
            for i, entry in enumerate(result['conversation_history'], 1):
                file.write(f"[{entry.get('timestamp', 'N/A')}]\n")
                if entry.get('type') == 'file_analysis':
                    file.write(f"åˆ†ææ–‡ä»¶: {entry.get('file_path', 'Unknown')}\n")
                    file.write(f"åˆ†æç±»å‹: {entry.get('analysis_type', 'Unknown')}\n")
                    file.write(f"ç»“æœ: {'æˆåŠŸ' if entry.get('result', {}).get('success') else 'å¤±è´¥'}\n")
                else:
                    file.write(f"ç”¨æˆ·: {entry.get('user_input', 'N/A')}\n")
                    file.write(f"AI: {entry.get('ai_response', 'N/A')}\n")
                file.write("-" * 30 + "\n")

    def _save_deep_analysis_markdown(self, result: dict, file_path: Path):
        """ä¿å­˜æ·±åº¦åˆ†æMarkdownç»“æœ"""
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("# æ·±åº¦åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**ç›®æ ‡è·¯å¾„**: `{result['target']}`\n")
            f.write(f"**åˆ†ææ¨¡å¼**: {result['mode']}\n")
            f.write(f"**åˆ†ææ–‡ä»¶æ•°**: {result['files_analyzed']}\n")
            f.write(f"**æ€»æ‰§è¡Œæ—¶é—´**: {result['total_execution_time']:.2f}ç§’\n")
            f.write(f"**å¯¹è¯è½®æ¬¡**: {len(result.get('conversation_history', []))}\n\n")

            if result.get('conversation_history'):
                f.write("## å¯¹è¯å†å²\n\n")
                for i, entry in enumerate(result['conversation_history'], 1):
                    f.write(f"### å¯¹è¯ {i} - {entry.get('timestamp', 'N/A')}\n\n")
                    if entry.get('type') == 'file_analysis':
                        f.write(f"**æ–‡ä»¶**: `{entry.get('file_path', 'Unknown')}`\n")
                        f.write(f"**åˆ†æç±»å‹**: {entry.get('analysis_type', 'Unknown')}\n")
                        f.write(f"**ç»“æœ**: {'âœ… æˆåŠŸ' if entry.get('result', {}).get('success') else 'âŒ å¤±è´¥'}\n")
                        if entry.get('result', {}).get('content'):
                            content = entry['result']['content']
                            preview = content[:200] + "..." if len(content) > 200 else content
                            f.write(f"**å†…å®¹é¢„è§ˆ**:\n```\n{preview}\n```\n")
                    else:
                        f.write(f"**ç”¨æˆ·**: {entry.get('user_input', 'N/A')}\n")
                        f.write(f"**AI**: {entry.get('ai_response', 'N/A')}\n")
                    f.write("\n")

    def _show_enhanced_startup_banner(self, target: str):
        """æ˜¾ç¤ºå¢å¼ºçš„å¯åŠ¨æ¨ªå¹…"""
        from pathlib import Path
        import os

        # æ¸…å±ï¼ˆå¯é€‰ï¼‰
        if os.name == 'posix':  # Unix/Linux/macOS
            os.system('clear')
        else:  # Windows
            os.system('cls')

        print("\n" + "="*70)
        print("ğŸ§  AIæ·±åº¦åˆ†æåŠ©æ‰‹ - äº¤äº’å¼å¯¹è¯æ¨¡å¼".center(70))
        print("="*70)
        print()

        # æ˜¾ç¤ºç›®æ ‡ä¿¡æ¯
        target_path = Path(target)
        print(f"ğŸ“ åˆ†æç›®æ ‡: {target_path.resolve()}")
        print(f"ğŸ“Š ç›®æ ‡ç±»å‹: {'æ–‡ä»¶' if target_path.is_file() else 'ç›®å½•'}")

        if target_path.is_file():
            print(f"ğŸ“„ æ–‡ä»¶å¤§å°: {self._format_file_size(target_path.stat().st_size)}")
        elif target_path.is_dir():
            # ç»Ÿè®¡Pythonæ–‡ä»¶æ•°é‡
            try:
                py_files = list(target_path.rglob("*.py"))
                print(f"ğŸ Pythonæ–‡ä»¶: {len(py_files)} ä¸ª")
            except:
                print("ğŸ Pythonæ–‡ä»¶: æ— æ³•ç»Ÿè®¡")

        print(f"ğŸ• å¯åŠ¨æ—¶é—´: {self._get_current_time()}")
        print()

    def _show_initialization_progress(self):
        """æ˜¾ç¤ºåˆå§‹åŒ–è¿›åº¦"""
        import sys
        import time

        steps = [
            "ğŸ”§ åˆå§‹åŒ–AIæ¨¡å‹...",
            "ğŸ”— è¿æ¥åˆ°åˆ†ææœåŠ¡...",
            "ğŸ“š åŠ è½½çŸ¥è¯†åº“...",
            "ğŸ¯ é…ç½®åˆ†æå¼•æ“...",
            "âœ… ç³»ç»Ÿå°±ç»ªï¼"
        ]

        print("ğŸš€ ç³»ç»Ÿåˆå§‹åŒ–ä¸­:")
        for i, step in enumerate(steps, 1):
            # æ˜¾ç¤ºè¿›åº¦æ¡
            progress_bar = self._create_progress_bar(i, len(steps), width=30)
            print(f"  [{progress_bar}] {step}", end='\r')
            sys.stdout.flush()
            time.sleep(0.3)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

        print()  # æ¢è¡Œ
        print()

    def _create_progress_bar(self, current: int, total: int, width: int = 40) -> str:
        """åˆ›å»ºè¿›åº¦æ¡"""
        filled = int(width * current / total)
        bar = 'â–ˆ' * filled + 'â–‘' * (width - filled)
        return bar

    def _format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} TB"

    def _show_enhanced_session_info(self, context: ConversationContext, analyzer):
        """æ˜¾ç¤ºå¢å¼ºçš„ä¼šè¯ä¿¡æ¯"""
        from pathlib import Path

        print("ğŸ“Š ä¼šè¯é…ç½®ä¿¡æ¯:")
        print("-" * 50)
        print(f"  ğŸ¯ é»˜è®¤åˆ†æç±»å‹: {context.analysis_context['analysis_type']}")
        print(f"  ğŸ“ åˆ†æç›®æ ‡: {context.target}")
        print(f"  ğŸ’¬ å¯¹è¯æ¨¡å¼: æ™ºèƒ½ä¸Šä¸‹æ–‡æ„ŸçŸ¥")
        print(f"  ğŸ§  ä¸Šä¸‹æ–‡å®¹é‡: {context.max_context_length} è½®å¯¹è¯")
        print(f"  ğŸ’¾ è‡ªåŠ¨ä¿å­˜: å¯ç”¨")

        if self.output_file:
            print(f"  ğŸ“„ è¾“å‡ºæ–‡ä»¶: {Path(self.output_file).name}")
        else:
            print(f"  ğŸ“„ è¾“å‡ºæ–‡ä»¶: è‡ªåŠ¨ç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶")

        try:
            supported_types = analyzer.get_supported_analysis_types()
            print(f"  ğŸ”§ æ”¯æŒçš„åˆ†æç±»å‹: {', '.join(supported_types)}")
        except:
            print(f"  ğŸ”§ æ”¯æŒçš„åˆ†æç±»å‹: comprehensive, security, performance, architecture, code_review, refactoring")

        print(f"  ğŸ• ä¼šè¯å¼€å§‹: {context.session_start}")
        print()

    def _show_session_info(self, context: dict, analyzer):
        """æ˜¾ç¤ºä¼šè¯ä¿¡æ¯ï¼ˆä¿ç•™åŸæ–¹æ³•å…¼å®¹æ€§ï¼‰"""
        # å°†æ—§æ ¼å¼è½¬æ¢ä¸ºæ–°çš„ConversationContextæ ¼å¼
        temp_context = ConversationContext(context.get('target', 'unknown'))
        temp_context.analysis_context = context
        self._show_enhanced_session_info(temp_context, analyzer)

    def _show_analyzing_animation(self, message: str = "AIæ­£åœ¨åˆ†æ"):
        """æ˜¾ç¤ºåˆ†æåŠ¨ç”»"""
        import sys
        import time
        from threading import Thread

        def animate():
            chars = "â ‹â ™â ¹â ¸â ¼â ´â ¦â §â ‡â "
            for char in chars:
                sys.stdout.write(f'\r{char} {message}...')
                sys.stdout.flush()
                time.sleep(0.1)

        # åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œåº”è¯¥å¯åŠ¨åŠ¨ç”»çº¿ç¨‹
        # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬åªæ˜¾ç¤ºé™æ€æ¶ˆæ¯
        print(f"â³ {message}...")

    def _show_analysis_result_banner(self, success: bool, file_name: str = ""):
        """æ˜¾ç¤ºåˆ†æç»“æœæ¨ªå¹…"""
        if success:
            print(f"\nâœ… åˆ†æå®Œæˆ: {file_name}")
            print("ğŸ‰" * 20)
        else:
            print(f"\nâŒ åˆ†æå¤±è´¥: {file_name}")
            print("ğŸ’¥" * 20)

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def _show_fix_analysis_help(self):
        """æ˜¾ç¤ºä¿®å¤åˆ†æå¸®åŠ©ä¿¡æ¯"""
        print("\nğŸ“– ä¿®å¤åˆ†æå¸®åŠ©")
        print("-" * 40)
        print("å¯ç”¨å‘½ä»¤:")
        print("  help                    - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
        print("  scan                    - æ‰«æç›®æ ‡è·¯å¾„ä¸­çš„é—®é¢˜")
        print("  fix <file_path>         - ä¿®å¤æŒ‡å®šæ–‡ä»¶")
        print("  batch fix               - æ‰¹é‡ä¿®å¤æ‰€æœ‰æ–‡ä»¶")
        print("  auto confirm            - åˆ‡æ¢è‡ªåŠ¨ç¡®è®¤æ¨¡å¼")
        print("  status                  - æ˜¾ç¤ºå½“å‰çŠ¶æ€")
        print("  history                 - æ˜¾ç¤ºä¿®å¤å†å²")
        print("  export <filename>       - å¯¼å‡ºä¿®å¤ä¼šè¯")
        print("  quit/exit/q             - é€€å‡ºä¿®å¤æ¨¡å¼")
        print("\nä¿®å¤æµç¨‹:")
        print("  1. ä½¿ç”¨ 'scan' æ‰«ææ–‡ä»¶é—®é¢˜")
        print("  2. ä½¿ç”¨ 'fix <file>' ä¿®å¤æŒ‡å®šæ–‡ä»¶")
        print("  3. æˆ–è€…ä½¿ç”¨ 'batch fix' æ‰¹é‡ä¿®å¤")
        print("  4. ä½¿ç”¨ 'auto confirm' å¯ç”¨è‡ªåŠ¨ç¡®è®¤")
        print("  5. ä½¿ç”¨ 'history' æŸ¥çœ‹ä¿®å¤å†å²")
        print("\nç¤ºä¾‹:")
        print("  scan")
        print("  fix src/main.py")
        print("  batch fix")
        print("  export fix_session.json")
        print()

    def _scan_files_for_issues(self, static_coordinator, target: str, session: dict):
        """æ‰«ææ–‡ä»¶é—®é¢˜"""
        from pathlib import Path

        print(f"ğŸ” å¼€å§‹æ‰«æ: {target}")
        print("â³ æ­£åœ¨åˆ†ææ–‡ä»¶...")

        try:
            target_path = Path(target)
            if not target_path.exists():
                print(f"âŒ ç›®æ ‡è·¯å¾„ä¸å­˜åœ¨: {target}")
                return

            # æ”¶é›†Pythonæ–‡ä»¶
            python_files = []
            if target_path.is_file() and target_path.suffix == '.py':
                python_files.append(str(target_path))
            elif target_path.is_dir():
                python_files.extend([str(f) for f in target_path.rglob("*.py")])

            if not python_files:
                print("âš ï¸ æœªæ‰¾åˆ°Pythonæ–‡ä»¶")
                return

            print(f"ğŸ“ æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")

            # æ‰«æé—®é¢˜
            session['scanned_files'] = python_files
            session['identified_issues'] = {}
            total_issues = 0

            for i, file_path in enumerate(python_files, 1):
                print(f"ğŸ” [{i}/{len(python_files)}] æ‰«æ: {Path(file_path).name}")

                try:
                    result = static_coordinator.analyze_file(file_path)
                    issues = result.issues if result.issues else []

                    if issues:
                        session['identified_issues'][file_path] = [issue.to_dict() for issue in issues]
                        total_issues += len(issues)
                        print(f"  å‘ç° {len(issues)} ä¸ªé—®é¢˜")
                    else:
                        print(f"  âœ… æ— é—®é¢˜")

                except Exception as e:
                    print(f"  âŒ æ‰«æå¤±è´¥: {e}")

            print(f"\nğŸ“Š æ‰«æå®Œæˆ:")
            print(f"  ğŸ“„ æ‰«ææ–‡ä»¶: {len(python_files)}")
            print(f"  ğŸ” æœ‰é—®é¢˜æ–‡ä»¶: {len(session['identified_issues'])}")
            print(f"  âš ï¸ æ€»é—®é¢˜æ•°: {total_issues}")

            if session['identified_issues']:
                print(f"\nğŸ“‹ é—®é¢˜æ–‡ä»¶åˆ—è¡¨:")
                for file_path, issues in list(session['identified_issues'].items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"  ğŸ“„ {Path(file_path).name}: {len(issues)} ä¸ªé—®é¢˜")
                if len(session['identified_issues']) > 5:
                    print(f"  ... è¿˜æœ‰ {len(session['identified_issues']) - 5} ä¸ªæ–‡ä»¶")

        except Exception as e:
            print(f"âŒ æ‰«æå¤±è´¥: {e}")
            self.logger.error(f"Scan failed: {e}")

    def _fix_file_interactive(self, fix_coordinator, file_path: str, session: dict) -> dict:
        """äº¤äº’å¼æ–‡ä»¶ä¿®å¤"""
        from pathlib import Path
        import asyncio

        try:
            # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
            full_path = Path(session['target']) / file_path
            if not full_path.exists():
                full_path = Path(file_path)  # å°è¯•ç»å¯¹è·¯å¾„

            if not full_path.exists():
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None

            # è·å–é—®é¢˜åˆ—è¡¨
            file_key = str(full_path)
            if file_key not in session['identified_issues']:
                print(f"âš ï¸ æ–‡ä»¶ {file_path} æ²¡æœ‰æ‰«æåˆ°é—®é¢˜ï¼Œä½¿ç”¨ 'scan' å…ˆæ‰«æ")
                return None

            issues = session['identified_issues'][file_key]
            print(f"ğŸ”§ å¼€å§‹ä¿®å¤æ–‡ä»¶: {full_path}")
            print(f"ğŸ“‹ å‘ç°é—®é¢˜: {len(issues)} ä¸ª")

            # æ˜¾ç¤ºé—®é¢˜æ‘˜è¦
            for i, issue in enumerate(issues[:3], 1):
                message = issue.get('message', 'No message')
                line = issue.get('line', 'N/A')
                severity = issue.get('severity', 'unknown')
                print(f"  {i}. [{severity}] ç¬¬{line}è¡Œ: {message}")
            if len(issues) > 3:
                print(f"  ... è¿˜æœ‰ {len(issues) - 3} ä¸ªé—®é¢˜")

            # åˆ›å»ºä¿®å¤è¯·æ±‚
            request = FixAnalysisRequest(
                file_path=str(full_path),
                issues=issues,
                analysis_type="security",
                confirmation_required=not session['auto_confirm'],
                backup_enabled=True,
                auto_fix=session['auto_confirm']
            )

            print("â³ AIæ­£åœ¨ç”Ÿæˆä¿®å¤æ–¹æ¡ˆ...")

            # æ‰§è¡Œä¿®å¤
            result = asyncio.run(fix_coordinator.process_fix_request(request))

            if result.success:
                print(f"âœ… ä¿®å¤å®Œæˆ (è€—æ—¶: {result.total_time:.2f}ç§’)")
                print(f"ğŸ”§ å®Œæˆé˜¶æ®µ: {', '.join(result.stages_completed)}")

                if result.execution_result:
                    applied_fixes = len(result.execution_result.applied_suggestions)
                    print(f"ğŸ“ åº”ç”¨ä¿®å¤: {applied_fixes} ä¸ª")

                return result.to_dict()
            else:
                print(f"âŒ ä¿®å¤å¤±è´¥: {result.error_message}")
                return result.to_dict() if result else None

        except Exception as e:
            print(f"âŒ ä¿®å¤è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            self.logger.error(f"Interactive fix failed: {e}")
            return None

    def _batch_fix_interactive(self, fix_coordinator, session: dict) -> dict:
        """æ‰¹é‡ä¿®å¤äº¤äº’"""
        import asyncio

        if not session['identified_issues']:
            print("âš ï¸ æ²¡æœ‰æ‰«æåˆ°é—®é¢˜ï¼Œè¯·å…ˆä½¿ç”¨ 'scan' å‘½ä»¤")
            return None

        total_files = len(session['identified_issues'])
        total_issues = sum(len(issues) for issues in session['identified_issues'].values())

        print(f"ğŸ”§ å‡†å¤‡æ‰¹é‡ä¿®å¤:")
        print(f"ğŸ“ æ–‡ä»¶æ•°é‡: {total_files}")
        print(f"âš ï¸ é—®é¢˜æ€»æ•°: {total_issues}")
        print(f"ğŸ”§ è‡ªåŠ¨ç¡®è®¤: {'å¯ç”¨' if session['auto_confirm'] else 'ç¦ç”¨'}")

        if not session['auto_confirm']:
            print("\nâš ï¸ æ‰¹é‡ä¿®å¤å°†ä¿®æ”¹å¤šä¸ªæ–‡ä»¶ï¼Œå»ºè®®å…ˆå¯ç”¨ 'auto confirm'")
            choice = input("æ˜¯å¦ç»§ç»­? (y/n): ").strip().lower()
            if choice not in ['y', 'yes']:
                print("âŒ å–æ¶ˆæ‰¹é‡ä¿®å¤")
                return None

        print("\nâ³ å¼€å§‹æ‰¹é‡ä¿®å¤...")

        try:
            # åˆ›å»ºæ‰¹é‡ä¿®å¤è¯·æ±‚
            requests = []
            for file_path, issues in session['identified_issues'].items():
                request = FixAnalysisRequest(
                    file_path=file_path,
                    issues=issues,
                    analysis_type="security",
                    confirmation_required=not session['auto_confirm'],
                    backup_enabled=True,
                    auto_fix=session['auto_confirm']
                )
                requests.append(request)

            # æ‰§è¡Œæ‰¹é‡ä¿®å¤
            result = fix_coordinator.process_batch_fix_requests(requests)

            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“Š æ‰¹é‡ä¿®å¤å®Œæˆ:")
            print(f"âœ… æˆåŠŸæ–‡ä»¶: {result.successful_files}/{result.total_files}")
            print(f"â±ï¸ æ€»è€—æ—¶: {result.total_time:.2f}ç§’")
            print(f"ğŸ“ æ‘˜è¦: {result.summary}")

            if result.process_results:
                print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
                for process_result in result.process_results[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    file_name = Path(process_result.file_path).name
                    status = "âœ…" if process_result.success else "âŒ"
                    print(f"  {status} {file_name} ({process_result.total_time:.2f}s)")
                if len(result.process_results) > 5:
                    print(f"  ... è¿˜æœ‰ {len(result.process_results) - 5} ä¸ªæ–‡ä»¶")

            return result.__dict__ if hasattr(result, '__dict__') else {'batch_result': str(result)}

        except Exception as e:
            print(f"âŒ æ‰¹é‡ä¿®å¤å¤±è´¥: {e}")
            self.logger.error(f"Batch fix failed: {e}")
            return None

    def _show_fix_status(self, session: dict):
        """æ˜¾ç¤ºä¿®å¤çŠ¶æ€"""
        print("\nğŸ“Š ä¿®å¤ä¼šè¯çŠ¶æ€")
        print("=" * 40)
        print(f"ğŸ“ ç›®æ ‡è·¯å¾„: {session['target']}")
        print(f"ğŸ” å·²æ‰«ææ–‡ä»¶: {len(session['scanned_files'])}")
        print(f"âš ï¸ å‘ç°é—®é¢˜æ–‡ä»¶: {len(session['identified_issues'])}")
        print(f"ğŸ”§ ä¿®å¤å°è¯•: {len(session['fix_history'])}")
        print(f"âœ… æˆåŠŸä¿®å¤: {len([f for f in session['fix_history'] if f.get('success', False)])}")
        print(f"ğŸ¤– è‡ªåŠ¨ç¡®è®¤: {'å¯ç”¨' if session['auto_confirm'] else 'ç¦ç”¨'}")

        if session['identified_issues']:
            total_issues = sum(len(issues) for issues in session['identified_issues'].values())
            print(f"\nğŸ“‹ é—®é¢˜ç»Ÿè®¡:")
            print(f"  ğŸ” æ€»é—®é¢˜æ•°: {total_issues}")
            print(f"  ğŸ“ æœ‰é—®é¢˜æ–‡ä»¶: {len(session['identified_issues'])}")

            # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
            print(f"\nğŸ“„ å¾…ä¿®å¤æ–‡ä»¶:")
            for file_path, issues in list(session['identified_issues'].items())[:5]:
                if not any(f.get('file_path') == file_path for f in session['fix_history']):
                    file_name = Path(file_path).name
                    print(f"  ğŸ”§ {file_name}: {len(issues)} ä¸ªé—®é¢˜")
            if len(session['identified_issues']) > 5:
                print(f"  ... è¿˜æœ‰ {len(session['identified_issues']) - 5} ä¸ªæ–‡ä»¶")

        print()

    def _show_fix_history(self, session: dict):
        """æ˜¾ç¤ºä¿®å¤å†å²"""
        print("\nğŸ“œ ä¿®å¤å†å²")
        print("=" * 40)

        if not session['fix_history']:
            print("ğŸ“ æš‚æ— ä¿®å¤è®°å½•")
            print()

        for i, fix_record in enumerate(session['fix_history'], 1):
            file_name = Path(fix_record.get('file_path', 'Unknown')).name
            success = fix_record.get('success', False)
            time_taken = fix_record.get('total_time', 0)
            stages = fix_record.get('stages_completed', [])

            print(f"{i}. {'âœ…' if success else 'âŒ'} {file_name}")
            print(f"   è€—æ—¶: {time_taken:.2f}ç§’")
            print(f"   é˜¶æ®µ: {', '.join(stages)}")

            if not success and fix_record.get('error_message'):
                print(f"   é”™è¯¯: {fix_record['error_message']}")

            print()

    def _export_fix_session(self, session: dict, export_file: str):
        """å¯¼å‡ºä¿®å¤ä¼šè¯"""
        try:
            export_path = Path(export_file)
            if not export_path.suffix:
                export_path = export_path.with_suffix('.json')

            export_data = {
                'export_time': self._get_current_time(),
                'session': session,
                'summary': {
                    'target': session['target'],
                    'files_scanned': len(session['scanned_files']),
                    'issues_found': sum(len(issues) for issues in session['identified_issues'].values()),
                    'fixes_attempted': len(session['fix_history']),
                    'successful_fixes': len([f for f in session['fix_history'] if f.get('success', False)])
                }
            }

            with open(export_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False, default=str)

            print(f"âœ… ä¿®å¤ä¼šè¯å·²å¯¼å‡ºåˆ°: {export_path}")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")

    def _generate_fix_response(self, user_input: str, session: dict) -> str:
        """ç”Ÿæˆä¿®å¤å“åº”"""
        user_lower = user_input.lower()

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®ä¿®å¤ç›¸å…³çš„é—®é¢˜
        if any(keyword in user_lower for keyword in ['å¦‚ä½•ä¿®å¤', 'æ€ä¹ˆä¿®å¤', 'ä¿®å¤ä»€ä¹ˆ']):
            if session['identified_issues']:
                return f"å‘ç°äº† {len(session['identified_issues'])} ä¸ªæ–‡ä»¶æœ‰é—®é¢˜ã€‚ä½¿ç”¨ 'fix <æ–‡ä»¶è·¯å¾„>' ä¿®å¤æŒ‡å®šæ–‡ä»¶ï¼Œæˆ– 'batch fix' æ‰¹é‡ä¿®å¤ã€‚"
            else:
                return "è¿˜æ²¡æœ‰æ‰«æåˆ°é—®é¢˜ã€‚è¯·å…ˆä½¿ç”¨ 'scan' å‘½ä»¤æ‰«ææ–‡ä»¶ã€‚"

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®çŠ¶æ€ç›¸å…³çš„é—®é¢˜
        elif any(keyword in user_lower for keyword in ['çŠ¶æ€', 'è¿›åº¦', 'å¦‚ä½•äº†']):
            scanned = len(session['scanned_files'])
            issues = len(session['identified_issues'])
            fixed = len([f for f in session['fix_history'] if f.get('success', False)])
            return f"å·²æ‰«æ {scanned} ä¸ªæ–‡ä»¶ï¼Œå‘ç° {issues} ä¸ªæ–‡ä»¶æœ‰é—®é¢˜ï¼ŒæˆåŠŸä¿®å¤ {fixed} ä¸ªæ–‡ä»¶ã€‚"

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®è‡ªåŠ¨ç¡®è®¤ç›¸å…³çš„é—®é¢˜
        elif any(keyword in user_lower for keyword in ['è‡ªåŠ¨', 'auto', 'ç¡®è®¤']):
            status = "å¯ç”¨" if session['auto_confirm'] else "ç¦ç”¨"
            return f"è‡ªåŠ¨ç¡®è®¤å½“å‰{status}ã€‚ä½¿ç”¨ 'auto confirm' å‘½ä»¤å¯ä»¥åˆ‡æ¢çŠ¶æ€ã€‚"

        # é»˜è®¤å“åº”
        else:
            return "æˆ‘æ˜¯AIä»£ç ä¿®å¤åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨æ‰«æå’Œä¿®å¤ä»£ç é—®é¢˜ã€‚è¾“å…¥ 'help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤ï¼Œæˆ–ä½¿ç”¨ 'scan' å¼€å§‹æ‰«æé—®é¢˜ã€‚"

    def _save_fix_analysis_result(self, result: dict, output_file: str):
        """ä¿å­˜ä¿®å¤åˆ†æç»“æœ"""
        try:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            if output_file.endswith('.json'):
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(result, f, indent=2, ensure_ascii=False, default=str)
            elif output_file.endswith('.md'):
                self._save_fix_analysis_markdown(result, output_path)
            else:
                # ç®€å•æ–‡æœ¬æ ¼å¼
                with open(output_path, 'w', encoding='utf-8') as f:
                    self._save_fix_analysis_text(result, f)

            print(f"ğŸ“„ ä¿®å¤ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def _save_fix_analysis_text(self, result: dict, file):
        """ä¿å­˜ä¿®å¤åˆ†ææ–‡æœ¬ç»“æœ"""
        file.write(f"ä¿®å¤åˆ†ææŠ¥å‘Š\n")
        file.write("=" * 50 + "\n")
        file.write(f"ç›®æ ‡è·¯å¾„: {result['target']}\n")
        file.write(f"åˆ†ææ¨¡å¼: {result['mode']}\n")
        file.write(f"æ‰«ææ–‡ä»¶æ•°: {result['files_scanned']}\n")
        file.write(f"å‘ç°é—®é¢˜æ•°: {result['total_issues_found']}\n")
        file.write(f"ä¿®å¤å°è¯•æ•°: {result['fixes_attempted']}\n")
        file.write(f"æˆåŠŸä¿®å¤æ•°: {result['successful_fixes']}\n\n")

        session = result.get('fix_session', {})
        if session.get('fix_history'):
            file.write("ä¿®å¤å†å²:\n")
            file.write("-" * 30 + "\n")
            for i, fix_record in enumerate(session['fix_history'], 1):
                file_path = fix_record.get('file_path', 'Unknown')
                success = fix_record.get('success', False)
                file.write(f"{i}. {'âœ…' if success else 'âŒ'} {Path(file_path).name}\n")
                file.write(f"   çŠ¶æ€: {'æˆåŠŸ' if success else 'å¤±è´¥'}\n")
                if not success and fix_record.get('error_message'):
                    file.write(f"   é”™è¯¯: {fix_record['error_message']}\n")
                file.write("-" * 30 + "\n")

    def _save_fix_analysis_markdown(self, result: dict, file_path: Path):
        """ä¿å­˜ä¿®å¤åˆ†æMarkdownç»“æœ"""
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("# ä¿®å¤åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**ç›®æ ‡è·¯å¾„**: `{result['target']}`\n")
            f.write(f"**åˆ†ææ¨¡å¼**: {result['mode']}\n")
            f.write(f"**æ‰«ææ–‡ä»¶æ•°**: {result['files_scanned']}\n")
            f.write(f"**å‘ç°é—®é¢˜æ•°**: {result['total_issues_found']}\n")
            f.write(f"**ä¿®å¤å°è¯•æ•°**: {result['fixes_attempted']}\n")
            f.write(f"**æˆåŠŸä¿®å¤æ•°**: {result['successful_fixes']}\n\n")

            session = result.get('fix_session', {})

            # é—®é¢˜ç»Ÿè®¡
            if session.get('identified_issues'):
                f.write("## å‘ç°é—®é¢˜ç»Ÿè®¡\n\n")
                f.write("| æ–‡ä»¶ | é—®é¢˜æ•° |\n")
                f.write("|------|--------|\n")
                for file_path, issues in session['identified_issues'].items():
                    file_name = Path(file_path).name
                    f.write(f"| `{file_name}` | {len(issues)} |\n")
                f.write("\n")

            # ä¿®å¤å†å²
            if session.get('fix_history'):
                f.write("## ä¿®å¤å†å²\n\n")
                for i, fix_record in enumerate(session['fix_history'], 1):
                    file_name = Path(fix_record.get('file_path', 'Unknown')).name
                    success = fix_record.get('success', False)
                    status_icon = "âœ…" if success else "âŒ"

                    f.write(f"### {i}. {status_icon} {file_name}\n\n")
                    f.write(f"- **çŠ¶æ€**: {'æˆåŠŸ' if success else 'å¤±è´¥'}\n")
                    f.write(f"- **è€—æ—¶**: {fix_record.get('total_time', 0):.2f}ç§’\n")
                    f.write(f"- **å®Œæˆé˜¶æ®µ**: {', '.join(fix_record.get('stages_completed', []))}\n")

                    if not success and fix_record.get('error_message'):
                        f.write(f"- **é”™è¯¯**: {fix_record['error_message']}\n")

                    f.write("\n")