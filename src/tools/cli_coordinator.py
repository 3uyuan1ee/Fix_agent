#!/usr/bin/env python3
"""
CLIåˆ†æåè°ƒå™¨
ä¸ºCLIå‘½ä»¤è¡Œæ¥å£æä¾›ç®€åŒ–çš„åˆ†æåè°ƒåŠŸèƒ½
"""

import json
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

from ..utils.logger import get_logger
from ..utils.progress import ProgressTracker
from .static_coordinator import StaticAnalysisCoordinator


@dataclass
class CLIStaticCoordinator:
    """CLIé™æ€åˆ†æåè°ƒå™¨"""

    def __init__(self, tools: Optional[List[str]] = None, format: str = "simple",
                 output_file: Optional[str] = None, dry_run: bool = False,
                 progress: Optional[ProgressTracker] = None):
        """
        åˆå§‹åŒ–CLIé™æ€åˆ†æåè°ƒå™¨

        Args:
            tools: æŒ‡å®šçš„å·¥å…·åˆ—è¡¨
            format: è¾“å‡ºæ ¼å¼
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œ
            progress: è¿›åº¦è·Ÿè¸ªå™¨
        """
        self.tools = tools or ['ast', 'pylint', 'flake8']
        self.format = format
        self.output_file = output_file
        self.dry_run = dry_run
        self.progress = progress or ProgressTracker()
        self.logger = get_logger()

        # åˆ›å»ºé™æ€åˆ†æåè°ƒå™¨
        self.coordinator = StaticAnalysisCoordinator()
        if tools:
            self.coordinator.set_enabled_tools(tools)

    def analyze(self, target: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œé™æ€åˆ†æ

        Args:
            target: ç›®æ ‡è·¯å¾„

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            if self.dry_run:
                print(f"ğŸ” [è¯•è¿è¡Œ] å°†åˆ†æ: {target}")
                return {
                    'dry_run': True,
                    'target': target,
                    'tools': self.tools,
                    'format': self.format
                }

            target_path = Path(target)

            if not target_path.exists():
                print(f"âŒ é”™è¯¯: ç›®æ ‡è·¯å¾„ä¸å­˜åœ¨: {target}")
                return {'error': f"Target path does not exist: {target}"}

            # æ”¶é›†æ–‡ä»¶
            files = self._collect_files(target_path)
            if not files:
                print(f"âš ï¸  è­¦å‘Š: åœ¨ {target} ä¸­æœªæ‰¾åˆ°Pythonæ–‡ä»¶")
                return {
                    'target': target,
                    'files_analyzed': 0,
                    'total_issues': 0,
                    'files': []
                }

            # å¼€å§‹åˆ†æ
            self.progress.start(len(files))
            self.progress.update_file_count(0)

            all_results = []
            total_issues = 0

            for i, file_path in enumerate(files):
                self.progress.show_file_progress(file_path, i, len(files))

                try:
                    result = self.coordinator.analyze_file(file_path)
                    all_results.append(result)
                    total_issues += len(result.issues)
                    self.progress.update_issue_count(total_issues)

                    # æ˜¾ç¤ºå®æ—¶è¿›åº¦
                    if self.progress.verbose:
                        for issue in result.issues[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
                            print(f"  ğŸ“ {result.file_path}:{issue.line} - {issue.message}")

                except Exception as e:
                    self.logger.error(f"Failed to analyze {file_path}: {e}")
                    if self.progress.verbose:
                        print(f"  âŒ åˆ†æå¤±è´¥: {e}")

            self.progress.finish()
            self.progress.update_file_count(len(files))

            # ç”ŸæˆæŠ¥å‘Š
            report = self._generate_report(all_results, target)

            # ä¿å­˜ç»“æœ
            if self.output_file:
                self._save_report(report, self.output_file)

            return report

        except Exception as e:
            self.logger.error(f"Analysis failed: {e}")
            print(f"âŒ åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}

    def _collect_files(self, target_path: Path) -> List[str]:
        """æ”¶é›†Pythonæ–‡ä»¶"""
        files = []

        if target_path.is_file():
            if target_path.suffix == '.py':
                files.append(str(target_path))
        elif target_path.is_dir():
            # é€’å½’æ”¶é›†Pythonæ–‡ä»¶
            for py_file in target_path.rglob("*.py"):
                files.append(str(py_file))

        # æ’åºæ–‡ä»¶
        files.sort()
        return files

    def _generate_report(self, results: List[Any], target: str) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        total_issues = sum(len(result.issues) for result in results)

        report = {
            'target': target,
            'files_analyzed': len(results),
            'total_issues': total_issues,
            'format': self.format,
            'tools_used': self.tools,
            'files': [],
            'summary': {
                'total_files': len(results),
                'total_issues': total_issues,
                'severity_distribution': {},
                'tool_distribution': {}
            },
            'execution_time': sum(getattr(result, 'execution_time', 0) for result in results)
        }

        # ç»Ÿè®¡ä¸¥é‡ç¨‹åº¦å’Œå·¥å…·åˆ†å¸ƒ
        for result in results:
            for issue in result.issues:
                severity = issue.severity.value
                tool = issue.tool_name

                if severity not in report['summary']['severity_distribution']:
                    report['summary']['severity_distribution'][severity] = 0
                if tool not in report['summary']['tool_distribution']:
                    report['summary']['tool_distribution'][tool] = 0

                report['summary']['severity_distribution'][severity] += 1
                report['summary']['tool_distribution'][tool] += 1

        # æ·»åŠ æ–‡ä»¶è¯¦æƒ…
        for result in results:
            file_info = {
                'file_path': result.file_path,
                'issues_count': len(result.issues),
                'execution_time': result.execution_time,
                'summary': result.summary
            }

            # æ ¹æ®è¾“å‡ºæ ¼å¼æ·»åŠ è¯¦ç»†ä¿¡æ¯
            if self.format in ['detailed', 'json']:
                file_info['issues'] = [
                    {
                        'tool': issue.tool_name,
                        'line': issue.line,
                        'column': issue.column,
                        'severity': issue.severity.value,
                        'message': issue.message,
                        'type': issue.issue_type,
                        'code': issue.code
                    }
                    for issue in result.issues
                ]

            report['files'].append(file_info)

        return report

    def _save_report(self, report: Dict[str, Any], output_file: str):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        try:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            if output_file.endswith('.json'):
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(report, f, indent=2, ensure_ascii=False)
            elif output_file.endswith('.md'):
                self._save_markdown_report(report, output_path)
            else:
                # ç®€å•æ–‡æœ¬æ ¼å¼
                with open(output_path, 'w', encoding='utf-8') as f:
                    self._save_text_report(report, f)

        except Exception as e:
            self.logger.error(f"Failed to save report: {e}")
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")


    def _save_text_report(self, report: Dict[str, Any], file):
        """ä¿å­˜æ–‡æœ¬æ ¼å¼æŠ¥å‘Š"""
        file.write(f"é™æ€åˆ†ææŠ¥å‘Š\n")
        file.write("=" * 50 + "\n")
        file.write(f"ç›®æ ‡: {report['target']}\n")
        file.write(f"åˆ†ææ–‡ä»¶æ•°: {report['files_analyzed']}\n")
        file.write(f"å‘ç°é—®é¢˜æ•°: {report['total_issues']}\n")
        file.write(f"æ‰§è¡Œæ—¶é—´: {report['execution_time']:.2f}ç§’\n")
        file.write(f"ä½¿ç”¨å·¥å…·: {', '.join(report['tools_used'])}\n\n")

        if report['files']:
            file.write("æ–‡ä»¶è¯¦æƒ…:\n")
            file.write("-" * 30 + "\n")
            for file_info in report['files']:
                file.write(f"æ–‡ä»¶: {file_info['file_path']}\n")
                file.write(f"é—®é¢˜æ•°: {file_info['issues_count']}\n")
                file.write(f"æ‰§è¡Œæ—¶é—´: {file_info['execution_time']:.2f}ç§’\n")
                file.write("-" * 30 + "\n")

    def _save_markdown_report(self, report: Dict[str, Any], file):
        """ä¿å­˜Markdownæ ¼å¼æŠ¥å‘Š"""
        file.write("# é™æ€åˆ†ææŠ¥å‘Š\n\n")
        file.write(f"**ç›®æ ‡è·¯å¾„**: `{report['target']}`\n")
        file.write(f"**åˆ†ææ–‡ä»¶æ•°**: {report['files_analyzed']}\n")
        file.write(f"**å‘ç°é—®é¢˜æ•°**: {report['total_issues']}\n")
        file.write(f"**æ‰§è¡Œæ—¶é—´**: {report['execution_time']:.2f}ç§’\n")
        file.write(f"**ä½¿ç”¨å·¥å…·**: {', '.join(report['tools_used'])}\n\n")

        # ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
        if report['summary']['severity_distribution']:
            file.write("## é—®é¢˜ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ\n\n")
            file.write("| ä¸¥é‡ç¨‹åº¦ | æ•°é‡ |\n")
            file.write("|----------|------|\n")
            for severity, count in report['summary']['severity_distribution'].items():
                file.write(f"| {severity} | {count} |\n")
            file.write("\n")

        # å·¥å…·åˆ†å¸ƒ
        if report['summary']['tool_distribution']:
            file.write("## å·¥å…·å‘ç°é—®é¢˜åˆ†å¸ƒ\n\n")
            file.write("| å·¥å…· | å‘ç°é—®é¢˜æ•° |\n")
            file.write("|------|------------|\n")
            for tool, count in report['summary']['tool_distribution'].items():
                file.write(f"| {tool} | {count} |\n")
            file.write("\n")

        # æ–‡ä»¶è¯¦æƒ…
        if report['files']:
            file.write("## æ–‡ä»¶åˆ†æè¯¦æƒ…\n\n")
            for file_info in report['files']:
                file.write(f"### {file_info['file_path']}\n\n")
                file.write(f"- **é—®é¢˜æ•°**: {file_info['issues_count']}\n")
                file.write(f"- **æ‰§è¡Œæ—¶é—´**: {file_info['execution_time']:.2f}ç§’\n")

                if 'issues' in file_info and file_info['issues']:
                    file.write("- **é—®é¢˜åˆ—è¡¨**:\n")
                    for issue in file_info['issues'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé—®é¢˜
                        file.write(f"  - **{issue['tool']}**: [{issue['severity']}] {issue['message']}\n")
                        file.write(f"    - ä½ç½®: ç¬¬{issue['line']}è¡Œ\n")
                    if len(file_info['issues']) > 10:
                        file.write(f"  - ... è¿˜æœ‰ {len(file_info['issues']) - 10} ä¸ªé—®é¢˜\n")

                file.write("\n")


class CLIInteractiveCoordinator:
    """CLIäº¤äº’å¼åˆ†æåè°ƒå™¨"""

    def __init__(self, mode: str = 'deep', output_file: Optional[str] = None,
                 progress: Optional[ProgressTracker] = None):
        """
        åˆå§‹åŒ–CLIäº¤äº’å¼åè°ƒå™¨

        Args:
            mode: åˆ†ææ¨¡å¼ (deep/fix)
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            progress: è¿›åº¦è·Ÿè¸ªå™¨
        """
        self.mode = mode
        self.output_file = output_file
        self.progress = progress or ProgressTracker(verbose=True)
        self.logger = get_logger()

    def run_interactive(self, target: str) -> Dict[str, Any]:
        """è¿è¡Œäº¤äº’å¼åˆ†æ"""
        if self.mode == 'deep':
            return self._run_deep_analysis(target)
        elif self.mode == 'fix':
            return self._run_fix_analysis(target)
        else:
            raise ValueError(f"Unsupported interactive mode: {self.mode}")

    def _run_deep_analysis(self, target: str) -> Dict[str, Any]:
        """è¿è¡Œæ·±åº¦åˆ†æ"""
        from .deep_analyzer import DeepAnalyzer, DeepAnalysisRequest
        import asyncio

        print(f"ğŸ§  å¼€å§‹æ·±åº¦åˆ†æ: {target}")
        print("=" * 60)
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºåˆ†æ")
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'analyze <file_path>' åˆ†ææŒ‡å®šæ–‡ä»¶")
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'type <analysis_type>' è®¾ç½®åˆ†æç±»å‹")
        print()

        try:
            analyzer = DeepAnalyzer()
            conversation_history = []
            analysis_context = {
                'target': target,
                'analysis_type': 'comprehensive',
                'current_file': None,
                'previous_results': []
            }

            print(f"ğŸ“ ç›®æ ‡è·¯å¾„: {target}")
            print(f"ğŸ” å½“å‰åˆ†æç±»å‹: {analysis_context['analysis_type']}")
            print(f"ğŸ“Š æ”¯æŒçš„åˆ†æç±»å‹: {', '.join(analyzer.get_supported_analysis_types())}")
            print()

            # äº¤äº’å¼å¯¹è¯å¾ªç¯
            while True:
                try:
                    user_input = input("ğŸ¤– AIåˆ†æåŠ©æ‰‹> ").strip()

                    if not user_input:
                        continue

                    # å¤„ç†é€€å‡ºå‘½ä»¤
                    if user_input.lower() in ['quit', 'exit', 'q']:
                        print("ğŸ‘‹ é€€å‡ºæ·±åº¦åˆ†ææ¨¡å¼")
                        break

                    # å¤„ç†å¸®åŠ©å‘½ä»¤
                    elif user_input.lower() == 'help':
                        self._show_deep_analysis_help()
                        continue

                    # å¤„ç†ç±»å‹è®¾ç½®å‘½ä»¤
                    elif user_input.lower().startswith('type '):
                        new_type = user_input[5:].strip()
                        if new_type in analyzer.get_supported_analysis_types():
                            analysis_context['analysis_type'] = new_type
                            print(f"âœ… åˆ†æç±»å‹å·²è®¾ç½®ä¸º: {new_type}")
                        else:
                            print(f"âŒ ä¸æ”¯æŒçš„åˆ†æç±»å‹: {new_type}")
                            print(f"æ”¯æŒçš„ç±»å‹: {', '.join(analyzer.get_supported_analysis_types())}")
                        continue

                    # å¤„ç†åˆ†æå‘½ä»¤
                    elif user_input.lower().startswith('analyze '):
                        file_path = user_input[8:].strip()
                        result = self._analyze_file_interactive(analyzer, file_path, analysis_context, conversation_history)
                        if result:
                            analysis_context['previous_results'].append(result)
                        continue

                    # å¤„ç†æ€»ç»“å‘½ä»¤
                    elif user_input.lower() == 'summary':
                        self._show_analysis_summary(analysis_context)
                        continue

                    # å¤„ç†å¯¼å‡ºå‘½ä»¤
                    elif user_input.lower().startswith('export '):
                        export_file = user_input[7:].strip()
                        self._export_conversation(conversation_history, export_file)
                        continue

                    # å¤„ç†æ™®é€šå¯¹è¯è¾“å…¥
                    else:
                        print(f"ğŸ’­ æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜: {user_input}")
                        print("ğŸ” AIæ­£åœ¨æ€è€ƒ...")

                        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„å¯¹è¯å¤„ç†é€»è¾‘
                        # æš‚æ—¶ç»™å‡ºç®€å•çš„å›åº”
                        response = self._generate_conversational_response(user_input, analysis_context)
                        print(f"ğŸ¤– AI: {response}")

                        # è®°å½•å¯¹è¯å†å²
                        conversation_history.append({
                            'timestamp': self._get_current_time(),
                            'user_input': user_input,
                            'ai_response': response
                        })

                except KeyboardInterrupt:
                    print("\nğŸ‘‹ ä½¿ç”¨Ctrl+Cé€€å‡ºæ·±åº¦åˆ†ææ¨¡å¼")
                    break
                except EOFError:
                    print("\nğŸ‘‹ åˆ°è¾¾è¾“å…¥æœ«å°¾ï¼Œé€€å‡ºæ·±åº¦åˆ†ææ¨¡å¼")
                    break

            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            result = {
                'mode': 'deep',
                'target': target,
                'status': 'completed',
                'conversation_history': conversation_history,
                'analysis_context': analysis_context,
                'files_analyzed': len(analysis_context['previous_results']),
                'total_execution_time': sum(r.get('execution_time', 0) for r in analysis_context['previous_results'])
            }

            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            if self.output_file:
                self._save_deep_analysis_result(result, self.output_file)

            print("âœ… æ·±åº¦åˆ†æå®Œæˆ")
            return result

        except Exception as e:
            self.logger.error(f"Deep analysis failed: {e}")
            print(f"âŒ æ·±åº¦åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}

    def _run_fix_analysis(self, target: str) -> Dict[str, Any]:
        """è¿è¡Œä¿®å¤åˆ†æ"""
        from .fix_coordinator import FixCoordinator, FixAnalysisRequest
        from .static_coordinator import StaticAnalysisCoordinator
        import asyncio

        print(f"ğŸ”§ å¼€å§‹ä¿®å¤åˆ†æ: {target}")
        print("=" * 60)
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºä¿®å¤æ¨¡å¼")
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'scan' æ‰«ææ–‡ä»¶é—®é¢˜")
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'fix <file_path>' ä¿®å¤æŒ‡å®šæ–‡ä»¶")
        print("ğŸ’¡ æç¤º: è¾“å…¥ 'batch fix' æ‰¹é‡ä¿®å¤")
        print()

        try:
            # åˆå§‹åŒ–åè°ƒå™¨
            static_coordinator = StaticAnalysisCoordinator()
            fix_coordinator = FixCoordinator()

            # ä¿®å¤ä¼šè¯çŠ¶æ€
            fix_session = {
                'target': target,
                'scanned_files': [],
                'identified_issues': {},
                'fix_history': [],
                'current_file': None,
                'auto_confirm': False
            }

            print(f"ğŸ“ ç›®æ ‡è·¯å¾„: {target}")
            print(f"ğŸ”§ ä¿®å¤æ¨¡å¼: æ‰‹åŠ¨ç¡®è®¤ (å¯ä½¿ç”¨ 'auto confirm' åˆ‡æ¢)")
            print()

            # äº¤äº’å¼ä¿®å¤å¾ªç¯
            while True:
                try:
                    user_input = input("ğŸ”§ ä¿®å¤åŠ©æ‰‹> ").strip()

                    if not user_input:
                        continue

                    # å¤„ç†é€€å‡ºå‘½ä»¤
                    if user_input.lower() in ['quit', 'exit', 'q']:
                        print("ğŸ‘‹ é€€å‡ºä¿®å¤æ¨¡å¼")
                        break

                    # å¤„ç†å¸®åŠ©å‘½ä»¤
                    elif user_input.lower() == 'help':
                        self._show_fix_analysis_help()
                        continue

                    # å¤„ç†æ‰«æå‘½ä»¤
                    elif user_input.lower() == 'scan':
                        self._scan_files_for_issues(static_coordinator, target, fix_session)
                        continue

                    # å¤„ç†è‡ªåŠ¨ç¡®è®¤åˆ‡æ¢
                    elif user_input.lower() == 'auto confirm':
                        fix_session['auto_confirm'] = not fix_session['auto_confirm']
                        status = "å¯ç”¨" if fix_session['auto_confirm'] else "ç¦ç”¨"
                        print(f"âœ… è‡ªåŠ¨ç¡®è®¤å·²{status}")
                        continue

                    # å¤„ç†ä¿®å¤å‘½ä»¤
                    elif user_input.lower().startswith('fix '):
                        file_path = user_input[4:].strip()
                        result = self._fix_file_interactive(fix_coordinator, file_path, fix_session)
                        if result:
                            fix_session['fix_history'].append(result)
                        continue

                    # å¤„ç†æ‰¹é‡ä¿®å¤å‘½ä»¤
                    elif user_input.lower() == 'batch fix':
                        result = self._batch_fix_interactive(fix_coordinator, fix_session)
                        if result:
                            fix_session['fix_history'].extend(result.get('process_results', []))
                        continue

                    # å¤„ç†çŠ¶æ€å‘½ä»¤
                    elif user_input.lower() == 'status':
                        self._show_fix_status(fix_session)
                        continue

                    # å¤„ç†å†å²å‘½ä»¤
                    elif user_input.lower() == 'history':
                        self._show_fix_history(fix_session)
                        continue

                    # å¤„ç†å¯¼å‡ºå‘½ä»¤
                    elif user_input.lower().startswith('export '):
                        export_file = user_input[7:].strip()
                        self._export_fix_session(fix_session, export_file)
                        continue

                    # å¤„ç†æ™®é€šå¯¹è¯è¾“å…¥
                    else:
                        print(f"ğŸ’­ æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜: {user_input}")
                        response = self._generate_fix_response(user_input, fix_session)
                        print(f"ğŸ¤– ä¿®å¤åŠ©æ‰‹: {response}")

                except KeyboardInterrupt:
                    print("\nğŸ‘‹ ä½¿ç”¨Ctrl+Cé€€å‡ºä¿®å¤æ¨¡å¼")
                    break
                except EOFError:
                    print("\nğŸ‘‹ åˆ°è¾¾è¾“å…¥æœ«å°¾ï¼Œé€€å‡ºä¿®å¤æ¨¡å¼")
                    break

            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            result = {
                'mode': 'fix',
                'target': target,
                'status': 'completed',
                'fix_session': fix_session,
                'files_scanned': len(fix_session['scanned_files']),
                'total_issues_found': sum(len(issues) for issues in fix_session['identified_issues'].values()),
                'fixes_attempted': len(fix_session['fix_history']),
                'successful_fixes': len([f for f in fix_session['fix_history'] if f.get('success', False)])
            }

            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            if self.output_file:
                self._save_fix_analysis_result(result, self.output_file)

            print("âœ… ä¿®å¤åˆ†æå®Œæˆ")
            return result

        except Exception as e:
            self.logger.error(f"Fix analysis failed: {e}")
            print(f"âŒ ä¿®å¤åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}

    def _show_deep_analysis_help(self):
        """æ˜¾ç¤ºæ·±åº¦åˆ†æå¸®åŠ©ä¿¡æ¯"""
        print("\nğŸ“– æ·±åº¦åˆ†æå¸®åŠ©")
        print("-" * 40)
        print("å¯ç”¨å‘½ä»¤:")
        print("  help                    - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
        print("  analyze <file_path>     - åˆ†ææŒ‡å®šæ–‡ä»¶")
        print("  type <analysis_type>    - è®¾ç½®åˆ†æç±»å‹")
        print("  summary                 - æ˜¾ç¤ºåˆ†ææ€»ç»“")
        print("  export <filename>       - å¯¼å‡ºå¯¹è¯å†å²")
        print("  quit/exit/q             - é€€å‡ºåˆ†æ")
        print("\nåˆ†æç±»å‹:")
        print("  comprehensive           - ç»¼åˆåˆ†æ")
        print("  security                - å®‰å…¨åˆ†æ")
        print("  performance             - æ€§èƒ½åˆ†æ")
        print("  architecture            - æ¶æ„åˆ†æ")
        print("  code_review             - ä»£ç å®¡æŸ¥")
        print("  refactoring             - é‡æ„å»ºè®®")
        print("\nç¤ºä¾‹:")
        print("  analyze src/main.py")
        print("  type security")
        print("  export conversation.json")
        print()

    def _analyze_file_interactive(self, analyzer, file_path: str, context: dict, history: list) -> dict:
        """äº¤äº’å¼æ–‡ä»¶åˆ†æ"""
        from pathlib import Path
        import asyncio

        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            full_path = Path(context['target']) / file_path
            if not full_path.exists():
                full_path = Path(file_path)  # å°è¯•ç»å¯¹è·¯å¾„

            if not full_path.exists():
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None

            print(f"ğŸ” å¼€å§‹åˆ†ææ–‡ä»¶: {full_path}")
            print(f"ğŸ“Š åˆ†æç±»å‹: {context['analysis_type']}")
            print("â³ AIæ­£åœ¨æ·±åº¦åˆ†æ...")

            # åˆ›å»ºåˆ†æè¯·æ±‚
            request = DeepAnalysisRequest(
                file_path=str(full_path),
                analysis_type=context['analysis_type'],
                context=context
            )

            # æ‰§è¡Œå¼‚æ­¥åˆ†æ
            result = asyncio.run(analyzer.analyze_file(request))

            if result.success:
                print(f"âœ… åˆ†æå®Œæˆ (è€—æ—¶: {result.execution_time:.2f}ç§’)")
                print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {result.model_used}")

                # æ˜¾ç¤ºåˆ†æç»“æœæ‘˜è¦
                if result.structured_analysis and result.structured_analysis.get('structured'):
                    self._show_structured_result(result.structured_analysis)
                else:
                    # æ˜¾ç¤ºæ–‡æœ¬ç»“æœçš„æ‘˜è¦
                    content_preview = result.content[:300] + "..." if len(result.content) > 300 else result.content
                    print(f"ğŸ“‹ åˆ†æç»“æœ:")
                    print("-" * 20)
                    print(content_preview)
                    print("-" * 20)

                # è®°å½•åˆ°å¯¹è¯å†å²
                history.append({
                    'timestamp': self._get_current_time(),
                    'type': 'file_analysis',
                    'file_path': str(full_path),
                    'analysis_type': context['analysis_type'],
                    'result': result.to_dict()
                })

                return result.to_dict()
            else:
                print(f"âŒ åˆ†æå¤±è´¥: {result.error}")
                return None

        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            self.logger.error(f"Interactive analysis failed: {e}")
            return None

    def _show_structured_result(self, structured_result: dict):
        """æ˜¾ç¤ºç»“æ„åŒ–åˆ†æç»“æœ"""
        print("\nğŸ“Š ç»“æ„åŒ–åˆ†æç»“æœ:")
        print("-" * 30)

        if 'summary' in structured_result:
            print(f"ğŸ“ æ‘˜è¦: {structured_result['summary']}")

        if 'issues' in structured_result and structured_result['issues']:
            print(f"\nğŸ” å‘ç°é—®é¢˜ ({len(structured_result['issues'])}ä¸ª):")
            for i, issue in enumerate(structured_result['issues'][:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                severity = issue.get('severity', 'unknown')
                message = issue.get('message', 'No message')
                line = issue.get('line', 'N/A')
                print(f"  {i}. [{severity}] ç¬¬{line}è¡Œ: {message}")

            if len(structured_result['issues']) > 5:
                print(f"  ... è¿˜æœ‰ {len(structured_result['issues']) - 5} ä¸ªé—®é¢˜")

        if 'recommendations' in structured_result and structured_result['recommendations']:
            print(f"\nğŸ’¡ å»ºè®® ({len(structured_result['recommendations'])}æ¡):")
            for i, rec in enumerate(structured_result['recommendations'][:3], 1):  # åªæ˜¾ç¤ºå‰3æ¡
                print(f"  {i}. {rec}")

        print()

    def _show_analysis_summary(self, context: dict):
        """æ˜¾ç¤ºåˆ†ææ€»ç»“"""
        print("\nğŸ“Š åˆ†ææ€»ç»“")
        print("=" * 40)
        print(f"ğŸ“ ç›®æ ‡è·¯å¾„: {context['target']}")
        print(f"ğŸ” å½“å‰åˆ†æç±»å‹: {context['analysis_type']}")
        print(f"ğŸ“„ å·²åˆ†ææ–‡ä»¶: {len(context['previous_results'])}")

        if context['previous_results']:
            total_time = sum(r.get('execution_time', 0) for r in context['previous_results'])
            successful_files = len([r for r in context['previous_results'] if r.get('success', False)])
            print(f"âœ… æˆåŠŸåˆ†æ: {successful_files}/{len(context['previous_results'])} æ–‡ä»¶")
            print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")

            # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
            print("\nğŸ“‹ å·²åˆ†ææ–‡ä»¶åˆ—è¡¨:")
            for i, result in enumerate(context['previous_results'], 1):
                file_path = result.get('file_path', 'Unknown')
                success = result.get('success', False)
                status = "âœ…" if success else "âŒ"
                print(f"  {i}. {status} {Path(file_path).name}")

        print()

    def _export_conversation(self, history: list, export_file: str):
        """å¯¼å‡ºå¯¹è¯å†å²"""
        try:
            export_path = Path(export_file)
            if not export_path.suffix:
                export_path = export_path.with_suffix('.json')

            export_data = {
                'export_time': self._get_current_time(),
                'total_entries': len(history),
                'conversation_history': history
            }

            with open(export_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)

            print(f"âœ… å¯¹è¯å†å²å·²å¯¼å‡ºåˆ°: {export_path}")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")

    def _generate_conversational_response(self, user_input: str, context: dict) -> str:
        """ç”Ÿæˆå¯¹è¯å“åº”"""
        # è¿™é‡Œå¯ä»¥é›†æˆæ›´å¤æ‚çš„LLMå¯¹è¯é€»è¾‘
        # ç›®å‰æä¾›ç®€å•çš„è§„åˆ™å“åº”

        user_lower = user_input.lower()

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®åˆ†æç›¸å…³çš„é—®é¢˜
        if any(keyword in user_lower for keyword in ['å¦‚ä½•åˆ†æ', 'æ€ä¹ˆåˆ†æ', 'åˆ†æä»€ä¹ˆ']):
            return f"æ‚¨å¯ä»¥ä½¿ç”¨ 'analyze <æ–‡ä»¶è·¯å¾„>' å‘½ä»¤æ¥åˆ†ææŒ‡å®šæ–‡ä»¶ã€‚å½“å‰åˆ†æç±»å‹æ˜¯ {context['analysis_type']}ï¼Œå¯ä»¥ä½¿ç”¨ 'type <ç±»å‹>' å‘½ä»¤æ›´æ”¹ã€‚"

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®æ–‡ä»¶ç›¸å…³çš„é—®é¢˜
        elif any(keyword in user_lower for keyword in ['æ–‡ä»¶', 'ä»£ç ', 'project']):
            analyzed_count = len(context['previous_results'])
            if analyzed_count > 0:
                return f"æˆ‘å·²ç»åˆ†æäº† {analyzed_count} ä¸ªæ–‡ä»¶ã€‚ä½¿ç”¨ 'summary' å‘½ä»¤æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ï¼Œæˆ–è€…ä½¿ç”¨ 'analyze <æ–‡ä»¶è·¯å¾„>' åˆ†ææ›´å¤šæ–‡ä»¶ã€‚"
            else:
                return "è¿˜æ²¡æœ‰åˆ†æä»»ä½•æ–‡ä»¶ã€‚ä½¿ç”¨ 'analyze <æ–‡ä»¶è·¯å¾„>' å‘½ä»¤å¼€å§‹åˆ†æã€‚"

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®ç±»å‹ç›¸å…³çš„é—®é¢˜
        elif any(keyword in user_lower for keyword in ['ç±»å‹', 'type', 'åˆ†æç±»å‹']):
            return f"å½“å‰åˆ†æç±»å‹æ˜¯ {context['analysis_type']}ã€‚æ”¯æŒçš„ç±»å‹åŒ…æ‹¬: comprehensive, security, performance, architecture, code_review, refactoringã€‚"

        # é»˜è®¤å“åº”
        else:
            return "æˆ‘æ˜¯AIä»£ç åˆ†æåŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œæ·±åº¦ä»£ç åˆ†æã€‚è¾“å…¥ 'help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤ï¼Œæˆ–ç›´æ¥ä½¿ç”¨ 'analyze <æ–‡ä»¶è·¯å¾„>' å¼€å§‹åˆ†ææ–‡ä»¶ã€‚"

    def _save_deep_analysis_result(self, result: dict, output_file: str):
        """ä¿å­˜æ·±åº¦åˆ†æç»“æœ"""
        try:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            if output_file.endswith('.json'):
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(result, f, indent=2, ensure_ascii=False, default=str)
            elif output_file.endswith('.md'):
                self._save_deep_analysis_markdown(result, output_path)
            else:
                # ç®€å•æ–‡æœ¬æ ¼å¼
                with open(output_path, 'w', encoding='utf-8') as f:
                    self._save_deep_analysis_text(result, f)

            print(f"ğŸ“„ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_path}")

        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def _save_deep_analysis_text(self, result: dict, file):
        """ä¿å­˜æ·±åº¦åˆ†ææ–‡æœ¬ç»“æœ"""
        file.write(f"æ·±åº¦åˆ†ææŠ¥å‘Š\n")
        file.write("=" * 50 + "\n")
        file.write(f"ç›®æ ‡è·¯å¾„: {result['target']}\n")
        file.write(f"åˆ†ææ¨¡å¼: {result['mode']}\n")
        file.write(f"åˆ†ææ–‡ä»¶æ•°: {result['files_analyzed']}\n")
        file.write(f"æ€»æ‰§è¡Œæ—¶é—´: {result['total_execution_time']:.2f}ç§’\n")
        file.write(f"å¯¹è¯è½®æ¬¡: {len(result.get('conversation_history', []))}\n\n")

        if result.get('conversation_history'):
            file.write("å¯¹è¯å†å²:\n")
            file.write("-" * 30 + "\n")
            for i, entry in enumerate(result['conversation_history'], 1):
                file.write(f"[{entry.get('timestamp', 'N/A')}]\n")
                if entry.get('type') == 'file_analysis':
                    file.write(f"åˆ†ææ–‡ä»¶: {entry.get('file_path', 'Unknown')}\n")
                    file.write(f"åˆ†æç±»å‹: {entry.get('analysis_type', 'Unknown')}\n")
                    file.write(f"ç»“æœ: {'æˆåŠŸ' if entry.get('result', {}).get('success') else 'å¤±è´¥'}\n")
                else:
                    file.write(f"ç”¨æˆ·: {entry.get('user_input', 'N/A')}\n")
                    file.write(f"AI: {entry.get('ai_response', 'N/A')}\n")
                file.write("-" * 30 + "\n")

    def _save_deep_analysis_markdown(self, result: dict, file_path: Path):
        """ä¿å­˜æ·±åº¦åˆ†æMarkdownç»“æœ"""
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("# æ·±åº¦åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**ç›®æ ‡è·¯å¾„**: `{result['target']}`\n")
            f.write(f"**åˆ†ææ¨¡å¼**: {result['mode']}\n")
            f.write(f"**åˆ†ææ–‡ä»¶æ•°**: {result['files_analyzed']}\n")
            f.write(f"**æ€»æ‰§è¡Œæ—¶é—´**: {result['total_execution_time']:.2f}ç§’\n")
            f.write(f"**å¯¹è¯è½®æ¬¡**: {len(result.get('conversation_history', []))}\n\n")

            if result.get('conversation_history'):
                f.write("## å¯¹è¯å†å²\n\n")
                for i, entry in enumerate(result['conversation_history'], 1):
                    f.write(f"### å¯¹è¯ {i} - {entry.get('timestamp', 'N/A')}\n\n")
                    if entry.get('type') == 'file_analysis':
                        f.write(f"**æ–‡ä»¶**: `{entry.get('file_path', 'Unknown')}`\n")
                        f.write(f"**åˆ†æç±»å‹**: {entry.get('analysis_type', 'Unknown')}\n")
                        f.write(f"**ç»“æœ**: {'âœ… æˆåŠŸ' if entry.get('result', {}).get('success') else 'âŒ å¤±è´¥'}\n")
                        if entry.get('result', {}).get('content'):
                            content = entry['result']['content']
                            preview = content[:200] + "..." if len(content) > 200 else content
                            f.write(f"**å†…å®¹é¢„è§ˆ**:\n```\n{preview}\n```\n")
                    else:
                        f.write(f"**ç”¨æˆ·**: {entry.get('user_input', 'N/A')}\n")
                        f.write(f"**AI**: {entry.get('ai_response', 'N/A')}\n")
                    f.write("\n")

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def _show_fix_analysis_help(self):
        """æ˜¾ç¤ºä¿®å¤åˆ†æå¸®åŠ©ä¿¡æ¯"""
        print("\nğŸ“– ä¿®å¤åˆ†æå¸®åŠ©")
        print("-" * 40)
        print("å¯ç”¨å‘½ä»¤:")
        print("  help                    - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
        print("  scan                    - æ‰«æç›®æ ‡è·¯å¾„ä¸­çš„é—®é¢˜")
        print("  fix <file_path>         - ä¿®å¤æŒ‡å®šæ–‡ä»¶")
        print("  batch fix               - æ‰¹é‡ä¿®å¤æ‰€æœ‰æ–‡ä»¶")
        print("  auto confirm            - åˆ‡æ¢è‡ªåŠ¨ç¡®è®¤æ¨¡å¼")
        print("  status                  - æ˜¾ç¤ºå½“å‰çŠ¶æ€")
        print("  history                 - æ˜¾ç¤ºä¿®å¤å†å²")
        print("  export <filename>       - å¯¼å‡ºä¿®å¤ä¼šè¯")
        print("  quit/exit/q             - é€€å‡ºä¿®å¤æ¨¡å¼")
        print("\nä¿®å¤æµç¨‹:")
        print("  1. ä½¿ç”¨ 'scan' æ‰«ææ–‡ä»¶é—®é¢˜")
        print("  2. ä½¿ç”¨ 'fix <file>' ä¿®å¤æŒ‡å®šæ–‡ä»¶")
        print("  3. æˆ–è€…ä½¿ç”¨ 'batch fix' æ‰¹é‡ä¿®å¤")
        print("  4. ä½¿ç”¨ 'auto confirm' å¯ç”¨è‡ªåŠ¨ç¡®è®¤")
        print("  5. ä½¿ç”¨ 'history' æŸ¥çœ‹ä¿®å¤å†å²")
        print("\nç¤ºä¾‹:")
        print("  scan")
        print("  fix src/main.py")
        print("  batch fix")
        print("  export fix_session.json")
        print()

    def _scan_files_for_issues(self, static_coordinator, target: str, session: dict):
        """æ‰«ææ–‡ä»¶é—®é¢˜"""
        from pathlib import Path

        print(f"ğŸ” å¼€å§‹æ‰«æ: {target}")
        print("â³ æ­£åœ¨åˆ†ææ–‡ä»¶...")

        try:
            target_path = Path(target)
            if not target_path.exists():
                print(f"âŒ ç›®æ ‡è·¯å¾„ä¸å­˜åœ¨: {target}")
                return

            # æ”¶é›†Pythonæ–‡ä»¶
            python_files = []
            if target_path.is_file() and target_path.suffix == '.py':
                python_files.append(str(target_path))
            elif target_path.is_dir():
                python_files.extend([str(f) for f in target_path.rglob("*.py")])

            if not python_files:
                print("âš ï¸ æœªæ‰¾åˆ°Pythonæ–‡ä»¶")
                return

            print(f"ğŸ“ æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")

            # æ‰«æé—®é¢˜
            session['scanned_files'] = python_files
            session['identified_issues'] = {}
            total_issues = 0

            for i, file_path in enumerate(python_files, 1):
                print(f"ğŸ” [{i}/{len(python_files)}] æ‰«æ: {Path(file_path).name}")

                try:
                    result = static_coordinator.analyze_file(file_path)
                    issues = result.issues if result.issues else []

                    if issues:
                        session['identified_issues'][file_path] = [issue.to_dict() for issue in issues]
                        total_issues += len(issues)
                        print(f"  å‘ç° {len(issues)} ä¸ªé—®é¢˜")
                    else:
                        print(f"  âœ… æ— é—®é¢˜")

                except Exception as e:
                    print(f"  âŒ æ‰«æå¤±è´¥: {e}")

            print(f"\nğŸ“Š æ‰«æå®Œæˆ:")
            print(f"  ğŸ“„ æ‰«ææ–‡ä»¶: {len(python_files)}")
            print(f"  ğŸ” æœ‰é—®é¢˜æ–‡ä»¶: {len(session['identified_issues'])}")
            print(f"  âš ï¸ æ€»é—®é¢˜æ•°: {total_issues}")

            if session['identified_issues']:
                print(f"\nğŸ“‹ é—®é¢˜æ–‡ä»¶åˆ—è¡¨:")
                for file_path, issues in list(session['identified_issues'].items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"  ğŸ“„ {Path(file_path).name}: {len(issues)} ä¸ªé—®é¢˜")
                if len(session['identified_issues']) > 5:
                    print(f"  ... è¿˜æœ‰ {len(session['identified_issues']) - 5} ä¸ªæ–‡ä»¶")

        except Exception as e:
            print(f"âŒ æ‰«æå¤±è´¥: {e}")
            self.logger.error(f"Scan failed: {e}")

    def _fix_file_interactive(self, fix_coordinator, file_path: str, session: dict) -> dict:
        """äº¤äº’å¼æ–‡ä»¶ä¿®å¤"""
        from pathlib import Path
        import asyncio

        try:
            # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
            full_path = Path(session['target']) / file_path
            if not full_path.exists():
                full_path = Path(file_path)  # å°è¯•ç»å¯¹è·¯å¾„

            if not full_path.exists():
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None

            # è·å–é—®é¢˜åˆ—è¡¨
            file_key = str(full_path)
            if file_key not in session['identified_issues']:
                print(f"âš ï¸ æ–‡ä»¶ {file_path} æ²¡æœ‰æ‰«æåˆ°é—®é¢˜ï¼Œä½¿ç”¨ 'scan' å…ˆæ‰«æ")
                return None

            issues = session['identified_issues'][file_key]
            print(f"ğŸ”§ å¼€å§‹ä¿®å¤æ–‡ä»¶: {full_path}")
            print(f"ğŸ“‹ å‘ç°é—®é¢˜: {len(issues)} ä¸ª")

            # æ˜¾ç¤ºé—®é¢˜æ‘˜è¦
            for i, issue in enumerate(issues[:3], 1):
                message = issue.get('message', 'No message')
                line = issue.get('line', 'N/A')
                severity = issue.get('severity', 'unknown')
                print(f"  {i}. [{severity}] ç¬¬{line}è¡Œ: {message}")
            if len(issues) > 3:
                print(f"  ... è¿˜æœ‰ {len(issues) - 3} ä¸ªé—®é¢˜")

            # åˆ›å»ºä¿®å¤è¯·æ±‚
            request = FixAnalysisRequest(
                file_path=str(full_path),
                issues=issues,
                analysis_type="security",
                confirmation_required=not session['auto_confirm'],
                backup_enabled=True,
                auto_fix=session['auto_confirm']
            )

            print("â³ AIæ­£åœ¨ç”Ÿæˆä¿®å¤æ–¹æ¡ˆ...")

            # æ‰§è¡Œä¿®å¤
            result = asyncio.run(fix_coordinator.process_fix_request(request))

            if result.success:
                print(f"âœ… ä¿®å¤å®Œæˆ (è€—æ—¶: {result.total_time:.2f}ç§’)")
                print(f"ğŸ”§ å®Œæˆé˜¶æ®µ: {', '.join(result.stages_completed)}")

                if result.execution_result:
                    applied_fixes = len(result.execution_result.applied_suggestions)
                    print(f"ğŸ“ åº”ç”¨ä¿®å¤: {applied_fixes} ä¸ª")

                return result.to_dict()
            else:
                print(f"âŒ ä¿®å¤å¤±è´¥: {result.error_message}")
                return result.to_dict() if result else None

        except Exception as e:
            print(f"âŒ ä¿®å¤è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            self.logger.error(f"Interactive fix failed: {e}")
            return None

    def _batch_fix_interactive(self, fix_coordinator, session: dict) -> dict:
        """æ‰¹é‡ä¿®å¤äº¤äº’"""
        import asyncio

        if not session['identified_issues']:
            print("âš ï¸ æ²¡æœ‰æ‰«æåˆ°é—®é¢˜ï¼Œè¯·å…ˆä½¿ç”¨ 'scan' å‘½ä»¤")
            return None

        total_files = len(session['identified_issues'])
        total_issues = sum(len(issues) for issues in session['identified_issues'].values())

        print(f"ğŸ”§ å‡†å¤‡æ‰¹é‡ä¿®å¤:")
        print(f"ğŸ“ æ–‡ä»¶æ•°é‡: {total_files}")
        print(f"âš ï¸ é—®é¢˜æ€»æ•°: {total_issues}")
        print(f"ğŸ”§ è‡ªåŠ¨ç¡®è®¤: {'å¯ç”¨' if session['auto_confirm'] else 'ç¦ç”¨'}")

        if not session['auto_confirm']:
            print("\nâš ï¸ æ‰¹é‡ä¿®å¤å°†ä¿®æ”¹å¤šä¸ªæ–‡ä»¶ï¼Œå»ºè®®å…ˆå¯ç”¨ 'auto confirm'")
            choice = input("æ˜¯å¦ç»§ç»­? (y/n): ").strip().lower()
            if choice not in ['y', 'yes']:
                print("âŒ å–æ¶ˆæ‰¹é‡ä¿®å¤")
                return None

        print("\nâ³ å¼€å§‹æ‰¹é‡ä¿®å¤...")

        try:
            # åˆ›å»ºæ‰¹é‡ä¿®å¤è¯·æ±‚
            requests = []
            for file_path, issues in session['identified_issues'].items():
                request = FixAnalysisRequest(
                    file_path=file_path,
                    issues=issues,
                    analysis_type="security",
                    confirmation_required=not session['auto_confirm'],
                    backup_enabled=True,
                    auto_fix=session['auto_confirm']
                )
                requests.append(request)

            # æ‰§è¡Œæ‰¹é‡ä¿®å¤
            result = fix_coordinator.process_batch_fix_requests(requests)

            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“Š æ‰¹é‡ä¿®å¤å®Œæˆ:")
            print(f"âœ… æˆåŠŸæ–‡ä»¶: {result.successful_files}/{result.total_files}")
            print(f"â±ï¸ æ€»è€—æ—¶: {result.total_time:.2f}ç§’")
            print(f"ğŸ“ æ‘˜è¦: {result.summary}")

            if result.process_results:
                print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
                for process_result in result.process_results[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    file_name = Path(process_result.file_path).name
                    status = "âœ…" if process_result.success else "âŒ"
                    print(f"  {status} {file_name} ({process_result.total_time:.2f}s)")
                if len(result.process_results) > 5:
                    print(f"  ... è¿˜æœ‰ {len(result.process_results) - 5} ä¸ªæ–‡ä»¶")

            return result.__dict__ if hasattr(result, '__dict__') else {'batch_result': str(result)}

        except Exception as e:
            print(f"âŒ æ‰¹é‡ä¿®å¤å¤±è´¥: {e}")
            self.logger.error(f"Batch fix failed: {e}")
            return None

    def _show_fix_status(self, session: dict):
        """æ˜¾ç¤ºä¿®å¤çŠ¶æ€"""
        print("\nğŸ“Š ä¿®å¤ä¼šè¯çŠ¶æ€")
        print("=" * 40)
        print(f"ğŸ“ ç›®æ ‡è·¯å¾„: {session['target']}")
        print(f"ğŸ” å·²æ‰«ææ–‡ä»¶: {len(session['scanned_files'])}")
        print(f"âš ï¸ å‘ç°é—®é¢˜æ–‡ä»¶: {len(session['identified_issues'])}")
        print(f"ğŸ”§ ä¿®å¤å°è¯•: {len(session['fix_history'])}")
        print(f"âœ… æˆåŠŸä¿®å¤: {len([f for f in session['fix_history'] if f.get('success', False)])}")
        print(f"ğŸ¤– è‡ªåŠ¨ç¡®è®¤: {'å¯ç”¨' if session['auto_confirm'] else 'ç¦ç”¨'}")

        if session['identified_issues']:
            total_issues = sum(len(issues) for issues in session['identified_issues'].values())
            print(f"\nğŸ“‹ é—®é¢˜ç»Ÿè®¡:")
            print(f"  ğŸ” æ€»é—®é¢˜æ•°: {total_issues}")
            print(f"  ğŸ“ æœ‰é—®é¢˜æ–‡ä»¶: {len(session['identified_issues'])}")

            # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
            print(f"\nğŸ“„ å¾…ä¿®å¤æ–‡ä»¶:")
            for file_path, issues in list(session['identified_issues'].items())[:5]:
                if not any(f.get('file_path') == file_path for f in session['fix_history']):
                    file_name = Path(file_path).name
                    print(f"  ğŸ”§ {file_name}: {len(issues)} ä¸ªé—®é¢˜")
            if len(session['identified_issues']) > 5:
                print(f"  ... è¿˜æœ‰ {len(session['identified_issues']) - 5} ä¸ªæ–‡ä»¶")

        print()

    def _show_fix_history(self, session: dict):
        """æ˜¾ç¤ºä¿®å¤å†å²"""
        print("\nğŸ“œ ä¿®å¤å†å²")
        print("=" * 40)

        if not session['fix_history']:
            print("ğŸ“ æš‚æ— ä¿®å¤è®°å½•")
            print()

        for i, fix_record in enumerate(session['fix_history'], 1):
            file_name = Path(fix_record.get('file_path', 'Unknown')).name
            success = fix_record.get('success', False)
            time_taken = fix_record.get('total_time', 0)
            stages = fix_record.get('stages_completed', [])

            print(f"{i}. {'âœ…' if success else 'âŒ'} {file_name}")
            print(f"   è€—æ—¶: {time_taken:.2f}ç§’")
            print(f"   é˜¶æ®µ: {', '.join(stages)}")

            if not success and fix_record.get('error_message'):
                print(f"   é”™è¯¯: {fix_record['error_message']}")

            print()

    def _export_fix_session(self, session: dict, export_file: str):
        """å¯¼å‡ºä¿®å¤ä¼šè¯"""
        try:
            export_path = Path(export_file)
            if not export_path.suffix:
                export_path = export_path.with_suffix('.json')

            export_data = {
                'export_time': self._get_current_time(),
                'session': session,
                'summary': {
                    'target': session['target'],
                    'files_scanned': len(session['scanned_files']),
                    'issues_found': sum(len(issues) for issues in session['identified_issues'].values()),
                    'fixes_attempted': len(session['fix_history']),
                    'successful_fixes': len([f for f in session['fix_history'] if f.get('success', False)])
                }
            }

            with open(export_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False, default=str)

            print(f"âœ… ä¿®å¤ä¼šè¯å·²å¯¼å‡ºåˆ°: {export_path}")

        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")

    def _generate_fix_response(self, user_input: str, session: dict) -> str:
        """ç”Ÿæˆä¿®å¤å“åº”"""
        user_lower = user_input.lower()

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®ä¿®å¤ç›¸å…³çš„é—®é¢˜
        if any(keyword in user_lower for keyword in ['å¦‚ä½•ä¿®å¤', 'æ€ä¹ˆä¿®å¤', 'ä¿®å¤ä»€ä¹ˆ']):
            if session['identified_issues']:
                return f"å‘ç°äº† {len(session['identified_issues'])} ä¸ªæ–‡ä»¶æœ‰é—®é¢˜ã€‚ä½¿ç”¨ 'fix <æ–‡ä»¶è·¯å¾„>' ä¿®å¤æŒ‡å®šæ–‡ä»¶ï¼Œæˆ– 'batch fix' æ‰¹é‡ä¿®å¤ã€‚"
            else:
                return "è¿˜æ²¡æœ‰æ‰«æåˆ°é—®é¢˜ã€‚è¯·å…ˆä½¿ç”¨ 'scan' å‘½ä»¤æ‰«ææ–‡ä»¶ã€‚"

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®çŠ¶æ€ç›¸å…³çš„é—®é¢˜
        elif any(keyword in user_lower for keyword in ['çŠ¶æ€', 'è¿›åº¦', 'å¦‚ä½•äº†']):
            scanned = len(session['scanned_files'])
            issues = len(session['identified_issues'])
            fixed = len([f for f in session['fix_history'] if f.get('success', False)])
            return f"å·²æ‰«æ {scanned} ä¸ªæ–‡ä»¶ï¼Œå‘ç° {issues} ä¸ªæ–‡ä»¶æœ‰é—®é¢˜ï¼ŒæˆåŠŸä¿®å¤ {fixed} ä¸ªæ–‡ä»¶ã€‚"

        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¢é—®è‡ªåŠ¨ç¡®è®¤ç›¸å…³çš„é—®é¢˜
        elif any(keyword in user_lower for keyword in ['è‡ªåŠ¨', 'auto', 'ç¡®è®¤']):
            status = "å¯ç”¨" if session['auto_confirm'] else "ç¦ç”¨"
            return f"è‡ªåŠ¨ç¡®è®¤å½“å‰{status}ã€‚ä½¿ç”¨ 'auto confirm' å‘½ä»¤å¯ä»¥åˆ‡æ¢çŠ¶æ€ã€‚"

        # é»˜è®¤å“åº”
        else:
            return "æˆ‘æ˜¯AIä»£ç ä¿®å¤åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨æ‰«æå’Œä¿®å¤ä»£ç é—®é¢˜ã€‚è¾“å…¥ 'help' æŸ¥çœ‹å¯ç”¨å‘½ä»¤ï¼Œæˆ–ä½¿ç”¨ 'scan' å¼€å§‹æ‰«æé—®é¢˜ã€‚"

    def _save_fix_analysis_result(self, result: dict, output_file: str):
        """ä¿å­˜ä¿®å¤åˆ†æç»“æœ"""
        try:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            if output_file.endswith('.json'):
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(result, f, indent=2, ensure_ascii=False, default=str)
            elif output_file.endswith('.md'):
                self._save_fix_analysis_markdown(result, output_path)
            else:
                # ç®€å•æ–‡æœ¬æ ¼å¼
                with open(output_path, 'w', encoding='utf-8') as f:
                    self._save_fix_analysis_text(result, f)

            print(f"ğŸ“„ ä¿®å¤ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def _save_fix_analysis_text(self, result: dict, file):
        """ä¿å­˜ä¿®å¤åˆ†ææ–‡æœ¬ç»“æœ"""
        file.write(f"ä¿®å¤åˆ†ææŠ¥å‘Š\n")
        file.write("=" * 50 + "\n")
        file.write(f"ç›®æ ‡è·¯å¾„: {result['target']}\n")
        file.write(f"åˆ†ææ¨¡å¼: {result['mode']}\n")
        file.write(f"æ‰«ææ–‡ä»¶æ•°: {result['files_scanned']}\n")
        file.write(f"å‘ç°é—®é¢˜æ•°: {result['total_issues_found']}\n")
        file.write(f"ä¿®å¤å°è¯•æ•°: {result['fixes_attempted']}\n")
        file.write(f"æˆåŠŸä¿®å¤æ•°: {result['successful_fixes']}\n\n")

        session = result.get('fix_session', {})
        if session.get('fix_history'):
            file.write("ä¿®å¤å†å²:\n")
            file.write("-" * 30 + "\n")
            for i, fix_record in enumerate(session['fix_history'], 1):
                file_path = fix_record.get('file_path', 'Unknown')
                success = fix_record.get('success', False)
                file.write(f"{i}. {'âœ…' if success else 'âŒ'} {Path(file_path).name}\n")
                file.write(f"   çŠ¶æ€: {'æˆåŠŸ' if success else 'å¤±è´¥'}\n")
                if not success and fix_record.get('error_message'):
                    file.write(f"   é”™è¯¯: {fix_record['error_message']}\n")
                file.write("-" * 30 + "\n")

    def _save_fix_analysis_markdown(self, result: dict, file_path: Path):
        """ä¿å­˜ä¿®å¤åˆ†æMarkdownç»“æœ"""
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("# ä¿®å¤åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**ç›®æ ‡è·¯å¾„**: `{result['target']}`\n")
            f.write(f"**åˆ†ææ¨¡å¼**: {result['mode']}\n")
            f.write(f"**æ‰«ææ–‡ä»¶æ•°**: {result['files_scanned']}\n")
            f.write(f"**å‘ç°é—®é¢˜æ•°**: {result['total_issues_found']}\n")
            f.write(f"**ä¿®å¤å°è¯•æ•°**: {result['fixes_attempted']}\n")
            f.write(f"**æˆåŠŸä¿®å¤æ•°**: {result['successful_fixes']}\n\n")

            session = result.get('fix_session', {})

            # é—®é¢˜ç»Ÿè®¡
            if session.get('identified_issues'):
                f.write("## å‘ç°é—®é¢˜ç»Ÿè®¡\n\n")
                f.write("| æ–‡ä»¶ | é—®é¢˜æ•° |\n")
                f.write("|------|--------|\n")
                for file_path, issues in session['identified_issues'].items():
                    file_name = Path(file_path).name
                    f.write(f"| `{file_name}` | {len(issues)} |\n")
                f.write("\n")

            # ä¿®å¤å†å²
            if session.get('fix_history'):
                f.write("## ä¿®å¤å†å²\n\n")
                for i, fix_record in enumerate(session['fix_history'], 1):
                    file_name = Path(fix_record.get('file_path', 'Unknown')).name
                    success = fix_record.get('success', False)
                    status_icon = "âœ…" if success else "âŒ"

                    f.write(f"### {i}. {status_icon} {file_name}\n\n")
                    f.write(f"- **çŠ¶æ€**: {'æˆåŠŸ' if success else 'å¤±è´¥'}\n")
                    f.write(f"- **è€—æ—¶**: {fix_record.get('total_time', 0):.2f}ç§’\n")
                    f.write(f"- **å®Œæˆé˜¶æ®µ**: {', '.join(fix_record.get('stages_completed', []))}\n")

                    if not success and fix_record.get('error_message'):
                        f.write(f"- **é”™è¯¯**: {fix_record['error_message']}\n")

                    f.write("\n")