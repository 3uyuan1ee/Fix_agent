# ğŸ”‘ LLM APIé…ç½®æŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨é…ç½®çœŸå®çš„LLM APIæ¥ä½¿ç”¨AIDefectDetectorçš„æ·±åº¦åˆ†æã€ä¿®å¤åˆ†æå’Œå·¥ä½œæµä¿®å¤åŠŸèƒ½ã€‚

## ğŸ“‹ é¡¹ç›®æ¶æ„æ¦‚è§ˆ

æœ¬é¡¹ç›®é‡‡ç”¨**åˆ†å±‚æ¶æ„è®¾è®¡**çš„LLMé…ç½®ç³»ç»Ÿï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åº”ç”¨å±‚ (Application Layer)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LLMClient (ç»Ÿä¸€å®¢æˆ·ç«¯)  â”‚  LLMConfigManager (é…ç½®ç®¡ç†å™¨)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  æŠ½è±¡å±‚ (Abstraction Layer)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     LLMProvider (æŠ½è±¡åŸºç±»)    â”‚    LLMConfig (æ•°æ®æ¨¡å‹)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  å®ç°å±‚ (Implementation Layer)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ OpenAI â”‚ Anthropic â”‚ ZhipuAI â”‚ Mock â”‚ HTTPClient â”‚ Exception  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  é…ç½®å±‚ (Configuration Layer)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ llm_config.yaml â”‚ user_config.yaml â”‚ ç¯å¢ƒå˜é‡ â”‚ configure_llm.py â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ LLMæä¾›å•†é€‰æ‹©æŒ‡å—

é¡¹ç›®æ”¯æŒä»¥ä¸‹LLMæä¾›å•†ï¼Œå„æœ‰ç‰¹è‰²ï¼š

### ğŸ‡¨ğŸ‡³ æ™ºè°±AI (å¼ºçƒˆæ¨èå›½å†…ç”¨æˆ·)

**ä¼˜åŠ¿:**
- âœ… å›½å†…è®¿é—®ç¨³å®šï¼Œæ— ç½‘ç»œé™åˆ¶
- âœ… æ”¯æŒä¸­æ–‡ä¼˜åŒ–ï¼Œç†è§£èƒ½åŠ›å¼º
- âœ… æ€§ä»·æ¯”é«˜ï¼Œæ–°ç”¨æˆ·æœ‰å…è´¹é¢åº¦
- âœ… æ”¯æŒå‡½æ•°è°ƒç”¨å’Œæµå¼å“åº”
- âœ… æ”¯æŒè§†è§‰æ¨¡å‹ (glm-4v)

**é€‚ç”¨åœºæ™¯:**
- å›½å†…ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- ä¸­æ–‡ä»£ç åˆ†æ
- æˆæœ¬æ•æ„Ÿçš„é¡¹ç›®
- éœ€è¦ç¨³å®šæœåŠ¡

**é…ç½®ç¤ºä¾‹:**
```yaml
zhipu:
  provider: "zhipu"
  model: "glm-4.5-air"       # æ¨èæ¨¡å‹
  api_key: "${ZHIPU_API_KEY}"
  api_base: "https://open.bigmodel.cn/api/paas/v4/"
  max_tokens: 4000
  temperature: 0.3
  timeout: 60
  max_retries: 3
```

### ğŸŒ OpenAI (åŠŸèƒ½æœ€å¼º)

**ä¼˜åŠ¿:**
- âœ… æ¨¡å‹èƒ½åŠ›æœ€å¼ºï¼Œç”Ÿæ€æœ€å®Œå–„
- âœ… æ”¯æŒæœ€æ–°çš„GPT-4 Turbo
- âœ… å‡½æ•°è°ƒç”¨åŠŸèƒ½å¼ºå¤§
- âœ… ç¤¾åŒºæ”¯æŒä¸°å¯Œ

**é™åˆ¶:**
- âš ï¸ éœ€è¦ç§‘å­¦ä¸Šç½‘ï¼Œå›½å†…è®¿é—®ä¸ç¨³å®š
- âš ï¸ æˆæœ¬ç›¸å¯¹è¾ƒé«˜

**é…ç½®ç¤ºä¾‹:**
```yaml
openai:
  provider: "openai"
  model: "gpt-4-turbo"        # æ€§ä»·æ¯”é«˜
  api_key: "${OPENAI_API_KEY}"
  api_base: "${OPENAI_BASE_URL:https://api.openai.com/v1}"
  max_tokens: 4000
  temperature: 0.3
  timeout: 30
  max_retries: 3
  # ä»£ç†é…ç½®ç¤ºä¾‹
  # api_base: "https://your-proxy.com/v1"
```

### ğŸ¤– Anthropic Claude (æ¨ç†èƒ½åŠ›ä¼˜ç§€)

**ä¼˜åŠ¿:**
- âœ… é•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›æœ€å¼º
- âœ… æ¨ç†èƒ½åŠ›å’Œå®‰å…¨æ€§ä¼˜ç§€
- âœ… Claude-3ç³»åˆ—æ¨¡å‹è¡¨ç°ä¼˜å¼‚
- âœ… ä»£ç åˆ†æèƒ½åŠ›å¼º

**é™åˆ¶:**
- âš ï¸ éœ€è¦ç§‘å­¦ä¸Šç½‘
- âš ï¸ æˆæœ¬è¾ƒé«˜

**é…ç½®ç¤ºä¾‹:**
```yaml
anthropic:
  provider: "anthropic"
  model: "claude-3-sonnet-20240229"
  api_key: "${ANTHROPIC_API_KEY}"
  api_base: "${ANTHROPIC_BASE_URL:https://api.anthropic.com}"
  max_tokens: 4000
  temperature: 0.3
  timeout: 30
  max_retries: 3
```

### ğŸ§ª Mock Provider (æµ‹è¯•å¼€å‘)

**ç”¨é€”:**
- âœ… æµ‹è¯•å’Œå¼€å‘ç¯å¢ƒ
- âœ… æ¼”ç¤ºå’ŒåŸå‹éªŒè¯
- âœ… æˆæœ¬æ§åˆ¶
- âœ… ç¦»çº¿å¼€å‘

**é…ç½®ç¤ºä¾‹:**
```yaml
mock:
  provider: "mock"
  model: "mock-model"
  api_key: "mock-api-key"
  api_base: "https://mock.api.com"
  max_tokens: 4000
  temperature: 0.7
  timeout: 30
```

## ğŸš€ å¿«é€Ÿé…ç½®æ–¹æ³•

### æ–¹æ³•1: ä½¿ç”¨ç»Ÿä¸€é…ç½®è„šæœ¬ (æœ€ç®€å•) â­

```bash
# äº¤äº’å¼é…ç½®å‘å¯¼
python3 scripts/configure_llm.py

# å¿«é€Ÿé…ç½®æ¨¡å¼
python3 scripts/configure_llm.py --quick

# ç›´æ¥é…ç½®æŒ‡å®šæä¾›å•†
python3 scripts/configure_llm.py --provider zhipu
python3 scripts/configure_llm.py --provider openai
python3 scripts/configure_llm.py --provider anthropic
```

**é…ç½®è„šæœ¬åŠŸèƒ½ç‰¹ç‚¹:**
- ğŸ¯ äº¤äº’å¼å‘å¯¼ï¼Œä¸€æ­¥æ­¥å¼•å¯¼é…ç½®
- ğŸ“‹ æ”¯æŒæ‰€æœ‰ä¸»æµLLMæä¾›å•†
- ğŸ”§ è‡ªåŠ¨æ›´æ–°é…ç½®æ–‡ä»¶
- âœ… é…ç½®éªŒè¯å’Œè¿æ¥æµ‹è¯•
- ğŸ¯ æ”¯æŒç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶ä¸¤ç§æ–¹å¼
- ğŸ’¡ æ™ºèƒ½æ•…éšœè¯Šæ–­å’Œå»ºè®®

### æ–¹æ³•2: ç¯å¢ƒå˜é‡é…ç½® (æ¨èå¼€å‘è€…)

```bash
# æ™ºè°±AI (æ¨èå›½å†…ç”¨æˆ·)
export ZHIPU_API_KEY="your-zhipu-api-key-here"

# OpenAI
export OPENAI_API_KEY="your-openai-api-key-here"
export OPENAI_BASE_URL="https://api.openai.com/v1"

# Anthropic
export ANTHROPIC_API_KEY="your-anthropic-api-key-here"
export ANTHROPIC_BASE_URL="https://api.anthropic.com"

# ç«‹å³ä½¿ç”¨
python3 main.py analyze deep ./src
```

### æ–¹æ³•3: æ‰‹åŠ¨ç¼–è¾‘é…ç½®æ–‡ä»¶

ç¼–è¾‘ `config/llm_config.yaml`ï¼š

```yaml
providers:
  zhipu:
    provider: "zhipu"
    model: "glm-4.5-air"
    api_key: "your-actual-api-key"  # æˆ– "${ZHIPU_API_KEY}"
    api_base: "https://open.bigmodel.cn/api/paas/v4/"
    max_tokens: 4000
    temperature: 0.3
    timeout: 60
    max_retries: 3
```

## ğŸ”‘ APIå¯†é’¥è·å–æŒ‡å—

### æ™ºè°±AI (æ¨è)

#### æ­¥éª¤1: æ³¨å†Œè´¦å·
1. è®¿é—® [æ™ºè°±AIå¼€æ”¾å¹³å°](https://open.bigmodel.cn/)
2. ç‚¹å‡»"æ³¨å†Œ"æŒ‰é’®
3. ä½¿ç”¨æ‰‹æœºå·æˆ–é‚®ç®±å®Œæˆæ³¨å†Œ
4. å®Œæˆå®åè®¤è¯ï¼ˆéœ€è¦èº«ä»½è¯ï¼‰

#### æ­¥éª¤2: è·å–APIå¯†é’¥
1. ç™»å½•åè¿›å…¥"æ§åˆ¶å°"
2. åœ¨å·¦ä¾§èœå•é€‰æ‹©"APIå¯†é’¥"
3. ç‚¹å‡»"åˆ›å»ºAPIå¯†é’¥"
4. è®¾ç½®å¯†é’¥åç§°ï¼ˆå¦‚ï¼šAIDefectDetectorï¼‰
5. å¤åˆ¶ç”Ÿæˆçš„APIå¯†é’¥
6. ä¿å­˜å¯†é’¥åˆ°å®‰å…¨ä½ç½®

#### æ­¥éª¤3: å……å€¼ä½™é¢
1. åœ¨æ§åˆ¶å°é€‰æ‹©"ä½™é¢ç®¡ç†"
2. é€‰æ‹©å……å€¼å¥—é¤
3. æ–°ç”¨æˆ·é€šå¸¸æœ‰å…è´¹è¯•ç”¨é¢åº¦
4. æ ¹æ®éœ€è¦é€‰æ‹©åˆé€‚çš„å……å€¼æ–¹æ¡ˆ

### OpenAI

#### æ­¥éª¤1: æ³¨å†Œè´¦å·
1. è®¿é—® [OpenAI Platform](https://platform.openai.com/)
2. ä½¿ç”¨é‚®ç®±æˆ–Googleè´¦å·æ³¨å†Œ
3. éªŒè¯é‚®ç®±åœ°å€

#### æ­¥éª¤2: è·å–APIå¯†é’¥
1. ç™»å½•åè¿›å…¥ "API Keys" é¡µé¢
2. ç‚¹å‡» "Create new secret key"
3. è®¾ç½®å¯†é’¥åç§°å’Œæƒé™
4. å¤åˆ¶å¹¶ä¿å­˜APIå¯†é’¥ï¼ˆåªæ˜¾ç¤ºä¸€æ¬¡ï¼‰

#### æ­¥éª¤3: ç»‘å®šæ”¯ä»˜
1. åœ¨ "Settings" â†’ "Billing" ä¸­
2. æ·»åŠ æ”¯ä»˜æ–¹å¼ï¼ˆä¿¡ç”¨å¡æˆ–å€Ÿè®°å¡ï¼‰
3. è®¾ç½®ä½¿ç”¨é™é¢

### Anthropic Claude

#### æ­¥éª¤1: æ³¨å†Œè´¦å·
1. è®¿é—® [Anthropic Console](https://console.anthropic.com/)
2. ä½¿ç”¨é‚®ç®±æ³¨å†Œè´¦å·
3. éªŒè¯é‚®ç®±åœ°å€

#### æ­¥éª¤2: è·å–APIå¯†é’¥
1. ç™»å½•åè¿›å…¥ "API Keys" é¡µé¢
2. ç‚¹å‡» "Create Key"
3. è®¾ç½®å¯†é’¥åç§°å’Œæƒé™
4. å¤åˆ¶å¹¶ä¿å­˜APIå¯†é’¥

#### æ­¥éª¤3: è®¾ç½®è®¡è´¹
1. åœ¨ "Usage" é¡µé¢æŸ¥çœ‹ç”¨é‡
2. è®¾ç½®é¢„ç®—æé†’
3. æ ¹æ®éœ€è¦é€‰æ‹©è®¡è´¹æ–¹æ¡ˆ

## ğŸ› ï¸ é…ç½®éªŒè¯å’Œæµ‹è¯•

### ä½¿ç”¨é…ç½®è„šæœ¬éªŒè¯

```bash
# æŸ¥çœ‹å½“å‰é…ç½®çŠ¶æ€
python3 scripts/configure_llm.py --status

# è¿è¡Œé…ç½®è¯Šæ–­
python3 scripts/configure_llm.py --diagnose

# æµ‹è¯•æŒ‡å®šæä¾›å•†è¿æ¥
python3 scripts/configure_llm.py --test zhipu
python3 scripts/configure_llm.py --test openai
python3 scripts/configure_llm.py --test anthropic
```

### æ‰‹åŠ¨éªŒè¯é…ç½®

```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦è®¾ç½®
echo $ZHIPU_API_KEY
echo $OPENAI_API_KEY
echo $ANTHROPIC_API_KEY

# æµ‹è¯•æ·±åº¦åˆ†æåŠŸèƒ½
python3 main.py analyze deep ./src/utils/config.py --verbose

# æµ‹è¯•ä¿®å¤åˆ†æåŠŸèƒ½
python3 main.py analyze fix ./src/utils/config.py --verbose

# æµ‹è¯•å·¥ä½œæµåŠŸèƒ½
python3 main.py analyze workflow ./src/utils/config.py --dry-run
```

## ğŸ”§ é«˜çº§é…ç½®é€‰é¡¹

### å¤šæä¾›å•†é…ç½®

é…ç½®æ–‡ä»¶æ”¯æŒåŒæ—¶é…ç½®å¤šä¸ªæä¾›å•†ï¼š

```yaml
# config/llm_config.yaml
providers:
  zhipu:
    provider: "zhipu"
    model: "glm-4.5-air"
    api_key: "${ZHIPU_API_KEY}"
    api_base: "https://open.bigmodel.cn/api/paas/v4/"
    max_tokens: 4000
    temperature: 0.3
    timeout: 60
    max_retries: 3

  openai:
    provider: "openai"
    model: "gpt-4-turbo"
    api_key: "${OPENAI_API_KEY}"
    api_base: "${OPENAI_BASE_URL:https://api.openai.com/v1}"
    max_tokens: 4000
    temperature: 0.3
    timeout: 30
    max_retries: 3

  mock:
    provider: "mock"
    model: "mock-model"
    api_key: "mock-api-key"
    api_base: "https://mock.api.com"
    max_tokens: 4000
    temperature: 0.7
    timeout: 30
```

### ç”¨æˆ·é…ç½®æ–‡ä»¶

ç¼–è¾‘ `~/.aidefect/config.yaml` è®¾ç½®é»˜è®¤æä¾›å•†ï¼š

```yaml
llm:
  default_provider: "zhipu"  # è®¾ç½®é»˜è®¤ä½¿ç”¨çš„æä¾›å•†
  fallback_providers: ["mock"]  # å¤‡ç”¨æä¾›å•†

  # æä¾›å•†ç‰¹å®šé…ç½®å¯ä»¥è¦†ç›–å…¨å±€é…ç½®
  zhipu:
    temperature: 0.2  # æ›´ä¿å®ˆçš„å‚æ•°
    max_tokens: 6000   # æ›´å¤§çš„è¾“å‡ºé•¿åº¦
```

### æ¨¡å‹å‚æ•°ä¼˜åŒ–

#### ä¸åŒåœºæ™¯çš„æ¨èå‚æ•°

**ä»£ç å®¡æŸ¥ (ä¸¥æ ¼æ¨¡å¼)**
```yaml
code_review:
  temperature: 0.1      # ä½æ¸©åº¦ï¼Œæ›´ç¡®å®šæ€§çš„è¾“å‡º
  max_tokens: 2000      # é€‚ä¸­çš„è¾“å‡ºé•¿åº¦
  model: "glm-4.5"      # ä½¿ç”¨å¼ºæ¨¡å‹
```

**åˆ›æ„æ”¹è¿› (åˆ›æ„æ¨¡å¼)**
```yaml
creative_improvement:
  temperature: 0.8      # é«˜æ¸©åº¦ï¼Œæ›´æœ‰åˆ›æ„
  max_tokens: 4000      # è¾ƒé•¿çš„è¾“å‡º
  model: "claude-3-sonnet-20240229"  # ä½¿ç”¨åˆ›æ„æ¨¡å‹
```

**å®‰å…¨åˆ†æ (ä¿å®ˆæ¨¡å¼)**
```yaml
security_analysis:
  temperature: 0.2      # ä½æ¸©åº¦ï¼Œç¡®ä¿å‡†ç¡®æ€§
  max_tokens: 6000      # è¯¦ç»†çš„å®‰å…¨åˆ†æ
  model: "gpt-4"        # ä½¿ç”¨æœ€å¼ºæ¨¡å‹
```

## ğŸ›¡ï¸ å®‰å…¨æœ€ä½³å®è·µ

### APIå¯†é’¥å®‰å…¨

1. **æ°¸ä¸æäº¤APIå¯†é’¥åˆ°ç‰ˆæœ¬æ§åˆ¶:**
```bash
# ç¡®ä¿ .env æ–‡ä»¶åœ¨ .gitignore ä¸­
echo ".env" >> .gitignore
echo "~/.aidefect/.env" >> .gitignore
echo "config/user_config.yaml" >> .gitignore
```

2. **ä½¿ç”¨ç¯å¢ƒå˜é‡:**
```bash
# æ¨èï¼šä½¿ç”¨ç¯å¢ƒå˜é‡
export ZHIPU_API_KEY="your-key"

# é¿å…ï¼šç¡¬ç¼–ç åœ¨ä»£ç ä¸­
# âŒ é”™è¯¯åšæ³•
api_key = "sk-xxxxxxxxxxxxxxxx"  # ä¸è¦è¿™æ ·åš
```

3. **å®šæœŸè½®æ¢APIå¯†é’¥:**
```bash
# å®šæœŸæ›´æ¢APIå¯†é’¥ï¼ˆå¦‚æ¯æœˆï¼‰
# åœ¨æ§åˆ¶å°ä¸­ç¦ç”¨æ—§å¯†é’¥ï¼Œåˆ›å»ºæ–°å¯†é’¥
```

### é…ç½®æ–‡ä»¶å®‰å…¨

1. **æ–‡ä»¶æƒé™è®¾ç½®:**
```bash
# è®¾ç½®é…ç½®æ–‡ä»¶æƒé™
chmod 600 ~/.aidefect/config.yaml
chmod 600 config/llm_config.yaml
chmod 600 ~/.aidefect/.env
```

2. **æ•æ„Ÿä¿¡æ¯è¿‡æ»¤:**
```yaml
# âœ… æ­£ç¡®ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡
api_key: "${ZHIPU_API_KEY}"

# âŒ é”™è¯¯ï¼šç›´æ¥å†™å…¥å¯†é’¥
api_key: "sk-xxxxxxxxxxxxxxxx"
```

### ç½‘ç»œå®‰å…¨

1. **ä½¿ç”¨HTTPS:**
```yaml
# âœ… æ­£ç¡®ï¼šä½¿ç”¨HTTPS
api_base: "https://api.openai.com/v1"

# âŒ é”™è¯¯ï¼šä½¿ç”¨HTTPï¼ˆä¸å®‰å…¨ï¼‰
api_base: "http://api.openai.com/v1"
```

2. **ä»£ç†é…ç½®ï¼ˆå¦‚éœ€è¦ï¼‰:**
```yaml
# é…ç½®ä»£ç†æœåŠ¡å™¨
api_base: "https://your-proxy.com/v1"
# æˆ–è®¾ç½®ç¯å¢ƒå˜é‡
export HTTPS_PROXY="http://your-proxy:8080"
export HTTP_PROXY="http://your-proxy:8080"
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. APIå¯†é’¥ç›¸å…³é”™è¯¯

**é”™è¯¯ä¿¡æ¯:**
```
âŒ Authentication failed: Invalid API key
âŒ APIå¯†é’¥è®¤è¯å¤±è´¥
```

**è§£å†³æ–¹æ¡ˆ:**
```bash
# æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®è®¾ç½®
echo $ZHIPU_API_KEY

# éªŒè¯APIå¯†é’¥æ ¼å¼
# æ™ºè°±AIï¼šé€šå¸¸ä»¥æ•°å­—å¼€å¤´
# OpenAIï¼šé€šå¸¸ä»¥ "sk-" å¼€å¤´
# Anthropicï¼šé€šå¸¸ä»¥ "sk-ant-" å¼€å¤´

# é‡æ–°è®¾ç½®APIå¯†é’¥
export ZHIPU_API_KEY="correct-api-key"

# ä½¿ç”¨é…ç½®è„šæœ¬é‡æ–°é…ç½®
python3 scripts/configure_llm.py --provider zhipu
```

#### 2. ç½‘ç»œè¿æ¥é—®é¢˜

**é”™è¯¯ä¿¡æ¯:**
```
âŒ Connection timeout
âŒ ç½‘ç»œè¿æ¥è¶…æ—¶
âŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨
```

**è§£å†³æ–¹æ¡ˆ:**
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
ping open.bigmodel.cn

# æ£€æŸ¥ä»£ç†è®¾ç½®ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
echo $HTTPS_PROXY
echo $HTTP_PROXY

# æµ‹è¯•APIè¿æ¥
curl -X POST "https://open.bigmodel.cn/api/paas/v4/chat/completions" \
  -H "Authorization: Bearer $ZHIPU_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model":"glm-4.5-air","messages":[{"role":"user","content":"Hello"}],"max_tokens":10}'
```

#### 3. é…é¢ä¸è¶³é—®é¢˜

**é”™è¯¯ä¿¡æ¯:**
```
âŒ Insufficient quota
âŒ è´¦æˆ·ä½™é¢ä¸è¶³
âŒ APIé…é¢å·²ç”¨å®Œ
```

**è§£å†³æ–¹æ¡ˆ:**
```bash
# æ£€æŸ¥è´¦æˆ·ä½™é¢
# ç™»å½•æ™ºè°±AIæ§åˆ¶å°æŸ¥çœ‹ä½™é¢

# å……å€¼è´¦æˆ·
# åœ¨æ§åˆ¶å°é€‰æ‹©åˆé€‚çš„å……å€¼æ–¹æ¡ˆ

# è®¾ç½®ä½¿ç”¨é™åˆ¶
export LLM_MAX_REQUESTS_PER_MIN=60  # é™åˆ¶è¯·æ±‚é¢‘ç‡
```

#### 4. æ¨¡å‹ä¸æ”¯æŒé—®é¢˜

**é”™è¯¯ä¿¡æ¯:**
```
âŒ Model not found: invalid-model
âŒ æ¨¡å‹ä¸å­˜åœ¨
âŒ ä¸æ”¯æŒçš„æ¨¡å‹
```

**è§£å†³æ–¹æ¡ˆ:**
```bash
# æŸ¥çœ‹æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
æ™ºè°±AI: glm-4.5, glm-4.5-air, glm-4, glm-4-airx, glm-4-flash, glm-4v
OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229

# æ£€æŸ¥å½“å‰é…ç½®çš„æ¨¡å‹
python3 -c "
import yaml
with open('config/llm_config.yaml', 'r') as f:
    config = yaml.safe_load(f)
    zhipu_config = config['providers'].get('zhipu', {})
    print(f'å½“å‰æ¨¡å‹: {zhipu_config.get(\"model\", \"æœªé…ç½®\")}')
"
```

#### 5. é…ç½®æ–‡ä»¶é—®é¢˜

**é”™è¯¯ä¿¡æ¯:**
```
âŒ Configuration file not found
âŒ é…ç½®æ–‡ä»¶è§£æé”™è¯¯
âŒ é…ç½®éªŒè¯å¤±è´¥
```

**è§£å†³æ–¹æ¡ˆ:**
```bash
# æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -la config/llm_config.yaml
ls -la ~/.aidefect/config.yaml

# éªŒè¯é…ç½®æ–‡ä»¶è¯­æ³•
python3 -c "import yaml; yaml.safe_load(open('config/llm_config.yaml'))"

# é‡æ–°ç”Ÿæˆé…ç½®æ–‡ä»¶
python3 scripts/configure_llm.py --provider zhipu
```

### é…ç½®è¯Šæ–­å·¥å…·

**è¿è¡Œå®Œæ•´è¯Šæ–­:**
```bash
python3 scripts/configure_llm.py --diagnose
```

**æ£€æŸ¥é…ç½®åŠ è½½çŠ¶æ€:**
```bash
python3 scripts/configure_llm.py --status
```

**æµ‹è¯•APIè¿æ¥:**
```bash
python3 scripts/configure_llm.py --test zhipu
```

## ğŸ“ é…ç½®ç¤ºä¾‹æ¨¡æ¿

### åŸºç¡€å¼€å‘é…ç½®

```yaml
# config/llm_config.yaml - åŸºç¡€é…ç½®
providers:
  mock:
    provider: "mock"
    model: "mock-model"
    api_key: "mock-api-key"
    api_base: "https://mock.api.com"
    max_tokens: 2000
    temperature: 0.7
    timeout: 30
```

### ç”Ÿäº§ç¯å¢ƒé…ç½®

```yaml
# config/llm_config.yaml - ç”Ÿäº§é…ç½®
providers:
  zhipu:
    provider: "zhipu"
    model: "glm-4.5-air"
    api_key: "${ZHIPU_API_KEY}"
    api_base: "https://open.bigmodel.cn/api/paas/v4/"
    max_tokens: 8000  # ç”Ÿäº§ç¯å¢ƒå¢åŠ tokené™åˆ¶
    temperature: 0.2  # ç”Ÿäº§ç¯å¢ƒé™ä½åˆ›é€ æ€§
    timeout: 60       # ç”Ÿäº§ç¯å¢ƒå¢åŠ è¶…æ—¶æ—¶é—´
    max_retries: 5    # ç”Ÿäº§ç¯å¢ƒå¢åŠ é‡è¯•æ¬¡æ•°

  # ç”Ÿäº§å›é€€é…ç½®
  openai:
    provider: "openai"
    model: "gpt-4-turbo"
    api_key: "${OPENAI_API_KEY}"
    api_base: "${OPENAI_BASE_URL:https://api.openai.com/v1}"
    max_tokens: 8000
    temperature: 0.2
    timeout: 60
    max_retries: 5

  mock:
    provider: "mock"
    model: "mock-model"
    api_key: "mock-api-key"
    api_base: "https://mock.api.com"
    max_tokens: 4000
    temperature: 0.7
    timeout: 30
```

### é«˜çº§é…ç½®ç¤ºä¾‹

```yaml
# config/llm_config.yaml - é«˜çº§é…ç½®
providers:
  zhipu:
    provider: "zhipu"
    model: "glm-4.5-air"
    api_key: "${ZHIPU_API_KEY}"
    api_base: "https://open.bigmodel.cn/api/paas/v4/"

    # åŸºç¡€å‚æ•°
    max_tokens: 4000
    temperature: 0.3
    timeout: 60
    max_retries: 3

    # é«˜çº§å‚æ•°
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0

    # æµå¼å“åº”é…ç½®
    stream: true
    stream_timeout: 30

    # å¹¶å‘æ§åˆ¶
    max_concurrent_requests: 5
    request_rate_limit: 60  # æ¯åˆ†é’Ÿè¯·æ±‚æ•°

    # ç¼“å­˜é…ç½®
    enable_cache: true
    cache_ttl: 3600  # ç¼“å­˜1å°æ—¶

    # é‡è¯•ç­–ç•¥
    retry_strategy: "exponential_backoff"
    initial_retry_delay: 1.0
    max_retry_delay: 60.0
```

## ğŸ¯ ä½¿ç”¨æ¨¡å¼ä¸é…ç½®å»ºè®®

### é™æ€åˆ†ææ¨¡å¼
- **æ— éœ€APIé…ç½®**
- **æ¨èå·¥å…·é…ç½®**: `ast, pylint, flake8, bandit`
- **è¾“å‡ºæ ¼å¼**: `json, table, markdown`

### æ·±åº¦åˆ†ææ¨¡å¼
- **éœ€è¦APIé…ç½®**
- **æ¨èæ¨¡å‹**: `glm-4.5-air` (æ™ºè°±) æˆ– `gpt-4-turbo` (OpenAI)
- **æ¨èå‚æ•°**: `temperature: 0.3, max_tokens: 4000`
- **é€‚åˆåœºæ™¯**: ä»£ç é‡æ„å»ºè®®ã€æ¶æ„åˆ†æ

### ä¿®å¤åˆ†ææ¨¡å¼
- **éœ€è¦APIé…ç½®**
- **æ¨èæ¨¡å‹**: `glm-4.5` (æ™ºè°±) æˆ– `gpt-4` (OpenAI)
- **æ¨èå‚æ•°**: `temperature: 0.2, max_tokens: 6000`
- **é€‚åˆåœºæ™¯**: å®‰å…¨æ¼æ´ä¿®å¤ã€æ€§èƒ½ä¼˜åŒ–

### å·¥ä½œæµä¿®å¤æ¨¡å¼ â­
- **éœ€è¦APIé…ç½®**
- **æ¨èæ¨¡å‹**: `glm-4.5` (æ™ºè°±) æˆ– `gpt-4` (OpenAI)
- **æ¨èå‚æ•°**: `temperature: 0.2, max_tokens: 6000`
- **é€‚åˆåœºæ™¯**: å¤æ‚ä¿®å¤é¡¹ç›®ã€å®Œæ•´é—­ç¯ä¿®å¤

## ğŸš€ å¿«é€Ÿå¼€å§‹

ç°åœ¨æ‚¨å·²ç»äº†è§£äº†å®Œæ•´çš„APIé…ç½®æµç¨‹ï¼Œé€‰æ‹©æœ€é€‚åˆæ‚¨çš„é…ç½®æ–¹å¼å¼€å§‹ä½¿ç”¨ï¼š

### ğŸš€ æœ€å¿«æ–¹å¼ - å¿«é€Ÿé…ç½®å‘å¯¼

```bash
# 1. è¿è¡Œå¿«é€Ÿé…ç½®å‘å¯¼
python3 scripts/configure_llm.py --quick

# 2. æŒ‰æç¤ºé€‰æ‹©æä¾›å•†å’Œè¾“å…¥APIå¯†é’¥

# 3. æµ‹è¯•é…ç½®
python3 scripts/configure_llm.py --test zhipu

# 4. å¼€å§‹ä½¿ç”¨
python3 main.py analyze workflow ./src
```

### âš¡ æ¨èæ–¹å¼ - æ™ºè°±AIé…ç½®

```bash
# 1. é…ç½®æ™ºè°±AIï¼ˆæ¨èå›½å†…ç”¨æˆ·ï¼‰
python3 scripts/configure_llm.py --provider zhipu

# 2. è¾“å…¥æ‚¨çš„æ™ºè°±AI APIå¯†é’¥

# 3. å¼€å§‹æ·±åº¦åˆ†æ
python3 main.py analyze deep ./src --verbose

# 4. ä½“éªŒå·¥ä½œæµæ¨¡å¼
python3 main.py analyze workflow ./src --dry-run
```

### ğŸ”§ æ‰‹åŠ¨é…ç½®æ–¹å¼

```bash
# 1. è®¾ç½®ç¯å¢ƒå˜é‡
export ZHIPU_API_KEY="your-api-key"

# 2. ç«‹å³ä½¿ç”¨
python3 main.py analyze deep ./src

# 3. æµ‹è¯•å·¥ä½œæµ
python3 main.py analyze workflow ./src
```

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é…ç½®é—®é¢˜ï¼š

1. **è¿è¡Œè¯Šæ–­å·¥å…·**: `python3 scripts/configure_llm.py --diagnose`
2. **æŸ¥çœ‹é…ç½®çŠ¶æ€**: `python3 scripts/configure_llm.py --status`
3. **æµ‹è¯•è¿æ¥**: `python3 scripts/configure_llm.py --test [provider]`
4. **é‡æ–°é…ç½®**: `python3 scripts/configure_llm.py --provider [provider]`

ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼ğŸš€ å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹å¿«é€Ÿå¼€å§‹æŒ‡å—æˆ–ä½¿ç”¨é…ç½®è¯Šæ–­å·¥å…·ã€‚